import{s as F,o as I,n as O}from"../chunks/scheduler.362310b7.js";import{S as R,i as B,g as d,s as i,r as L,A as D,h as g,f as n,c as r,j,u as M,x as H,k as Y,y as J,a as s,v as C,d as E,t as q,w as z}from"../chunks/index.57dfc70d.js";import{T as K}from"../chunks/Tip.14b2ab21.js";import{H as N,E as Q}from"../chunks/index.fa158b42.js";function V(w){let a,m='Tensor Parallelism only works for <a href="../supported_models">models officially supported</a>, it will not work when falling back to <code>transformers</code>. You can get more information about unsupported models <a href="../basic_tutorials/non_core_models">here</a>.';return{c(){a=d("p"),a.innerHTML=m},l(o){a=g(o,"P",{"data-svelte-h":!0}),H(a)!=="svelte-1psn3zf"&&(a.innerHTML=m)},m(o,$){s(o,a,$)},p:O,d(o){o&&n(a)}}}function W(w){let a,m,o,$,p,P,u,A="Tensor parallelism is a technique used to fit a large model in multiple GPUs. For example, when multiplying the input tensors with the first weight tensor, the matrix multiplication is equivalent to splitting the weight tensor column-wise, multiplying each column with the input separately, and then concatenating the separate outputs. These outputs are then transferred from the GPUs and concatenated together to get the final result, like below ðŸ‘‡",T,f,G='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/tgi/TP.png" alt="Image courtesy of Anton Lozkhov"/>',v,l,x,c,S='You can learn a lot more details about tensor-parallelism from <a href="https://huggingface.co/docs/transformers/main/en/perf_train_gpu_many#tensor-parallelism" rel="nofollow">the <code>transformers</code> docs</a>.',b,h,y,_,k;return p=new N({props:{title:"Tensor Parallelism",local:"tensor-parallelism",headingTag:"h1"}}),l=new K({props:{warning:!0,$$slots:{default:[V]},$$scope:{ctx:w}}}),h=new Q({props:{source:"https://github.com/huggingface/text-generation-inference/blob/main/docs/source/conceptual/tensor_parallelism.md"}}),{c(){a=d("meta"),m=i(),o=d("p"),$=i(),L(p.$$.fragment),P=i(),u=d("p"),u.textContent=A,T=i(),f=d("p"),f.innerHTML=G,v=i(),L(l.$$.fragment),x=i(),c=d("p"),c.innerHTML=S,b=i(),L(h.$$.fragment),y=i(),_=d("p"),this.h()},l(e){const t=D("svelte-u9bgzb",document.head);a=g(t,"META",{name:!0,content:!0}),t.forEach(n),m=r(e),o=g(e,"P",{}),j(o).forEach(n),$=r(e),M(p.$$.fragment,e),P=r(e),u=g(e,"P",{"data-svelte-h":!0}),H(u)!=="svelte-d2if4l"&&(u.textContent=A),T=r(e),f=g(e,"P",{"data-svelte-h":!0}),H(f)!=="svelte-xk4xsj"&&(f.innerHTML=G),v=r(e),M(l.$$.fragment,e),x=r(e),c=g(e,"P",{"data-svelte-h":!0}),H(c)!=="svelte-1mk24de"&&(c.innerHTML=S),b=r(e),M(h.$$.fragment,e),y=r(e),_=g(e,"P",{}),j(_).forEach(n),this.h()},h(){Y(a,"name","hf:doc:metadata"),Y(a,"content",X)},m(e,t){J(document.head,a),s(e,m,t),s(e,o,t),s(e,$,t),C(p,e,t),s(e,P,t),s(e,u,t),s(e,T,t),s(e,f,t),s(e,v,t),C(l,e,t),s(e,x,t),s(e,c,t),s(e,b,t),C(h,e,t),s(e,y,t),s(e,_,t),k=!0},p(e,[t]){const U={};t&2&&(U.$$scope={dirty:t,ctx:e}),l.$set(U)},i(e){k||(E(p.$$.fragment,e),E(l.$$.fragment,e),E(h.$$.fragment,e),k=!0)},o(e){q(p.$$.fragment,e),q(l.$$.fragment,e),q(h.$$.fragment,e),k=!1},d(e){e&&(n(m),n(o),n($),n(P),n(u),n(T),n(f),n(v),n(x),n(c),n(b),n(y),n(_)),n(a),z(p,e),z(l,e),z(h,e)}}}const X='{"title":"Tensor Parallelism","local":"tensor-parallelism","sections":[],"depth":1}';function Z(w){return I(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class se extends R{constructor(a){super(),B(this,a,Z,W,F,{})}}export{se as component};
