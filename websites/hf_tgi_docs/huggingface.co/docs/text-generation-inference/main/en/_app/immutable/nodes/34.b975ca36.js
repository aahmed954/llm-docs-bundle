import{s as H,n as L,o as N}from"../chunks/scheduler.362310b7.js";import{S,i as E,g as h,s as l,r as _,A as X,h as w,f as a,c as s,j as z,u as j,x as C,k as D,y as F,a as n,v as x,d as Z,t as V,w as k}from"../chunks/index.57dfc70d.js";import{C as Y}from"../chunks/CodeBlock.5d40996c.js";import{H as Q,E as O}from"../chunks/index.fa158b42.js";function q(B){let i,g,f,v,o,I,r,P='TGI optimized models are supported on NVIDIA <a href="https://www.nvidia.com/en-us/data-center/h100/" rel="nofollow">H100</a>, <a href="https://www.nvidia.com/en-us/data-center/a100/" rel="nofollow">A100</a>, <a href="https://www.nvidia.com/en-us/data-center/products/a10-gpu/" rel="nofollow">A10G</a> and <a href="https://www.nvidia.com/en-us/data-center/tesla-t4/" rel="nofollow">T4</a> GPUs with CUDA 12.2+. Note that you have to install <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html" rel="nofollow">NVIDIA Container Toolkit</a> to use it.',J,m,W="For other NVIDIA GPUs, continuous batching will still apply, but some operations like flash attention and paged attention will not be executed.",b,u,R="TGI can be used on NVIDIA GPUs through its official docker image:",G,c,$,p,A='The launched TGI server can then be queried from clients, make sure to check out the <a href="./basic_tutorials/consuming_tgi">Consuming TGI</a> guide.',y,d,M,T,U;return o=new Q({props:{title:"Using TGI with Nvidia GPUs",local:"using-tgi-with-nvidia-gpus",headingTag:"h1"}}),c=new Y({props:{code:"bW9kZWwlM0R0ZWtuaXVtJTJGT3Blbkhlcm1lcy0yLjUtTWlzdHJhbC03QiUwQXZvbHVtZSUzRCUyNFBXRCUyRmRhdGElMjAlMjMlMjBzaGFyZSUyMGElMjB2b2x1bWUlMjB3aXRoJTIwdGhlJTIwRG9ja2VyJTIwY29udGFpbmVyJTIwdG8lMjBhdm9pZCUyMGRvd25sb2FkaW5nJTIwd2VpZ2h0cyUyMGV2ZXJ5JTIwcnVuJTBBJTBBZG9ja2VyJTIwcnVuJTIwLS1ncHVzJTIwYWxsJTIwLS1zaG0tc2l6ZSUyMDY0ZyUyMC1wJTIwODA4MCUzQTgwJTIwLXYlMjAlMjR2b2x1bWUlM0ElMkZkYXRhJTIwJTVDJTBBJTIwJTIwJTIwJTIwZ2hjci5pbyUyRmh1Z2dpbmdmYWNlJTJGdGV4dC1nZW5lcmF0aW9uLWluZmVyZW5jZSUzQTMuMy4xJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbC1pZCUyMCUyNG1vZGVs",highlighted:`model=teknium/OpenHermes-2.5-Mistral-7B
volume=<span class="hljs-variable">$PWD</span>/data <span class="hljs-comment"># share a volume with the Docker container to avoid downloading weights every run</span>

docker run --gpus all --shm-size 64g -p 8080:80 -v <span class="hljs-variable">$volume</span>:/data \\
    ghcr.io/huggingface/text-generation-inference:3.3.1 \\
    --model-id <span class="hljs-variable">$model</span>`,wrap:!1}}),d=new O({props:{source:"https://github.com/huggingface/text-generation-inference/blob/main/docs/source/installation_nvidia.md"}}),{c(){i=h("meta"),g=l(),f=h("p"),v=l(),_(o.$$.fragment),I=l(),r=h("p"),r.innerHTML=P,J=l(),m=h("p"),m.textContent=W,b=l(),u=h("p"),u.textContent=R,G=l(),_(c.$$.fragment),$=l(),p=h("p"),p.innerHTML=A,y=l(),_(d.$$.fragment),M=l(),T=h("p"),this.h()},l(t){const e=X("svelte-u9bgzb",document.head);i=w(e,"META",{name:!0,content:!0}),e.forEach(a),g=s(t),f=w(t,"P",{}),z(f).forEach(a),v=s(t),j(o.$$.fragment,t),I=s(t),r=w(t,"P",{"data-svelte-h":!0}),C(r)!=="svelte-1j2e35e"&&(r.innerHTML=P),J=s(t),m=w(t,"P",{"data-svelte-h":!0}),C(m)!=="svelte-6jbgov"&&(m.textContent=W),b=s(t),u=w(t,"P",{"data-svelte-h":!0}),C(u)!=="svelte-uuz14s"&&(u.textContent=R),G=s(t),j(c.$$.fragment,t),$=s(t),p=w(t,"P",{"data-svelte-h":!0}),C(p)!=="svelte-uo4xf6"&&(p.innerHTML=A),y=s(t),j(d.$$.fragment,t),M=s(t),T=w(t,"P",{}),z(T).forEach(a),this.h()},h(){D(i,"name","hf:doc:metadata"),D(i,"content",K)},m(t,e){F(document.head,i),n(t,g,e),n(t,f,e),n(t,v,e),x(o,t,e),n(t,I,e),n(t,r,e),n(t,J,e),n(t,m,e),n(t,b,e),n(t,u,e),n(t,G,e),x(c,t,e),n(t,$,e),n(t,p,e),n(t,y,e),x(d,t,e),n(t,M,e),n(t,T,e),U=!0},p:L,i(t){U||(Z(o.$$.fragment,t),Z(c.$$.fragment,t),Z(d.$$.fragment,t),U=!0)},o(t){V(o.$$.fragment,t),V(c.$$.fragment,t),V(d.$$.fragment,t),U=!1},d(t){t&&(a(g),a(f),a(v),a(I),a(r),a(J),a(m),a(b),a(u),a(G),a($),a(p),a(y),a(M),a(T)),a(i),k(o,t),k(c,t),k(d,t)}}}const K='{"title":"Using TGI with Nvidia GPUs","local":"using-tgi-with-nvidia-gpus","sections":[],"depth":1}';function tt(B){return N(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class lt extends S{constructor(i){super(),E(this,i,tt,q,H,{})}}export{lt as component};
