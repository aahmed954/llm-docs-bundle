import{s as ya,n as fa,o as ba}from"../chunks/scheduler.362310b7.js";import{S as va,i as wa,g as i,s as n,r as c,m as R,H as F,A as za,h as p,f as t,c as l,j as Es,u,x as m,n as D,B as O,k as oa,y as N,a as e,v as g,d,t as y,w as f}from"../chunks/index.57dfc70d.js";import{C as K}from"../chunks/CodeBlock.5d40996c.js";import{H as Us,E as Ta}from"../chunks/index.fa158b42.js";function xa(Vs){let h,ss,S,as,b,ts,v,Ys="TGI offers many quantization schemes to run LLMs effectively and fast based on your use-case. TGI supports GPTQ, AWQ, bits-and-bytes, EETQ, Marlin, EXL2 and fp8 quantization.",es,w,Ns="To leverage GPTQ, AWQ, Marlin and EXL2 quants, you must provide pre-quantized weights. Whereas for bits-and-bytes, EETQ and fp8, weights are quantized by TGI on the fly.",ns,z,Ss="We recommend using the official quantization scripts for creating your quants:",ls,T,Bs='<li><a href="https://github.com/casper-hansen/AutoAWQ/blob/main/examples/quantize.py" rel="nofollow">AWQ</a></li> <li><a href="https://github.com/AutoGPTQ/AutoGPTQ/blob/main/examples/quantization/basic_usage.py" rel="nofollow">GPTQ/ Marlin</a></li> <li><a href="https://github.com/turboderp/exllamav2/blob/master/doc/convert.md" rel="nofollow">EXL2</a></li>',is,x,Rs="For on-the-fly quantization you simply need to pass one of the supported quantization types and TGI takes care of the rest.",ps,M,ms,$,Fs="bitsandbytes is a library used to apply 8-bit and 4-bit quantization to models. Unlike GPTQ quantization, bitsandbytes doesnâ€™t require a calibration dataset or any post-processing â€“ weights are automatically quantized on load. However, inference with bitsandbytes is slower than GPTQ or FP16 precision.",rs,q,Ds=`8-bit quantization enables multi-billion parameter scale models to fit in smaller hardware without degrading performance too much.
In TGI, you can use 8-bit quantization by adding <code>--quantize bitsandbytes</code> like below ðŸ‘‡`,os,G,hs,L,Os="4-bit quantization is also possible with bitsandbytes. You can choose one of the following 4-bit data types: 4-bit float (<code>fp4</code>), or 4-bit <code>NormalFloat</code> (<code>nf4</code>). These data types were introduced in the context of parameter-efficient fine-tuning, but you can apply them for inference by automatically converting the model weights on load.",cs,W,Ks="In TGI, you can use 4-bit quantization by adding <code>--quantize bitsandbytes-nf4</code> or <code>--quantize bitsandbytes-fp4</code> like below ðŸ‘‡",us,_,gs,k,sa='You can get more information about 8-bit quantization by reading this <a href="https://huggingface.co/blog/hf-bitsandbytes-integration" rel="nofollow">blog post</a>, and 4-bit quantization by reading <a href="https://huggingface.co/blog/4bit-transformers-bitsandbytes" rel="nofollow">this blog post</a>.',ds,Z,aa="Similarly you can use pass you can pass <code>--quantize eetq</code> or <code>--quantize fp8</code> for respective quantization schemes.",ys,J,ta="In addition to this, TGI allows creating GPTQ quants directly by passing the model weights and a calibration dataset.",fs,C,bs,I,ea="GPTQ is a post-training quantization method to make the model smaller. It quantizes the layers by finding a compressed version of that weight, that will yield a minimum mean squared error like below ðŸ‘‡",vs,r,As,ws,ha='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>',zs,Ts,ca='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">W_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>',xs,Ms,ua='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">X_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>',$s,qs,ga='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace linebreak="newline"></mspace><mi>h</mi><mi>a</mi><mi>t</mi><msub><mi>W</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\\\\hat{W}_{l}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">ha</span><span class="mord mathnormal">t</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>',Gs,Ls,da='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msup><msub><mover accent="true"><mi>W</mi><mo>^</mo></mover><mi>l</mi></msub><mo lspace="0em" rspace="0em">âˆ—</mo></msup><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><msub><mi>n</mi><mover accent="true"><msub><mi>W</mi><mi>l</mi></msub><mo>^</mo></mover></msub><mi mathvariant="normal">âˆ£</mi><mi mathvariant="normal">âˆ£</mi><msub><mi>W</mi><mi>l</mi></msub><mi>X</mi><mo>âˆ’</mo><msub><mover accent="true"><mi>W</mi><mo>^</mo></mover><mi>l</mi></msub><mi>X</mi><mi mathvariant="normal">âˆ£</mi><msubsup><mi mathvariant="normal">âˆ£</mi><mn>2</mn><mn>2</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">({\\hat{W}_{l}}^{*} = argmin_{\\hat{W_{l}}} ||W_{l}X-\\hat{W}_{l}X||^{2}_{2})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2754em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0254em;"><span style="top:-3.3997em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">âˆ—</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1738em;vertical-align:-0.4238em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">mi</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3821em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span><span style="top:-2.9523em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.4238em;"><span></span></span></span></span></span></span><span class="mord">âˆ£âˆ£</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">âˆ’</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1968em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord">âˆ£</span><span class="mord"><span class="mord">âˆ£</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>',Ws,P,na='TGI allows you to both run an already GPTQ quantized model (see available models <a href="https://huggingface.co/models?search=gptq" rel="nofollow">here</a>) or quantize a model of your choice using quantization script. You can run a quantized model by simply passing â€”quantize like below ðŸ‘‡',_s,j,ks,Q,la='Note that TGIâ€™s GPTQ implementation doesnâ€™t use <a href="https://github.com/PanQiWei/AutoGPTQ" rel="nofollow">AutoGPTQ</a> under the hood. However, models quantized using AutoGPTQ or Optimum can still be served by TGI.',Zs,H,ia="To quantize a given model using GPTQ with a calibration dataset, simply run",Js,X,Cs,A,pa="This will create a new directory with the quantized files which you can use with,",Is,E,Ps,U,ma="You can learn more about the quantization options by running <code>text-generation-server quantize --help</code>.",js,V,ra=`If you wish to do more with GPTQ models (e.g. train an adapter on top), you can read about transformers GPTQ integration <a href="https://huggingface.co/blog/gptq-integration" rel="nofollow">here</a>.
You can learn more about GPTQ from the <a href="https://arxiv.org/pdf/2210.17323.pdf" rel="nofollow">paper</a>.`,Qs,Y,Hs,B,Xs;return b=new Us({props:{title:"Quantization",local:"quantization",headingTag:"h1"}}),M=new Us({props:{title:"Quantization with bitsandbytes, EETQ & fp8",local:"quantization-with-bitsandbytes-eetq--fp8",headingTag:"h2"}}),G=new K({props:{code:"ZG9ja2VyJTIwcnVuJTIwLS1ncHVzJTIwYWxsJTIwLS1zaG0tc2l6ZSUyMDFnJTIwLXAlMjA4MDgwJTNBODAlMjAtdiUyMCUyNHZvbHVtZSUzQSUyRmRhdGElMjBnaGNyLmlvJTJGaHVnZ2luZ2ZhY2UlMkZ0ZXh0LWdlbmVyYXRpb24taW5mZXJlbmNlJTNBMy4zLjElMjAtLW1vZGVsLWlkJTIwJTI0bW9kZWwlMjAtLXF1YW50aXplJTIwYml0c2FuZGJ5dGVz",highlighted:'docker run --gpus all --shm-size 1g -p 8080:80 -v <span class="hljs-variable">$volume</span>:/data ghcr.io/huggingface/text-generation-inference:3.3.1 --model-id <span class="hljs-variable">$model</span> --quantize bitsandbytes',wrap:!1}}),_=new K({props:{code:"ZG9ja2VyJTIwcnVuJTIwLS1ncHVzJTIwYWxsJTIwLS1zaG0tc2l6ZSUyMDFnJTIwLXAlMjA4MDgwJTNBODAlMjAtdiUyMCUyNHZvbHVtZSUzQSUyRmRhdGElMjBnaGNyLmlvJTJGaHVnZ2luZ2ZhY2UlMkZ0ZXh0LWdlbmVyYXRpb24taW5mZXJlbmNlJTNBMy4zLjElMjAtLW1vZGVsLWlkJTIwJTI0bW9kZWwlMjAtLXF1YW50aXplJTIwYml0c2FuZGJ5dGVzLW5mNA==",highlighted:'docker run --gpus all --shm-size 1g -p 8080:80 -v <span class="hljs-variable">$volume</span>:/data ghcr.io/huggingface/text-generation-inference:3.3.1 --model-id <span class="hljs-variable">$model</span> --quantize bitsandbytes-nf4',wrap:!1}}),C=new Us({props:{title:"Quantization with GPTQ",local:"quantization-with-gptq",headingTag:"h2"}}),j=new K({props:{code:"ZG9ja2VyJTIwcnVuJTIwLS1ncHVzJTIwYWxsJTIwLS1zaG0tc2l6ZSUyMDFnJTIwLXAlMjA4MDgwJTNBODAlMjAtdiUyMCUyNHZvbHVtZSUzQSUyRmRhdGElMjBnaGNyLmlvJTJGaHVnZ2luZ2ZhY2UlMkZ0ZXh0LWdlbmVyYXRpb24taW5mZXJlbmNlJTNBMy4zLjElMjAtLW1vZGVsLWlkJTIwJTI0bW9kZWwlMjAtLXF1YW50aXplJTIwZ3B0cQ==",highlighted:'docker run --gpus all --shm-size 1g -p 8080:80 -v <span class="hljs-variable">$volume</span>:/data ghcr.io/huggingface/text-generation-inference:3.3.1 --model-id <span class="hljs-variable">$model</span> --quantize gptq',wrap:!1}}),X=new K({props:{code:"dGV4dC1nZW5lcmF0aW9uLXNlcnZlciUyMHF1YW50aXplJTIwdGlpdWFlJTJGZmFsY29uLTQwYiUyMCUyRmRhdGElMkZmYWxjb24tNDBiLWdwdHElMEElMjMlMjBBZGQlMjAtLXVwbG9hZC10by1tb2RlbC1pZCUyME1ZVVNFUk5BTUUlMkZmYWxjb24tNDBiJTIwdG8lMjBwdXNoJTIwdGhlJTIwY3JlYXRlZCUyMG1vZGVsJTIwdG8lMjB0aGUlMjBodWIlMjBkaXJlY3RseQ==",highlighted:`text-generation-server quantize tiiuae/falcon-40b /data/falcon-40b-gptq
<span class="hljs-comment"># Add --upload-to-model-id MYUSERNAME/falcon-40b to push the created model to the hub directly</span>`,wrap:!1}}),E=new K({props:{code:"dGV4dC1nZW5lcmF0aW9uLWxhdW5jaGVyJTIwLS1tb2RlbC1pZCUyMCUyRmRhdGElMkZmYWxjb24tNDBiLWdwdHElMkYlMjAtLXNoYXJkZWQlMjB0cnVlJTIwLS1udW0tc2hhcmQlMjAyJTIwLS1xdWFudGl6ZSUyMGdwdHE=",highlighted:'text-generation-launcher --model-id /data/falcon-40b-gptq/ --sharded <span class="hljs-literal">true</span> --num-shard 2 --quantize gptq',wrap:!1}}),Y=new Ta({props:{source:"https://github.com/huggingface/text-generation-inference/blob/main/docs/source/conceptual/quantization.md"}}),{c(){h=i("meta"),ss=n(),S=i("p"),as=n(),c(b.$$.fragment),ts=n(),v=i("p"),v.textContent=Ys,es=n(),w=i("p"),w.textContent=Ns,ns=n(),z=i("p"),z.textContent=Ss,ls=n(),T=i("ol"),T.innerHTML=Bs,is=n(),x=i("p"),x.textContent=Rs,ps=n(),c(M.$$.fragment),ms=n(),$=i("p"),$.textContent=Fs,rs=n(),q=i("p"),q.innerHTML=Ds,os=n(),c(G.$$.fragment),hs=n(),L=i("p"),L.innerHTML=Os,cs=n(),W=i("p"),W.innerHTML=Ks,us=n(),c(_.$$.fragment),gs=n(),k=i("p"),k.innerHTML=sa,ds=n(),Z=i("p"),Z.innerHTML=aa,ys=n(),J=i("p"),J.textContent=ta,fs=n(),c(C.$$.fragment),bs=n(),I=i("p"),I.textContent=ea,vs=n(),r=i("p"),As=R("Given a layer"),ws=new F(!1),zs=R(" with weight matrix"),Ts=new F(!1),xs=R(" and layer input"),Ms=new F(!1),$s=R(", find quantized weight"),qs=new F(!1),Gs=R(`:
`),Ls=new F(!1),Ws=n(),P=i("p"),P.innerHTML=na,_s=n(),c(j.$$.fragment),ks=n(),Q=i("p"),Q.innerHTML=la,Zs=n(),H=i("p"),H.textContent=ia,Js=n(),c(X.$$.fragment),Cs=n(),A=i("p"),A.textContent=pa,Is=n(),c(E.$$.fragment),Ps=n(),U=i("p"),U.innerHTML=ma,js=n(),V=i("p"),V.innerHTML=ra,Qs=n(),c(Y.$$.fragment),Hs=n(),B=i("p"),this.h()},l(s){const a=za("svelte-u9bgzb",document.head);h=p(a,"META",{name:!0,content:!0}),a.forEach(t),ss=l(s),S=p(s,"P",{}),Es(S).forEach(t),as=l(s),u(b.$$.fragment,s),ts=l(s),v=p(s,"P",{"data-svelte-h":!0}),m(v)!=="svelte-1uhon0f"&&(v.textContent=Ys),es=l(s),w=p(s,"P",{"data-svelte-h":!0}),m(w)!=="svelte-m25niz"&&(w.textContent=Ns),ns=l(s),z=p(s,"P",{"data-svelte-h":!0}),m(z)!=="svelte-1uq49rw"&&(z.textContent=Ss),ls=l(s),T=p(s,"OL",{"data-svelte-h":!0}),m(T)!=="svelte-1fjxs52"&&(T.innerHTML=Bs),is=l(s),x=p(s,"P",{"data-svelte-h":!0}),m(x)!=="svelte-dlxq44"&&(x.textContent=Rs),ps=l(s),u(M.$$.fragment,s),ms=l(s),$=p(s,"P",{"data-svelte-h":!0}),m($)!=="svelte-aqqk8a"&&($.textContent=Fs),rs=l(s),q=p(s,"P",{"data-svelte-h":!0}),m(q)!=="svelte-ktr7x0"&&(q.innerHTML=Ds),os=l(s),u(G.$$.fragment,s),hs=l(s),L=p(s,"P",{"data-svelte-h":!0}),m(L)!=="svelte-1kt0l3g"&&(L.innerHTML=Os),cs=l(s),W=p(s,"P",{"data-svelte-h":!0}),m(W)!=="svelte-113ygv"&&(W.innerHTML=Ks),us=l(s),u(_.$$.fragment,s),gs=l(s),k=p(s,"P",{"data-svelte-h":!0}),m(k)!=="svelte-bx1jaz"&&(k.innerHTML=sa),ds=l(s),Z=p(s,"P",{"data-svelte-h":!0}),m(Z)!=="svelte-17aol0b"&&(Z.innerHTML=aa),ys=l(s),J=p(s,"P",{"data-svelte-h":!0}),m(J)!=="svelte-1likkzk"&&(J.textContent=ta),fs=l(s),u(C.$$.fragment,s),bs=l(s),I=p(s,"P",{"data-svelte-h":!0}),m(I)!=="svelte-aix1yq"&&(I.textContent=ea),vs=l(s),r=p(s,"P",{});var o=Es(r);As=D(o,"Given a layer"),ws=O(o,!1),zs=D(o," with weight matrix"),Ts=O(o,!1),xs=D(o," and layer input"),Ms=O(o,!1),$s=D(o,", find quantized weight"),qs=O(o,!1),Gs=D(o,`:
`),Ls=O(o,!1),o.forEach(t),Ws=l(s),P=p(s,"P",{"data-svelte-h":!0}),m(P)!=="svelte-14up0yw"&&(P.innerHTML=na),_s=l(s),u(j.$$.fragment,s),ks=l(s),Q=p(s,"P",{"data-svelte-h":!0}),m(Q)!=="svelte-14lnxb8"&&(Q.innerHTML=la),Zs=l(s),H=p(s,"P",{"data-svelte-h":!0}),m(H)!=="svelte-1drv0r"&&(H.textContent=ia),Js=l(s),u(X.$$.fragment,s),Cs=l(s),A=p(s,"P",{"data-svelte-h":!0}),m(A)!=="svelte-f1w88s"&&(A.textContent=pa),Is=l(s),u(E.$$.fragment,s),Ps=l(s),U=p(s,"P",{"data-svelte-h":!0}),m(U)!=="svelte-32p5y6"&&(U.innerHTML=ma),js=l(s),V=p(s,"P",{"data-svelte-h":!0}),m(V)!=="svelte-a14ru9"&&(V.innerHTML=ra),Qs=l(s),u(Y.$$.fragment,s),Hs=l(s),B=p(s,"P",{}),Es(B).forEach(t),this.h()},h(){oa(h,"name","hf:doc:metadata"),oa(h,"content",Ma),ws.a=zs,Ts.a=xs,Ms.a=$s,qs.a=Gs,Ls.a=null},m(s,a){N(document.head,h),e(s,ss,a),e(s,S,a),e(s,as,a),g(b,s,a),e(s,ts,a),e(s,v,a),e(s,es,a),e(s,w,a),e(s,ns,a),e(s,z,a),e(s,ls,a),e(s,T,a),e(s,is,a),e(s,x,a),e(s,ps,a),g(M,s,a),e(s,ms,a),e(s,$,a),e(s,rs,a),e(s,q,a),e(s,os,a),g(G,s,a),e(s,hs,a),e(s,L,a),e(s,cs,a),e(s,W,a),e(s,us,a),g(_,s,a),e(s,gs,a),e(s,k,a),e(s,ds,a),e(s,Z,a),e(s,ys,a),e(s,J,a),e(s,fs,a),g(C,s,a),e(s,bs,a),e(s,I,a),e(s,vs,a),e(s,r,a),N(r,As),ws.m(ha,r),N(r,zs),Ts.m(ca,r),N(r,xs),Ms.m(ua,r),N(r,$s),qs.m(ga,r),N(r,Gs),Ls.m(da,r),e(s,Ws,a),e(s,P,a),e(s,_s,a),g(j,s,a),e(s,ks,a),e(s,Q,a),e(s,Zs,a),e(s,H,a),e(s,Js,a),g(X,s,a),e(s,Cs,a),e(s,A,a),e(s,Is,a),g(E,s,a),e(s,Ps,a),e(s,U,a),e(s,js,a),e(s,V,a),e(s,Qs,a),g(Y,s,a),e(s,Hs,a),e(s,B,a),Xs=!0},p:fa,i(s){Xs||(d(b.$$.fragment,s),d(M.$$.fragment,s),d(G.$$.fragment,s),d(_.$$.fragment,s),d(C.$$.fragment,s),d(j.$$.fragment,s),d(X.$$.fragment,s),d(E.$$.fragment,s),d(Y.$$.fragment,s),Xs=!0)},o(s){y(b.$$.fragment,s),y(M.$$.fragment,s),y(G.$$.fragment,s),y(_.$$.fragment,s),y(C.$$.fragment,s),y(j.$$.fragment,s),y(X.$$.fragment,s),y(E.$$.fragment,s),y(Y.$$.fragment,s),Xs=!1},d(s){s&&(t(ss),t(S),t(as),t(ts),t(v),t(es),t(w),t(ns),t(z),t(ls),t(T),t(is),t(x),t(ps),t(ms),t($),t(rs),t(q),t(os),t(hs),t(L),t(cs),t(W),t(us),t(gs),t(k),t(ds),t(Z),t(ys),t(J),t(fs),t(bs),t(I),t(vs),t(r),t(Ws),t(P),t(_s),t(ks),t(Q),t(Zs),t(H),t(Js),t(Cs),t(A),t(Is),t(Ps),t(U),t(js),t(V),t(Qs),t(Hs),t(B)),t(h),f(b,s),f(M,s),f(G,s),f(_,s),f(C,s),f(j,s),f(X,s),f(E,s),f(Y,s)}}}const Ma='{"title":"Quantization","local":"quantization","sections":[{"title":"Quantization with bitsandbytes, EETQ & fp8","local":"quantization-with-bitsandbytes-eetq--fp8","sections":[],"depth":2},{"title":"Quantization with GPTQ","local":"quantization-with-gptq","sections":[],"depth":2}],"depth":1}';function $a(Vs){return ba(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _a extends va{constructor(h){super(),wa(this,h,$a,xa,ya,{})}}export{_a as component};
