
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="ollama 的中英文文档，中文文档由 llamafactory.cn 翻译">
      
      
      
      
        <link rel="prev" href="https://ollama.readthedocs.io/en/">
      
      
        <link rel="next" href="https://ollama.readthedocs.io/en/examples/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Quickstart - Ollama English Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <script async type="text/javascript" src="../../_/static/javascript/readthedocs-addons.js"></script><meta name="readthedocs-project-slug" content="ollama" /><meta name="readthedocs-version-slug" content="latest" /><meta name="readthedocs-resolver-filename" content="/en/quickstart/" /><meta name="readthedocs-http-status" content="200" /></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="index.html#ollama" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://ollama.readthedocs.io/en/" title="Ollama English Documentation" class="md-header__button md-logo" aria-label="Ollama English Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ollama English Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Quickstart
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换至深色模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至深色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换至浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="https://ollama.readthedocs.io/quickstart/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="index.html" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://ollama.readthedocs.io/en/" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="index.html" class="md-tabs__link">
          
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="https://ollama.readthedocs.io/en/api/" class="md-tabs__link">
          
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="https://ollama.readthedocs.io/en/troubleshooting/" class="md-tabs__link">
          
  
  Resources

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="https://ollama.readthedocs.io/en/gpu_source/" class="md-tabs__link">
          
  
  GPU Resources

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://ollama.readthedocs.io/en/" title="Ollama English Documentation" class="md-nav__button md-logo" aria-label="Ollama English Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Ollama English Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="index.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="index.html#macos" class="md-nav__link">
    <span class="md-ellipsis">
      macOS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#windows" class="md-nav__link">
    <span class="md-ellipsis">
      Windows
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#linux" class="md-nav__link">
    <span class="md-ellipsis">
      Linux
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#docker" class="md-nav__link">
    <span class="md-ellipsis">
      Docker
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Libraries
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#quickstart" class="md-nav__link">
    <span class="md-ellipsis">
      Quickstart
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#model-library" class="md-nav__link">
    <span class="md-ellipsis">
      Model library
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#customize-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Customize a model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Customize a model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#import-from-gguf" class="md-nav__link">
    <span class="md-ellipsis">
      Import from GGUF
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#import-from-pytorch-or-safetensors" class="md-nav__link">
    <span class="md-ellipsis">
      Import from PyTorch or Safetensors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#customize-a-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      Customize a prompt
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#cli-reference" class="md-nav__link">
    <span class="md-ellipsis">
      CLI Reference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLI Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#create-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Create a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#pull-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Pull a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#remove-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Remove a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#copy-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Copy a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#multiline-input" class="md-nav__link">
    <span class="md-ellipsis">
      Multiline input
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#multimodal-models" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#pass-the-prompt-as-an-argument" class="md-nav__link">
    <span class="md-ellipsis">
      Pass the prompt as an argument
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#show-model-information" class="md-nav__link">
    <span class="md-ellipsis">
      Show model information
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#list-models-on-your-computer" class="md-nav__link">
    <span class="md-ellipsis">
      List models on your computer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#list-which-models-are-currently-loaded" class="md-nav__link">
    <span class="md-ellipsis">
      List which models are currently loaded
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#stop-a-model-which-is-currently-running" class="md-nav__link">
    <span class="md-ellipsis">
      Stop a model which is currently running
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#start-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      Start Ollama
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#building" class="md-nav__link">
    <span class="md-ellipsis">
      Building
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#running-local-builds" class="md-nav__link">
    <span class="md-ellipsis">
      Running local builds
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#rest-api" class="md-nav__link">
    <span class="md-ellipsis">
      REST API
    </span>
  </a>
  
    <nav class="md-nav" aria-label="REST API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#generate-a-response" class="md-nav__link">
    <span class="md-ellipsis">
      Generate a response
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#chat-with-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Chat with a model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#community-integrations" class="md-nav__link">
    <span class="md-ellipsis">
      Community Integrations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Community Integrations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#web-desktop" class="md-nav__link">
    <span class="md-ellipsis">
      Web &amp; Desktop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#cloud" class="md-nav__link">
    <span class="md-ellipsis">
      Cloud
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#terminal" class="md-nav__link">
    <span class="md-ellipsis">
      Terminal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#apple-vision-pro" class="md-nav__link">
    <span class="md-ellipsis">
      Apple Vision Pro
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#database" class="md-nav__link">
    <span class="md-ellipsis">
      Database
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#package-managers" class="md-nav__link">
    <span class="md-ellipsis">
      Package managers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#libraries_1" class="md-nav__link">
    <span class="md-ellipsis">
      Libraries
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#mobile" class="md-nav__link">
    <span class="md-ellipsis">
      Mobile
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#extensions-plugins" class="md-nav__link">
    <span class="md-ellipsis">
      Extensions &amp; Plugins
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#supported-backends" class="md-nav__link">
    <span class="md-ellipsis">
      Supported backends
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/examples/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Examples
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/import/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Importing models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/linux/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Linux Documentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/windows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Windows Documentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/docker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docker Documentation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/modelfile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modelfile Reference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/openai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenAI Compatibility
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Resources
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Resources
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/troubleshooting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Troubleshooting Guide
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Development guide
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GPU Resources
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            GPU Resources
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://ollama.readthedocs.io/en/gpu_source/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ollama x UCloud CompShare
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="index.html#macos" class="md-nav__link">
    <span class="md-ellipsis">
      macOS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#windows" class="md-nav__link">
    <span class="md-ellipsis">
      Windows
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#linux" class="md-nav__link">
    <span class="md-ellipsis">
      Linux
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#docker" class="md-nav__link">
    <span class="md-ellipsis">
      Docker
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Libraries
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#quickstart" class="md-nav__link">
    <span class="md-ellipsis">
      Quickstart
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#model-library" class="md-nav__link">
    <span class="md-ellipsis">
      Model library
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#customize-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Customize a model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Customize a model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#import-from-gguf" class="md-nav__link">
    <span class="md-ellipsis">
      Import from GGUF
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#import-from-pytorch-or-safetensors" class="md-nav__link">
    <span class="md-ellipsis">
      Import from PyTorch or Safetensors
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#customize-a-prompt" class="md-nav__link">
    <span class="md-ellipsis">
      Customize a prompt
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#cli-reference" class="md-nav__link">
    <span class="md-ellipsis">
      CLI Reference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CLI Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#create-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Create a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#pull-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Pull a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#remove-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Remove a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#copy-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Copy a model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#multiline-input" class="md-nav__link">
    <span class="md-ellipsis">
      Multiline input
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#multimodal-models" class="md-nav__link">
    <span class="md-ellipsis">
      Multimodal models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#pass-the-prompt-as-an-argument" class="md-nav__link">
    <span class="md-ellipsis">
      Pass the prompt as an argument
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#show-model-information" class="md-nav__link">
    <span class="md-ellipsis">
      Show model information
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#list-models-on-your-computer" class="md-nav__link">
    <span class="md-ellipsis">
      List models on your computer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#list-which-models-are-currently-loaded" class="md-nav__link">
    <span class="md-ellipsis">
      List which models are currently loaded
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#stop-a-model-which-is-currently-running" class="md-nav__link">
    <span class="md-ellipsis">
      Stop a model which is currently running
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#start-ollama" class="md-nav__link">
    <span class="md-ellipsis">
      Start Ollama
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#building" class="md-nav__link">
    <span class="md-ellipsis">
      Building
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Building">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#running-local-builds" class="md-nav__link">
    <span class="md-ellipsis">
      Running local builds
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#rest-api" class="md-nav__link">
    <span class="md-ellipsis">
      REST API
    </span>
  </a>
  
    <nav class="md-nav" aria-label="REST API">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#generate-a-response" class="md-nav__link">
    <span class="md-ellipsis">
      Generate a response
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#chat-with-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Chat with a model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="index.html#community-integrations" class="md-nav__link">
    <span class="md-ellipsis">
      Community Integrations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Community Integrations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="index.html#web-desktop" class="md-nav__link">
    <span class="md-ellipsis">
      Web &amp; Desktop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#cloud" class="md-nav__link">
    <span class="md-ellipsis">
      Cloud
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#terminal" class="md-nav__link">
    <span class="md-ellipsis">
      Terminal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#apple-vision-pro" class="md-nav__link">
    <span class="md-ellipsis">
      Apple Vision Pro
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#database" class="md-nav__link">
    <span class="md-ellipsis">
      Database
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#package-managers" class="md-nav__link">
    <span class="md-ellipsis">
      Package managers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#libraries_1" class="md-nav__link">
    <span class="md-ellipsis">
      Libraries
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#mobile" class="md-nav__link">
    <span class="md-ellipsis">
      Mobile
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#extensions-plugins" class="md-nav__link">
    <span class="md-ellipsis">
      Extensions &amp; Plugins
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="index.html#supported-backends" class="md-nav__link">
    <span class="md-ellipsis">
      Supported backends
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
  
  <!-- <div class="ad-container" style="margin: 2rem 0; padding: 1rem; background: #4CAF50; color: white; border-radius: 4px;">
    <a href="https://www.llamafactory.cn" style="color: inherit; text-decoration: none; display: block; text-align: center;">
      🚀 广告位招租 | 立即咨询
    </a>
    
  </div> -->
  <!-- <img src="http://localhost:5174/three-party/ollama-ucloud.png"
    style="cursor: pointer; margin-bottom: 12px;"
    onclick="window.open('https://www.compshare.cn/?ytag=GPU_web_LlamaFactory', '_blank')"
  /> -->
  <!-- <img src="https://www.llamafactory.cn/three-party/ollama-ucloud.png"
    style="cursor: pointer; margin-bottom: 8px;"
    onclick="fetch('https://api.llamafactory.cn/paper/view', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            credentials: 'include',
            body: JSON.stringify({ id: 1 })
          }); window.open('https://www.compshare.cn/?ytag=GPU_web_ollama', '_blank')"
  /> -->
  
                  


<div align="center">
 <img alt="ollama" height="200px" src="https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7">
</div>

<h1 id="ollama">Ollama</h1>
<p><a href="https://discord.gg/ollama"><img alt="Discord" src="https://dcbadge.vercel.app/api/server/ollama?style=flat&amp;compact=true" /></a></p>
<p>Get up and running with large language models.</p>
<h3 id="macos">macOS</h3>
<p><a href="https://ollama.com/download/Ollama-darwin.zip">Download</a></p>
<h3 id="windows">Windows</h3>
<p><a href="https://ollama.com/download/OllamaSetup.exe">Download</a></p>
<h3 id="linux">Linux</h3>
<pre><code>curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<p><a href="https://github.com/ollama/ollama/blob/main/docs/linux.md">Manual install instructions</a></p>
<h3 id="docker">Docker</h3>
<p>The official <a href="https://hub.docker.com/r/ollama/ollama">Ollama Docker image</a> <code>ollama/ollama</code> is available on Docker Hub.</p>
<h3 id="libraries">Libraries</h3>
<ul>
<li><a href="https://github.com/ollama/ollama-python">ollama-python</a></li>
<li><a href="https://github.com/ollama/ollama-js">ollama-js</a></li>
</ul>
<h2 id="quickstart">Quickstart</h2>
<p>To run and chat with <a href="https://ollama.com/library/llama3.2">Llama 3.2</a>:</p>
<pre><code>ollama run llama3.2
</code></pre>
<h2 id="model-library">Model library</h2>
<p>Ollama supports a list of models available on <a href="https://ollama.com/library" title="ollama model library">ollama.com/library</a></p>
<p>Here are some example models that can be downloaded:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Parameters</th>
<th>Size</th>
<th>Download</th>
</tr>
</thead>
<tbody>
<tr>
<td>Llama 3.2</td>
<td>3B</td>
<td>2.0GB</td>
<td><code>ollama run llama3.2</code></td>
</tr>
<tr>
<td>Llama 3.2</td>
<td>1B</td>
<td>1.3GB</td>
<td><code>ollama run llama3.2:1b</code></td>
</tr>
<tr>
<td>Llama 3.2 Vision</td>
<td>11B</td>
<td>7.9GB</td>
<td><code>ollama run llama3.2-vision</code></td>
</tr>
<tr>
<td>Llama 3.2 Vision</td>
<td>90B</td>
<td>55GB</td>
<td><code>ollama run llama3.2-vision:90b</code></td>
</tr>
<tr>
<td>Llama 3.1</td>
<td>8B</td>
<td>4.7GB</td>
<td><code>ollama run llama3.1</code></td>
</tr>
<tr>
<td>Llama 3.1</td>
<td>70B</td>
<td>40GB</td>
<td><code>ollama run llama3.1:70b</code></td>
</tr>
<tr>
<td>Llama 3.1</td>
<td>405B</td>
<td>231GB</td>
<td><code>ollama run llama3.1:405b</code></td>
</tr>
<tr>
<td>Phi 3 Mini</td>
<td>3.8B</td>
<td>2.3GB</td>
<td><code>ollama run phi3</code></td>
</tr>
<tr>
<td>Phi 3 Medium</td>
<td>14B</td>
<td>7.9GB</td>
<td><code>ollama run phi3:medium</code></td>
</tr>
<tr>
<td>Gemma 2</td>
<td>2B</td>
<td>1.6GB</td>
<td><code>ollama run gemma2:2b</code></td>
</tr>
<tr>
<td>Gemma 2</td>
<td>9B</td>
<td>5.5GB</td>
<td><code>ollama run gemma2</code></td>
</tr>
<tr>
<td>Gemma 2</td>
<td>27B</td>
<td>16GB</td>
<td><code>ollama run gemma2:27b</code></td>
</tr>
<tr>
<td>Mistral</td>
<td>7B</td>
<td>4.1GB</td>
<td><code>ollama run mistral</code></td>
</tr>
<tr>
<td>Moondream 2</td>
<td>1.4B</td>
<td>829MB</td>
<td><code>ollama run moondream</code></td>
</tr>
<tr>
<td>Neural Chat</td>
<td>7B</td>
<td>4.1GB</td>
<td><code>ollama run neural-chat</code></td>
</tr>
<tr>
<td>Starling</td>
<td>7B</td>
<td>4.1GB</td>
<td><code>ollama run starling-lm</code></td>
</tr>
<tr>
<td>Code Llama</td>
<td>7B</td>
<td>3.8GB</td>
<td><code>ollama run codellama</code></td>
</tr>
<tr>
<td>Llama 2 Uncensored</td>
<td>7B</td>
<td>3.8GB</td>
<td><code>ollama run llama2-uncensored</code></td>
</tr>
<tr>
<td>LLaVA</td>
<td>7B</td>
<td>4.5GB</td>
<td><code>ollama run llava</code></td>
</tr>
<tr>
<td>Solar</td>
<td>10.7B</td>
<td>6.1GB</td>
<td><code>ollama run solar</code></td>
</tr>
</tbody>
</table>
<blockquote>
<p>[!NOTE]
You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.</p>
</blockquote>
<h2 id="customize-a-model">Customize a model</h2>
<h3 id="import-from-gguf">Import from GGUF</h3>
<p>Ollama supports importing GGUF models in the Modelfile:</p>
<ol>
<li>Create a file named <code>Modelfile</code>, with a <code>FROM</code> instruction with the local filepath to the model you want to import.</li>
</ol>
<p><code>FROM ./vicuna-33b.Q4_0.gguf</code></p>
<ol>
<li>Create the model in Ollama</li>
</ol>
<p><code>ollama create example -f Modelfile</code></p>
<ol>
<li>Run the model</li>
</ol>
<p><code>ollama run example</code></p>
<h3 id="import-from-pytorch-or-safetensors">Import from PyTorch or Safetensors</h3>
<p>See the <a href="https://ollama.readthedocs.io/en/import/">guide</a> on importing models for more information.</p>
<h3 id="customize-a-prompt">Customize a prompt</h3>
<p>Models from the Ollama library can be customized with a prompt. For example, to customize the <code>llama3.2</code> model:</p>
<pre><code>ollama pull llama3.2
</code></pre>
<p>Create a <code>Modelfile</code>:</p>
<pre><code>FROM llama3.2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM &quot;&quot;&quot;
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
&quot;&quot;&quot;
</code></pre>
<p>Next, create and run the model:</p>
<pre><code>ollama create mario -f ./Modelfile
ollama run mario
&gt;&gt;&gt; hi
Hello! It's your friend Mario.
</code></pre>
<p>For more examples, see the <a href="https://github.com/ollama/ollama/tree/main/examples">examples</a> directory. For more information on working with a Modelfile, see the <a href="https://ollama.readthedocs.io/en/modelfile/">Modelfile</a> documentation.</p>
<h2 id="cli-reference">CLI Reference</h2>
<h3 id="create-a-model">Create a model</h3>
<p><code>ollama create</code> is used to create a model from a Modelfile.</p>
<pre><code>ollama create mymodel -f ./Modelfile
</code></pre>
<h3 id="pull-a-model">Pull a model</h3>
<pre><code>ollama pull llama3.2
</code></pre>
<blockquote>
<p>This command can also be used to update a local model. Only the diff will be pulled.</p>
</blockquote>
<h3 id="remove-a-model">Remove a model</h3>
<pre><code>ollama rm llama3.2
</code></pre>
<h3 id="copy-a-model">Copy a model</h3>
<pre><code>ollama cp llama3.2 my-model
</code></pre>
<h3 id="multiline-input">Multiline input</h3>
<p>For multiline input, you can wrap text with <code>"""</code>:</p>
<pre><code>&gt;&gt;&gt; &quot;&quot;&quot;Hello,
... world!
... &quot;&quot;&quot;
I'm a basic program that prints the famous &quot;Hello, world!&quot; message to the console.
</code></pre>
<h3 id="multimodal-models">Multimodal models</h3>
<pre><code>ollama run llava &quot;What's in this image? /Users/jmorgan/Desktop/smile.png&quot;
The image features a yellow smiley face, which is likely the central focus of the picture.
</code></pre>
<h3 id="pass-the-prompt-as-an-argument">Pass the prompt as an argument</h3>
<pre><code>$ ollama run llama3.2 &quot;Summarize this file: $(cat README.md)&quot;
 Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.
</code></pre>
<h3 id="show-model-information">Show model information</h3>
<pre><code>ollama show llama3.2
</code></pre>
<h3 id="list-models-on-your-computer">List models on your computer</h3>
<pre><code>ollama list
</code></pre>
<h3 id="list-which-models-are-currently-loaded">List which models are currently loaded</h3>
<pre><code>ollama ps
</code></pre>
<h3 id="stop-a-model-which-is-currently-running">Stop a model which is currently running</h3>
<pre><code>ollama stop llama3.2
</code></pre>
<h3 id="start-ollama">Start Ollama</h3>
<p><code>ollama serve</code> is used when you want to start ollama without running the desktop application.</p>
<h2 id="building">Building</h2>
<p>See the <a href="https://github.com/ollama/ollama/blob/main/docs/development.md">developer guide</a></p>
<h3 id="running-local-builds">Running local builds</h3>
<p>Next, start the server:</p>
<pre><code>./ollama serve
</code></pre>
<p>Finally, in a separate shell, run a model:</p>
<pre><code>./ollama run llama3.2
</code></pre>
<h2 id="rest-api">REST API</h2>
<p>Ollama has a REST API for running and managing models.</p>
<h3 id="generate-a-response">Generate a response</h3>
<pre><code>curl http://localhost:11434/api/generate -d '{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;prompt&quot;:&quot;Why is the sky blue?&quot;
}'
</code></pre>
<h3 id="chat-with-a-model">Chat with a model</h3>
<pre><code>curl http://localhost:11434/api/chat -d '{
  &quot;model&quot;: &quot;llama3.2&quot;,
  &quot;messages&quot;: [
    { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;why is the sky blue?&quot; }
  ]
}'
</code></pre>
<p>See the <a href="https://ollama.readthedocs.io/en/api/">API documentation</a> for all endpoints.</p>
<h2 id="community-integrations">Community Integrations</h2>
<h3 id="web-desktop">Web &amp; Desktop</h3>
<ul>
<li><a href="https://github.com/open-webui/open-webui">Open WebUI</a></li>
<li><a href="https://github.com/AugustDev/enchanted">Enchanted (macOS native)</a></li>
<li><a href="https://github.com/fmaclen/hollama">Hollama</a></li>
<li><a href="https://github.com/ParisNeo/lollms-webui">Lollms-Webui</a></li>
<li><a href="https://github.com/danny-avila/LibreChat">LibreChat</a></li>
<li><a href="https://github.com/bionic-gpt/bionic-gpt">Bionic GPT</a></li>
<li><a href="https://github.com/rtcfirefly/ollama-ui">HTML UI</a></li>
<li><a href="https://github.com/jikkuatwork/saddle">Saddle</a></li>
<li><a href="https://github.com/ivanfioravanti/chatbot-ollama">Chatbot UI</a></li>
<li><a href="https://github.com/mckaywrigley/chatbot-ui">Chatbot UI v2</a></li>
<li><a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file">Typescript UI</a></li>
<li><a href="https://github.com/richawo/minimal-llm-ui">Minimalistic React UI for Ollama Models</a></li>
<li><a href="https://github.com/kevinhermawan/Ollamac">Ollamac</a></li>
<li><a href="https://github.com/enricoros/big-AGI/blob/main/docs/config-local-ollama.md">big-AGI</a></li>
<li><a href="https://github.com/cheshire-cat-ai/core">Cheshire Cat assistant framework</a></li>
<li><a href="https://github.com/semperai/amica">Amica</a></li>
<li><a href="https://github.com/BruceMacD/chatd">chatd</a></li>
<li><a href="https://github.com/kghandour/Ollama-SwiftUI">Ollama-SwiftUI</a></li>
<li><a href="https://github.com/langgenius/dify">Dify.AI</a></li>
<li><a href="https://mindmac.app">MindMac</a></li>
<li><a href="https://github.com/jakobhoeg/nextjs-ollama-llm-ui">NextJS Web Interface for Ollama</a></li>
<li><a href="https://msty.app">Msty</a></li>
<li><a href="https://github.com/Bin-Huang/Chatbox">Chatbox</a></li>
<li><a href="https://github.com/tgraupmann/WinForm_Ollama_Copilot">WinForm Ollama Copilot</a></li>
<li><a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web">NextChat</a> with <a href="https://docs.nextchat.dev/models/ollama">Get Started Doc</a></li>
<li><a href="https://github.com/mmo80/alpaca-webui">Alpaca WebUI</a></li>
<li><a href="https://github.com/enoch1118/ollamaGUI">OllamaGUI</a></li>
<li><a href="https://github.com/InternLM/OpenAOE">OpenAOE</a></li>
<li><a href="https://github.com/leonid20000/OdinRunes">Odin Runes</a></li>
<li><a href="https://github.com/mrdjohnson/llm-x">LLM-X</a> (Progressive Web App)</li>
<li><a href="https://github.com/Mintplex-Labs/anything-llm">AnythingLLM (Docker + MacOs/Windows/Linux native app)</a></li>
<li><a href="https://github.com/rapidarchitect/ollama_basic_chat">Ollama Basic Chat: Uses HyperDiv Reactive UI</a></li>
<li><a href="https://github.com/drazdra/ollama-chats">Ollama-chats RPG</a></li>
<li><a href="https://github.com/reid41/QA-Pilot">QA-Pilot</a> (Chat with Code Repository)</li>
<li><a href="https://github.com/sugarforever/chat-ollama">ChatOllama</a> (Open Source Chatbot based on Ollama with Knowledge Bases)</li>
<li><a href="https://github.com/Nagi-ovo/CRAG-Ollama-Chat">CRAG Ollama Chat</a> (Simple Web Search with Corrective RAG)</li>
<li><a href="https://github.com/infiniflow/ragflow">RAGFlow</a> (Open-source Retrieval-Augmented Generation engine based on deep document understanding)</li>
<li><a href="https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold">StreamDeploy</a> (LLM Application Scaffold)</li>
<li><a href="https://github.com/swuecho/chat">chat</a> (chat web app for teams)</li>
<li><a href="https://github.com/lobehub/lobe-chat">Lobe Chat</a> with <a href="https://lobehub.com/docs/self-hosting/examples/ollama">Integrating Doc</a></li>
<li><a href="https://github.com/datvodinh/rag-chatbot.git">Ollama RAG Chatbot</a> (Local Chat with multiple PDFs using Ollama and RAG)</li>
<li><a href="https://www.nurgo-software.com/products/brainsoup">BrainSoup</a> (Flexible native client with RAG &amp; multi-agent automation)</li>
<li><a href="https://github.com/Renset/macai">macai</a> (macOS client for Ollama, ChatGPT, and other compatible API back-ends)</li>
<li><a href="https://github.com/dezoito/ollama-grid-search">Ollama Grid Search</a> (app to evaluate and compare models)</li>
<li><a href="https://github.com/Otacon/olpaka">Olpaka</a> (User-friendly Flutter Web App for Ollama)</li>
<li><a href="https://github.com/CrazyNeil/OllamaSpring">OllamaSpring</a> (Ollama Client for macOS)</li>
<li><a href="https://github.com/kartikm7/llocal">LLocal.in</a> (Easy to use Electron Desktop Client for Ollama)</li>
<li><a href="https://github.com/dcSpark/shinkai-apps">Shinkai Desktop</a> (Two click install Local AI using Ollama + Files + RAG)</li>
<li><a href="https://github.com/zeyoyt/ailama">AiLama</a> (A Discord User App that allows you to interact with Ollama anywhere in discord )</li>
<li><a href="https://github.com/rapidarchitect/ollama_mesop/">Ollama with Google Mesop</a> (Mesop Chat Client implementation with Ollama)</li>
<li><a href="https://github.com/SciPhi-AI/R2R">R2R</a> (Open-source RAG engine)</li>
<li><a href="https://github.com/elearningshow/ollama-kis">Ollama-Kis</a> (A simple easy to use GUI with sample custom LLM for Drivers Education)</li>
<li><a href="https://opengpa.org">OpenGPA</a> (Open-source offline-first Enterprise Agentic Application)</li>
<li><a href="https://github.com/mateuszmigas/painting-droid">Painting Droid</a> (Painting app with AI integrations)</li>
<li><a href="https://www.kerlig.com/">Kerlig AI</a> (AI writing assistant for macOS)</li>
<li><a href="https://github.com/MindWorkAI/AI-Studio">AI Studio</a></li>
<li><a href="https://github.com/gyopak/sidellama">Sidellama</a> (browser-based LLM client)</li>
<li><a href="https://github.com/trypromptly/LLMStack">LLMStack</a> (No-code multi-agent framework to build LLM agents and workflows)</li>
<li><a href="https://boltai.com">BoltAI for Mac</a> (AI Chat Client for Mac)</li>
<li><a href="https://github.com/av/harbor">Harbor</a> (Containerized LLM Toolkit with Ollama as default backend)</li>
<li><a href="https://github.com/szczyglis-dev/py-gpt">PyGPT</a> (AI desktop assistant for Linux, Windows and Mac)</li>
<li><a href="https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md">AutoGPT</a> (AutoGPT Ollama integration)</li>
<li><a href="https://www.jonathanhecl.com/go-crew/">Go-CREW</a> (Powerful Offline RAG in Golang)</li>
<li><a href="https://github.com/openvmp/partcad/">PartCAD</a> (CAD model generation with OpenSCAD and CadQuery)</li>
<li><a href="https://github.com/ollama4j/ollama4j-web-ui">Ollama4j Web UI</a> - Java-based Web UI for Ollama built with Vaadin, Spring Boot and Ollama4j</li>
<li><a href="https://github.com/kspviswa/pyOllaMx">PyOllaMx</a> - macOS application capable of chatting with both Ollama and Apple MLX models.</li>
<li><a href="https://github.com/saoudrizwan/claude-dev">Claude Dev</a> - VSCode extension for multi-file/whole-repo coding</li>
<li><a href="https://github.com/kangfenmao/cherry-studio">Cherry Studio</a> (Desktop client with Ollama support)</li>
<li><a href="https://github.com/1runeberg/confichat">ConfiChat</a> (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)</li>
<li><a href="https://github.com/nickthecook/archyve">Archyve</a> (RAG-enabling document library)</li>
<li><a href="https://github.com/rapidarchitect/ollama-crew-mesop">crewAI with Mesop</a> (Mesop Web Interface to run crewAI with Ollama)</li>
<li><a href="https://github.com/chyok/ollama-gui">Tkinter-based client</a> (Python tkinter-based Client for Ollama)</li>
<li><a href="https://github.com/trendy-design/llmchat">LLMChat</a> (Privacy focused, 100% local, intuitive all-in-one chat interface)</li>
<li><a href="https://github.com/Leon-Sander/Local-Multimodal-AI-Chat">Local Multimodal AI Chat</a> (Ollama-based LLM Chat with support for multiple features, including PDF RAG, voice chat, image-based interactions, and integration with OpenAI.)</li>
<li><a href="https://github.com/xark-argo/argo">ARGO</a> (Locally download and run Ollama and Huggingface models with RAG on Mac/Windows/Linux)</li>
<li><a href="https://github.com/EliasPereirah/OrionChat">OrionChat</a> - OrionChat is a web interface for chatting with different AI providers</li>
<li><a href="https://github.com/bklieger-groq/g1">G1</a> (Prototype of using prompting strategies to improve the LLM's reasoning through o1-like reasoning chains.)</li>
<li><a href="https://github.com/lemonit-eric-mao/ollama-web-management">Web management</a> (Web management page)</li>
<li><a href="https://github.com/promptery/promptery">Promptery</a> (desktop client for Ollama.)</li>
<li><a href="https://github.com/JHubi1/ollama-app">Ollama App</a> (Modern and easy-to-use multi-platform client for Ollama)</li>
<li><a href="https://github.com/h1ddenpr0cess20/ollamarama-matrix">ollamarama-matrix</a> (Ollama chatbot for the Matrix chat protocol)</li>
<li><a href="https://github.com/anan1213095357/ollama-chat-app">ollama-chat-app</a> (Flutter-based chat app)</li>
<li><a href="https://www.perfectmemory.ai/">Perfect Memory AI</a> (Productivity AI assists personalized by what you have seen on your screen, heard and said in the meetings)</li>
<li><a href="https://github.com/hexastack/hexabot">Hexabot</a> (A conversational AI builder)</li>
<li><a href="https://github.com/rapidarchitect/reddit_analyzer">Reddit Rate</a> (Search and Rate Reddit topics with a weighted summation)</li>
<li><a href="https://github.com/adarshM84/OpenTalkGpt">OpenTalkGpt</a></li>
<li><a href="https://github.com/vinhnx/vt.ai">VT</a> (A minimal multimodal AI chat app, with dynamic conversation routing. Supports local models via Ollama)</li>
<li><a href="https://github.com/nosia-ai/nosia">Nosia</a> (Easy to install and use RAG platform based on Ollama)</li>
<li><a href="https://github.com/nbonamy/witsy">Witsy</a> (An AI Desktop application avaiable for Mac/Windows/Linux)</li>
<li><a href="https://github.com/US-Artificial-Intelligence/abbey">Abbey</a> (A configurable AI interface server with notebooks, document storage, and YouTube support)</li>
</ul>
<h3 id="cloud">Cloud</h3>
<ul>
<li><a href="https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama">Google Cloud</a></li>
<li><a href="https://fly.io/docs/python/do-more/add-ollama/">Fly.io</a></li>
<li><a href="https://www.koyeb.com/deploy/ollama">Koyeb</a></li>
</ul>
<h3 id="terminal">Terminal</h3>
<ul>
<li><a href="https://github.com/ggozad/oterm">oterm</a></li>
<li><a href="https://github.com/s-kostyaev/ellama">Ellama Emacs client</a></li>
<li><a href="https://github.com/zweifisch/ollama">Emacs client</a></li>
<li><a href="https://github.com/David-Kunz/gen.nvim">gen.nvim</a></li>
<li><a href="https://github.com/nomnivore/ollama.nvim">ollama.nvim</a></li>
<li><a href="https://github.com/marco-souza/ollero.nvim">ollero.nvim</a></li>
<li><a href="https://github.com/gerazov/ollama-chat.nvim">ollama-chat.nvim</a></li>
<li><a href="https://github.com/huynle/ogpt.nvim">ogpt.nvim</a></li>
<li><a href="https://github.com/karthink/gptel">gptel Emacs client</a></li>
<li><a href="https://github.com/dustinblackman/oatmeal">Oatmeal</a></li>
<li><a href="https://github.com/pgibler/cmdh">cmdh</a></li>
<li><a href="https://github.com/npahlfer/ooo">ooo</a></li>
<li><a href="https://github.com/reid41/shell-pilot">shell-pilot</a></li>
<li><a href="https://github.com/pythops/tenere">tenere</a></li>
<li><a href="https://github.com/taketwo/llm-ollama">llm-ollama</a> for <a href="https://llm.datasette.io/en/stable/">Datasette's LLM CLI</a>.</li>
<li><a href="https://github.com/anaisbetts/typechat-cli">typechat-cli</a></li>
<li><a href="https://github.com/djcopley/ShellOracle">ShellOracle</a></li>
<li><a href="https://github.com/yusufcanb/tlm">tlm</a></li>
<li><a href="https://github.com/ericcurtin/podman-ollama">podman-ollama</a></li>
<li><a href="https://github.com/sammcj/gollama">gollama</a></li>
<li><a href="https://github.com/paulrobello/parllama">ParLlama</a></li>
<li><a href="https://github.com/cognitivetech/ollama-ebook-summary/">Ollama eBook Summary</a></li>
<li><a href="https://github.com/rapidarchitect/ollama_moe">Ollama Mixture of Experts (MOE) in 50 lines of code</a></li>
<li><a href="https://github.com/pepo-ec/vim-intelligence-bridge">vim-intelligence-bridge</a> Simple interaction of "Ollama" with the Vim editor</li>
<li><a href="https://x-cmd.com/mod/ollama">x-cmd ollama</a></li>
<li><a href="https://github.com/drunkwcodes/bb7">bb7</a></li>
<li><a href="https://github.com/marcusziade/Swollama">SwollamaCLI</a> bundled with the Swollama Swift package. <a href="https://github.com/marcusziade/Swollama?tab=readme-ov-file#cli-usage">Demo</a></li>
<li><a href="https://github.com/sigoden/aichat">aichat</a> All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools &amp; agents, with access to OpenAI, Claude, Gemini, Ollama, Groq, and more.</li>
<li><a href="https://github.com/xyproto/orbiton">orbiton</a> Configuration-free text editor and IDE with support for tab completion with Ollama.</li>
</ul>
<h3 id="apple-vision-pro">Apple Vision Pro</h3>
<ul>
<li><a href="https://github.com/AugustDev/enchanted">Enchanted</a></li>
</ul>
<h3 id="database">Database</h3>
<ul>
<li><a href="https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md">MindsDB</a> (Connects Ollama models with nearly 200 data platforms and apps)</li>
<li><a href="https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go">chromem-go</a> with <a href="https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama">example</a></li>
</ul>
<h3 id="package-managers">Package managers</h3>
<ul>
<li><a href="https://archlinux.org/packages/extra/x86_64/ollama/">Pacman</a></li>
<li><a href="https://github.com/gentoo/guru/tree/master/app-misc/ollama">Gentoo</a></li>
<li><a href="https://artifacthub.io/packages/helm/ollama-helm/ollama">Helm Chart</a></li>
<li><a href="https://codeberg.org/tusharhero/ollama-guix">Guix channel</a></li>
<li><a href="https://search.nixos.org/packages?channel=24.05&amp;show=ollama&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=ollama">Nix package</a></li>
<li><a href="https://flox.dev/blog/ollama-part-one">Flox</a></li>
</ul>
<h3 id="libraries_1">Libraries</h3>
<ul>
<li><a href="https://python.langchain.com/docs/integrations/llms/ollama">LangChain</a> and <a href="https://js.langchain.com/docs/integrations/chat/ollama/">LangChain.js</a> with <a href="https://js.langchain.com/docs/tutorials/local_rag/">example</a></li>
<li><a href="https://firebase.google.com/docs/genkit/plugins/ollama">Firebase Genkit</a></li>
<li><a href="https://github.com/crewAIInc/crewAI">crewAI</a></li>
<li><a href="https://github.com/spring-projects/spring-ai">Spring AI</a> with <a href="https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html">reference</a> and <a href="https://github.com/tzolov/ollama-tools">example</a></li>
<li><a href="https://github.com/tmc/langchaingo/">LangChainGo</a> with <a href="https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example">example</a></li>
<li><a href="https://github.com/langchain4j/langchain4j">LangChain4j</a> with <a href="https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java">example</a></li>
<li><a href="https://github.com/Abraxas-365/langchain-rust">LangChainRust</a> with <a href="https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs">example</a></li>
<li><a href="https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama">LLPhant</a></li>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/llm/ollama/">LlamaIndex</a> and <a href="https://ts.llamaindex.ai/modules/llms/available_llms/ollama">LlamaIndexTS</a></li>
<li><a href="https://github.com/BerriAI/litellm">LiteLLM</a></li>
<li><a href="https://github.com/presbrey/ollamafarm">OllamaFarm for Go</a></li>
<li><a href="https://github.com/awaescher/OllamaSharp">OllamaSharp for .NET</a></li>
<li><a href="https://github.com/gbaptista/ollama-ai">Ollama for Ruby</a></li>
<li><a href="https://github.com/pepperoni21/ollama-rs">Ollama-rs for Rust</a></li>
<li><a href="https://github.com/jmont-dev/ollama-hpp">Ollama-hpp for C++</a></li>
<li><a href="https://github.com/ollama4j/ollama4j">Ollama4j for Java</a></li>
<li><a href="https://modelfusion.dev/integration/model-provider/ollama">ModelFusion Typescript Library</a></li>
<li><a href="https://github.com/kevinhermawan/OllamaKit">OllamaKit for Swift</a></li>
<li><a href="https://github.com/breitburg/dart-ollama">Ollama for Dart</a></li>
<li><a href="https://github.com/cloudstudio/ollama-laravel">Ollama for Laravel</a></li>
<li><a href="https://github.com/davidmigloz/langchain_dart">LangChainDart</a></li>
<li><a href="https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama">Semantic Kernel - Python</a></li>
<li><a href="https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md">Haystack</a></li>
<li><a href="https://github.com/brainlid/langchain">Elixir LangChain</a></li>
<li><a href="https://github.com/JBGruber/rollama">Ollama for R - rollama</a></li>
<li><a href="https://github.com/hauselin/ollama-r">Ollama for R - ollama-r</a></li>
<li><a href="https://github.com/lebrunel/ollama-ex">Ollama-ex for Elixir</a></li>
<li><a href="https://github.com/b-tocs/abap_btocs_ollama">Ollama Connector for SAP ABAP</a></li>
<li><a href="https://testcontainers.com/modules/ollama/">Testcontainers</a></li>
<li><a href="https://portkey.ai/docs/welcome/integration-guides/ollama">Portkey</a></li>
<li><a href="https://github.com/svilupp/PromptingTools.jl">PromptingTools.jl</a> with an <a href="https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama">example</a></li>
<li><a href="https://github.com/Project-Llama/llamascript">LlamaScript</a></li>
<li><a href="https://github.com/emirsahin1/llm-axe">llm-axe</a> (Python Toolkit for Building LLM Powered Apps)</li>
<li><a href="https://docs.gollm.co/examples/ollama-example">Gollm</a></li>
<li><a href="https://github.com/jonathanhecl/gollama">Gollama for Golang</a></li>
<li><a href="https://github.com/xyproto/ollamaclient">Ollamaclient for Golang</a></li>
<li><a href="https://gitlab.com/tozd/go/fun">High-level function abstraction in Go</a></li>
<li><a href="https://github.com/ArdaGnsrn/ollama-php">Ollama PHP</a></li>
<li><a href="https://github.com/agents-flex/agents-flex">Agents-Flex for Java</a> with <a href="https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama">example</a></li>
<li><a href="https://github.com/parakeet-nest/parakeet">Parakeet</a> is a GoLang library, made to simplify the development of small generative AI applications with Ollama.</li>
<li><a href="https://github.com/andygill/haverscript">Haverscript</a> with <a href="https://github.com/andygill/haverscript/tree/main/examples">examples</a></li>
<li><a href="https://github.com/mattt/ollama-swift">Ollama for Swift</a></li>
<li><a href="https://github.com/marcusziade/Swollama">Swollama for Swift</a> with <a href="https://marcusziade.github.io/Swollama/documentation/swollama/">DocC</a></li>
<li><a href="https://github.com/prasad89/golamify">GoLamify</a></li>
<li><a href="https://github.com/tusharad/ollama-haskell">Ollama for Haskell</a></li>
<li><a href="https://github.com/nbonamy/multi-llm-ts">multi-llm-ts</a> (A Typescript/JavaScript library allowing access to different LLM in unified API)</li>
</ul>
<h3 id="mobile">Mobile</h3>
<ul>
<li><a href="https://github.com/AugustDev/enchanted">Enchanted</a></li>
<li><a href="https://github.com/Mobile-Artificial-Intelligence/maid">Maid</a></li>
<li><a href="https://github.com/JHubi1/ollama-app">Ollama App</a> (Modern and easy-to-use multi-platform client for Ollama)</li>
<li><a href="https://github.com/1runeberg/confichat">ConfiChat</a> (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)</li>
</ul>
<h3 id="extensions-plugins">Extensions &amp; Plugins</h3>
<ul>
<li><a href="https://github.com/MassimilianoPasquini97/raycast_ollama">Raycast extension</a></li>
<li><a href="https://github.com/mxyng/discollama">Discollama</a> (Discord bot inside the Ollama discord channel)</li>
<li><a href="https://github.com/continuedev/continue">Continue</a></li>
<li><a href="https://github.com/thewh1teagle/vibe">Vibe</a> (Transcribe and analyze meetings with Ollama)</li>
<li><a href="https://github.com/hinterdupfinger/obsidian-ollama">Obsidian Ollama plugin</a></li>
<li><a href="https://github.com/omagdy7/ollama-logseq">Logseq Ollama plugin</a></li>
<li><a href="https://github.com/andersrex/notesollama">NotesOllama</a> (Apple Notes Ollama plugin)</li>
<li><a href="https://github.com/samalba/dagger-chatbot">Dagger Chatbot</a></li>
<li><a href="https://github.com/mekb-turtle/discord-ai-bot">Discord AI Bot</a></li>
<li><a href="https://github.com/ruecat/ollama-telegram">Ollama Telegram Bot</a></li>
<li><a href="https://github.com/ej52/hass-ollama-conversation">Hass Ollama Conversation</a></li>
<li><a href="https://github.com/abrenneke/rivet-plugin-ollama">Rivet plugin</a></li>
<li><a href="https://github.com/longy2k/obsidian-bmo-chatbot">Obsidian BMO Chatbot plugin</a></li>
<li><a href="https://github.com/herval/cliobot">Cliobot</a> (Telegram bot with Ollama support)</li>
<li><a href="https://github.com/logancyang/obsidian-copilot">Copilot for Obsidian plugin</a></li>
<li><a href="https://github.com/pfrankov/obsidian-local-gpt">Obsidian Local GPT plugin</a></li>
<li><a href="https://docs.openinterpreter.com/language-model-setup/local-models/ollama">Open Interpreter</a></li>
<li><a href="https://github.com/ex3ndr/llama-coder">Llama Coder</a> (Copilot alternative using Ollama)</li>
<li><a href="https://github.com/bernardo-bruning/ollama-copilot">Ollama Copilot</a> (Proxy that allows you to use ollama as a copilot like Github copilot)</li>
<li><a href="https://github.com/rjmacarthy/twinny">twinny</a> (Copilot and Copilot chat alternative using Ollama)</li>
<li><a href="https://github.com/RussellCanfield/wingman-ai">Wingman-AI</a> (Copilot code and chat alternative using Ollama and Hugging Face)</li>
<li><a href="https://github.com/n4ze3m/page-assist">Page Assist</a> (Chrome Extension)</li>
<li><a href="https://github.com/imoize/plasmoid-ollamacontrol">Plasmoid Ollama Control</a> (KDE Plasma extension that allows you to quickly manage/control Ollama model)</li>
<li><a href="https://github.com/tusharhero/aitelegrambot">AI Telegram Bot</a> (Telegram bot using Ollama in backend)</li>
<li><a href="https://github.com/yaroslavyaroslav/OpenAI-sublime-text">AI ST Completion</a> (Sublime Text 4 AI assistant plugin with Ollama support)</li>
<li><a href="https://github.com/kevinthedang/discord-ollama">Discord-Ollama Chat Bot</a> (Generalized TypeScript Discord Bot w/ Tuning Documentation)</li>
<li><a href="https://github.com/rapmd73/Companion">Discord AI chat/moderation bot</a> Chat/moderation bot written in python. Uses Ollama to create personalities.</li>
<li><a href="https://github.com/nischalj10/headless-ollama">Headless Ollama</a> (Scripts to automatically install ollama client &amp; models on any OS for apps that depends on ollama server)</li>
<li><a href="https://github.com/xuyangbocn/terraform-aws-self-host-llm">Terraform AWS Ollama &amp; Open WebUI</a> (A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front end Open WebUI service.)</li>
<li><a href="https://github.com/jakubburkiewicz/node-red-contrib-ollama">node-red-contrib-ollama</a></li>
<li><a href="https://github.com/ivostoykov/localAI">Local AI Helper</a> (Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)</li>
<li><a href="https://github.com/jk011ru/vnc-lm">vnc-lm</a> (A containerized Discord bot with support for attachments and web links)</li>
<li><a href="https://github.com/SilasMarvin/lsp-ai">LSP-AI</a> (Open-source language server for AI-powered functionality)</li>
<li><a href="https://github.com/Palm1r/QodeAssist">QodeAssist</a> (AI-powered coding assistant plugin for Qt Creator)</li>
<li><a href="https://github.com/ECuiDev/obsidian-quiz-generator">Obsidian Quiz Generator plugin</a></li>
<li><a href="https://github.com/suncloudsmoon/TextCraft">TextCraft</a> (Copilot in Word alternative using Ollama)</li>
<li><a href="https://github.com/zeitlings/alfred-ollama">Alfred Ollama</a> (Alfred Workflow)</li>
</ul>
<h3 id="supported-backends">Supported backends</h3>
<ul>
<li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> project founded by Georgi Gerganov.</li>
</ul>












                  

              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.highlight"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
  
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  <script src="../../assets/js/custom.js"></script>

  </body>
</html>