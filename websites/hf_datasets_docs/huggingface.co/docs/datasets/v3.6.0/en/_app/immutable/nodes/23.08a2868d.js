import{s as _t,o as kt,n as Gt}from"../chunks/scheduler.bdbef820.js";import{S as It,i as Wt,g as p,s as l,r,A as Bt,h as m,f as s,c as n,j as Jt,u as f,x as o,k as gt,y as Ht,a,v as g,d as h,t as d,w as u}from"../chunks/index.c0aea24a.js";import{T as Ft}from"../chunks/Tip.31005f7d.js";import{C as z}from"../chunks/CodeBlock.e814ab8d.js";import{H as Rt,E as Yt}from"../chunks/index.89e522f3.js";function Zt(X){let i,w=`Now that you know how to process a dataset for image classification, learn
<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb" rel="nofollow">how to train an image classification model</a>
and use it for inference.`;return{c(){i=p("p"),i.innerHTML=w},l(c){i=m(c,"P",{"data-svelte-h":!0}),o(i)!=="svelte-rd509y"&&(i.innerHTML=w)},m(c,L){a(c,i,L)},p:Gt,d(c){c&&s(i)}}}function Lt(X){let i,w,c,L,j,E,$,ht="Image classification datasets are used to train a model to classify an entire image. There are a wide variety of applications enabled by these datasets such as identifying endangered wildlife species or screening for disease in medical images. This guide will show you how to apply transformations to an image classification dataset.",N,T,dt="Before you start, make sure you have up-to-date versions of <code>albumentations</code> and <code>cv2</code> installed:",P,v,A,x,ut='This guide uses the <a href="https://huggingface.co/datasets/beans" rel="nofollow">Beans</a> dataset for identifying the type of bean plant disease based on an image of its leaf.',q,U,yt="Load the dataset and take a look at an example:",S,C,V,J,bt="The dataset has three fields:",D,_,Mt="<li><code>image</code>: a PIL image object.</li> <li><code>image_file_path</code>: the path to the image file.</li> <li><code>labels</code>: the label or category of the image.</li>",K,k,wt="Next, check out an image:",O,y,jt='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/img_clf.png"/>',tt,G,$t="Now apply some augmentations with <code>albumentations</code>. Youâ€™ll randomly crop the image, flip it horizontally, and adjust its brightness.",et,I,st,W,Tt="Create a function to apply the transformation to the images:",at,B,lt,H,vt='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.set_transform">set_transform()</a> function to apply the transformation on-the-fly to batches of the dataset to consume less disk space:',nt,F,it,R,xt="You can verify the transformation worked by indexing into the <code>pixel_values</code> of the first example:",pt,Y,mt,b,Ut='<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/img_clf_aug.png"/> <img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/img_clf_aug.png"/>',ot,M,ct,Z,rt,Q,ft;return j=new Rt({props:{title:"Image classification",local:"image-classification",headingTag:"h1"}}),v=new z({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1VJTIwYWxidW1lbnRhdGlvbnMlMjBvcGVuY3YtcHl0aG9u",highlighted:"pip install -U albumentations opencv-python",wrap:!1}}),C=new z({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJBSS1MYWItTWFrZXJlcmUlMkZiZWFucyUyMiklMEFkYXRhc2V0JTVCJTIydHJhaW4lMjIlNUQlNUIxMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;AI-Lab-Makerere/beans&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">10</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at <span class="hljs-number">0x7F8D2F4D7A10</span>&gt;,
 <span class="hljs-string">&#x27;image_file_path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/b0a21163f78769a2cf11f58dfc767fb458fc7cea5c05dccc0144a2c0f0bc1292/train/angular_leaf_spot/angular_leaf_spot_train.204.jpg&#x27;</span>,
 <span class="hljs-string">&#x27;labels&#x27;</span>: <span class="hljs-number">0</span>}`,wrap:!1}}),I=new z({props:{code:"aW1wb3J0JTIwY3YyJTBBaW1wb3J0JTIwYWxidW1lbnRhdGlvbnMlMEFpbXBvcnQlMjBudW1weSUyMGFzJTIwbnAlMEElMEF0cmFuc2Zvcm0lMjAlM0QlMjBhbGJ1bWVudGF0aW9ucy5Db21wb3NlKCU1QiUwQSUyMCUyMCUyMCUyMGFsYnVtZW50YXRpb25zLlJhbmRvbUNyb3Aod2lkdGglM0QyNTYlMkMlMjBoZWlnaHQlM0QyNTYpJTJDJTBBJTIwJTIwJTIwJTIwYWxidW1lbnRhdGlvbnMuSG9yaXpvbnRhbEZsaXAocCUzRDAuNSklMkMlMEElMjAlMjAlMjAlMjBhbGJ1bWVudGF0aW9ucy5SYW5kb21CcmlnaHRuZXNzQ29udHJhc3QocCUzRDAuMiklMkMlMEElNUQp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> cv2
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> albumentations
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-meta">&gt;&gt;&gt; </span>transform = albumentations.Compose([
<span class="hljs-meta">... </span>    albumentations.RandomCrop(width=<span class="hljs-number">256</span>, height=<span class="hljs-number">256</span>),
<span class="hljs-meta">... </span>    albumentations.HorizontalFlip(p=<span class="hljs-number">0.5</span>),
<span class="hljs-meta">... </span>    albumentations.RandomBrightnessContrast(p=<span class="hljs-number">0.2</span>),
<span class="hljs-meta">... </span>])`,wrap:!1}}),B=new z({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHRyYW5zZm9ybShpbWFnZSUzRG5wLmFycmF5KGltYWdlKSklNUIlMjJpbWFnZSUyMiU1RCUyMGZvciUyMGltYWdlJTIwaW4lMjBleGFtcGxlcyU1QiUyMmltYWdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwJTVEJTBBJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwZXhhbXBsZXM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [
<span class="hljs-meta">... </span>        transform(image=np.array(image))[<span class="hljs-string">&quot;image&quot;</span>] <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`,wrap:!1}}),F=new z({props:{code:"ZGF0YXNldC5zZXRfdHJhbnNmb3JtKHRyYW5zZm9ybXMp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)',wrap:!1}}),Y=new z({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBaW1wb3J0JTIwbWF0cGxvdGxpYi5weXBsb3QlMjBhcyUyMHBsdCUwQSUwQWltZyUyMCUzRCUyMGRhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCU1QjAlNUQlNUIlMjJwaXhlbF92YWx1ZXMlMjIlNUQlMEFwbHQuaW1zaG93KGltZyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img)`,wrap:!1}}),M=new Ft({props:{$$slots:{default:[Zt]},$$scope:{ctx:X}}}),Z=new Yt({props:{source:"https://github.com/huggingface/datasets/blob/main/docs/source/image_classification.mdx"}}),{c(){i=p("meta"),w=l(),c=p("p"),L=l(),r(j.$$.fragment),E=l(),$=p("p"),$.textContent=ht,N=l(),T=p("p"),T.innerHTML=dt,P=l(),r(v.$$.fragment),A=l(),x=p("p"),x.innerHTML=ut,q=l(),U=p("p"),U.textContent=yt,S=l(),r(C.$$.fragment),V=l(),J=p("p"),J.textContent=bt,D=l(),_=p("ul"),_.innerHTML=Mt,K=l(),k=p("p"),k.textContent=wt,O=l(),y=p("div"),y.innerHTML=jt,tt=l(),G=p("p"),G.innerHTML=$t,et=l(),r(I.$$.fragment),st=l(),W=p("p"),W.textContent=Tt,at=l(),r(B.$$.fragment),lt=l(),H=p("p"),H.innerHTML=vt,nt=l(),r(F.$$.fragment),it=l(),R=p("p"),R.innerHTML=xt,pt=l(),r(Y.$$.fragment),mt=l(),b=p("div"),b.innerHTML=Ut,ot=l(),r(M.$$.fragment),ct=l(),r(Z.$$.fragment),rt=l(),Q=p("p"),this.h()},l(t){const e=Bt("svelte-u9bgzb",document.head);i=m(e,"META",{name:!0,content:!0}),e.forEach(s),w=n(t),c=m(t,"P",{}),Jt(c).forEach(s),L=n(t),f(j.$$.fragment,t),E=n(t),$=m(t,"P",{"data-svelte-h":!0}),o($)!=="svelte-sh7ab0"&&($.textContent=ht),N=n(t),T=m(t,"P",{"data-svelte-h":!0}),o(T)!=="svelte-1qtuikq"&&(T.innerHTML=dt),P=n(t),f(v.$$.fragment,t),A=n(t),x=m(t,"P",{"data-svelte-h":!0}),o(x)!=="svelte-1h05g43"&&(x.innerHTML=ut),q=n(t),U=m(t,"P",{"data-svelte-h":!0}),o(U)!=="svelte-1yzvpv3"&&(U.textContent=yt),S=n(t),f(C.$$.fragment,t),V=n(t),J=m(t,"P",{"data-svelte-h":!0}),o(J)!=="svelte-jjwn46"&&(J.textContent=bt),D=n(t),_=m(t,"UL",{"data-svelte-h":!0}),o(_)!=="svelte-1aryjya"&&(_.innerHTML=Mt),K=n(t),k=m(t,"P",{"data-svelte-h":!0}),o(k)!=="svelte-z9j9vb"&&(k.textContent=wt),O=n(t),y=m(t,"DIV",{class:!0,"data-svelte-h":!0}),o(y)!=="svelte-1fbgic4"&&(y.innerHTML=jt),tt=n(t),G=m(t,"P",{"data-svelte-h":!0}),o(G)!=="svelte-1jan26m"&&(G.innerHTML=$t),et=n(t),f(I.$$.fragment,t),st=n(t),W=m(t,"P",{"data-svelte-h":!0}),o(W)!=="svelte-50733g"&&(W.textContent=Tt),at=n(t),f(B.$$.fragment,t),lt=n(t),H=m(t,"P",{"data-svelte-h":!0}),o(H)!=="svelte-14uei9m"&&(H.innerHTML=vt),nt=n(t),f(F.$$.fragment,t),it=n(t),R=m(t,"P",{"data-svelte-h":!0}),o(R)!=="svelte-vr227m"&&(R.innerHTML=xt),pt=n(t),f(Y.$$.fragment,t),mt=n(t),b=m(t,"DIV",{class:!0,"data-svelte-h":!0}),o(b)!=="svelte-123w0ig"&&(b.innerHTML=Ut),ot=n(t),f(M.$$.fragment,t),ct=n(t),f(Z.$$.fragment,t),rt=n(t),Q=m(t,"P",{}),Jt(Q).forEach(s),this.h()},h(){gt(i,"name","hf:doc:metadata"),gt(i,"content",zt),gt(y,"class","flex justify-center"),gt(b,"class","flex justify-center")},m(t,e){Ht(document.head,i),a(t,w,e),a(t,c,e),a(t,L,e),g(j,t,e),a(t,E,e),a(t,$,e),a(t,N,e),a(t,T,e),a(t,P,e),g(v,t,e),a(t,A,e),a(t,x,e),a(t,q,e),a(t,U,e),a(t,S,e),g(C,t,e),a(t,V,e),a(t,J,e),a(t,D,e),a(t,_,e),a(t,K,e),a(t,k,e),a(t,O,e),a(t,y,e),a(t,tt,e),a(t,G,e),a(t,et,e),g(I,t,e),a(t,st,e),a(t,W,e),a(t,at,e),g(B,t,e),a(t,lt,e),a(t,H,e),a(t,nt,e),g(F,t,e),a(t,it,e),a(t,R,e),a(t,pt,e),g(Y,t,e),a(t,mt,e),a(t,b,e),a(t,ot,e),g(M,t,e),a(t,ct,e),g(Z,t,e),a(t,rt,e),a(t,Q,e),ft=!0},p(t,[e]){const Ct={};e&2&&(Ct.$$scope={dirty:e,ctx:t}),M.$set(Ct)},i(t){ft||(h(j.$$.fragment,t),h(v.$$.fragment,t),h(C.$$.fragment,t),h(I.$$.fragment,t),h(B.$$.fragment,t),h(F.$$.fragment,t),h(Y.$$.fragment,t),h(M.$$.fragment,t),h(Z.$$.fragment,t),ft=!0)},o(t){d(j.$$.fragment,t),d(v.$$.fragment,t),d(C.$$.fragment,t),d(I.$$.fragment,t),d(B.$$.fragment,t),d(F.$$.fragment,t),d(Y.$$.fragment,t),d(M.$$.fragment,t),d(Z.$$.fragment,t),ft=!1},d(t){t&&(s(w),s(c),s(L),s(E),s($),s(N),s(T),s(P),s(A),s(x),s(q),s(U),s(S),s(V),s(J),s(D),s(_),s(K),s(k),s(O),s(y),s(tt),s(G),s(et),s(st),s(W),s(at),s(lt),s(H),s(nt),s(it),s(R),s(pt),s(mt),s(b),s(ot),s(ct),s(rt),s(Q)),s(i),u(j,t),u(v,t),u(C,t),u(I,t),u(B,t),u(F,t),u(Y,t),u(M,t),u(Z,t)}}}const zt='{"title":"Image classification","local":"image-classification","sections":[],"depth":1}';function Qt(X){return kt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class qt extends It{constructor(i){super(),Wt(this,i,Qt,Lt,_t,{})}}export{qt as component};
