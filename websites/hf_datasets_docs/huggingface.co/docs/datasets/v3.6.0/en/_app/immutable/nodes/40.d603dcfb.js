import{s as os,c as q,j as ya,u as Q,g as S,d as D,o as yt,b as kt,n as Y,B as ka,t as Ia,f as bt}from"../chunks/scheduler.bdbef820.js";import{S as is,i as cs,g as _,h as M,j as z,f as i,k as y,a as f,y as H,D as wt,d as m,t as h,B as la,C as na,l as Ga,s as d,c as g,p as A,b as x,r as k,u as $,v as T,w as J,m as Ta,e as L,n as Ja,o as $a,q as dt,z as va,A as Ra,x as I}from"../chunks/index.c0aea24a.js";import{T as Za}from"../chunks/Tip.31005f7d.js";import{C as W}from"../chunks/CodeBlock.e814ab8d.js";import{C as Na}from"../chunks/CodeBlockFw.ce0c10d4.js";import{g as Fa}from"../chunks/globals.7f7f1b26.js";import{e as gt}from"../chunks/each.e59479a4.js";import{F as ht,M as te}from"../chunks/Markdown.1f17db59.js";import{H as us,E as Wa}from"../chunks/index.89e522f3.js";function Ba(o){let e,l,t,s,r,n;const c=o[7].default,u=q(c,o,o[6],null);return{c(){e=_("div"),l=_("ul"),u&&u.c(),this.h()},l(w){e=M(w,"DIV",{class:!0});var G=z(e);l=M(G,"UL",{class:!0});var v=z(l);u&&u.l(v),v.forEach(i),G.forEach(i),this.h()},h(){y(l,"class","min-w-full w-auto"),y(e,"class",t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(o[2]==="right"?"right-0":"left-0")+" "+o[0])},m(w,G){f(w,e,G),H(e,l),u&&u.m(l,null),o[8](e),s=!0,r||(n=wt(e,"click",function(){ya(o[1])&&o[1].apply(this,arguments)}),r=!0)},p(w,[G]){o=w,u&&u.p&&(!s||G&64)&&Q(u,c,o,o[6],s?D(c,o[6],G,null):S(o[6]),null),(!s||G&5&&t!==(t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(o[2]==="right"?"right-0":"left-0")+" "+o[0]))&&y(e,"class",t)},i(w){s||(m(u,w),s=!0)},o(w){h(u,w),s=!1},d(w){w&&i(e),u&&u.d(w),o[8](null),r=!1,n()}}}function Va(o,e,l){let{$$slots:t={},$$scope:s}=e,{classNames:r=""}=e,{dropdownElement:n=void 0}=e,{forceAlignement:c=void 0}=e,{onClose:u}=e,w=c??"left",G;yt(()=>{if(document.addEventListener("click",v),!c){const U=document.documentElement.clientWidth,b=G==null?void 0:G.getBoundingClientRect(),j=(b==null?void 0:b.left)??0,N=(b==null?void 0:b.width)??0;l(2,w=j+N>U?"right":"left")}return()=>{document.removeEventListener("click",v)}});function v(U){const b=U.target;b!==n&&!(n!=null&&n.contains(b))&&u(U)}function C(U){kt[U?"unshift":"push"](()=>{G=U,l(3,G)})}return o.$$set=U=>{"classNames"in U&&l(0,r=U.classNames),"dropdownElement"in U&&l(4,n=U.dropdownElement),"forceAlignement"in U&&l(5,c=U.forceAlignement),"onClose"in U&&l(1,u=U.onClose),"$$scope"in U&&l(6,s=U.$$scope)},[r,u,w,G,n,c,s,t,C]}class Xa extends is{constructor(e){super(),cs(this,e,Va,Ba,os,{classNames:0,dropdownElement:4,forceAlignement:5,onClose:1})}}function Ya(o){let e,l;return{c(){e=la("svg"),l=la("path"),this.h()},l(t){e=na(t,"svg",{class:!0,xmlns:!0,"xmlns:xlink":!0,"aria-hidden":!0,focusable:!0,role:!0,width:!0,height:!0,preserveAspectRatio:!0,viewBox:!0,style:!0});var s=z(e);l=na(s,"path",{d:!0,fill:!0}),z(l).forEach(i),s.forEach(i),this.h()},h(){y(l,"d","M7 10l5 5l5-5z"),y(l,"fill","currentColor"),y(e,"class",o[0]),y(e,"xmlns","http://www.w3.org/2000/svg"),y(e,"xmlns:xlink","http://www.w3.org/1999/xlink"),y(e,"aria-hidden","true"),y(e,"focusable","false"),y(e,"role","img"),y(e,"width","1em"),y(e,"height","1em"),y(e,"preserveAspectRatio","xMidYMid meet"),y(e,"viewBox","0 0 24 24"),Ga(e,"transform","rotate(360deg)")},m(t,s){f(t,e,s),H(e,l)},p(t,[s]){s&1&&y(e,"class",t[0])},i:Y,o:Y,d(t){t&&i(e)}}}function Ha(o,e,l){let{classNames:t=""}=e;return o.$$set=s=>{"classNames"in s&&l(0,t=s.classNames)},[t]}class za extends is{constructor(e){super(),cs(this,e,Ha,Ya,os,{classNames:0})}}const Ea=o=>({}),ra=o=>({}),Aa=o=>({}),oa=o=>({});function xa(o){let e,l,t,s,r,n=o[2]&&ia(o),c=o[9]&&ca();return{c(){n&&n.c(),e=d(),l=Ta(o[4]),t=d(),c&&c.c(),s=L()},l(u){n&&n.l(u),e=g(u),l=Ja(u,o[4]),t=g(u),c&&c.l(u),s=L()},m(u,w){n&&n.m(u,w),f(u,e,w),f(u,l,w),f(u,t,w),c&&c.m(u,w),f(u,s,w),r=!0},p(u,w){u[2]?n?(n.p(u,w),w&4&&m(n,1)):(n=ia(u),n.c(),m(n,1),n.m(e.parentNode,e)):n&&(A(),h(n,1,1,()=>{n=null}),x()),(!r||w&16)&&$a(l,u[4]),u[9]?c?w&512&&m(c,1):(c=ca(),c.c(),m(c,1),c.m(s.parentNode,s)):c&&(A(),h(c,1,1,()=>{c=null}),x())},i(u){r||(m(n),m(c),r=!0)},o(u){h(n),h(c),r=!1},d(u){u&&(i(e),i(l),i(t),i(s)),n&&n.d(u),c&&c.d(u)}}}function La(o){let e;const l=o[15].button,t=q(l,o,o[18],oa);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,r){t&&t.m(s,r),e=!0},p(s,r){t&&t.p&&(!e||r&262144)&&Q(t,l,s,s[18],e?D(l,s[18],r,Aa):S(s[18]),oa)},i(s){e||(m(t,s),e=!0)},o(s){h(t,s),e=!1},d(s){t&&t.d(s)}}}function ia(o){let e,l,t;var s=o[2];function r(n,c){return{props:{classNames:"mr-1.5 "+n[3]}}}return s&&(e=dt(s,r(o))),{c(){e&&k(e.$$.fragment),l=L()},l(n){e&&$(e.$$.fragment,n),l=L()},m(n,c){e&&T(e,n,c),f(n,l,c),t=!0},p(n,c){if(c&4&&s!==(s=n[2])){if(e){A();const u=e;h(u.$$.fragment,1,0,()=>{J(u,1)}),x()}s?(e=dt(s,r(n)),k(e.$$.fragment),m(e.$$.fragment,1),T(e,l.parentNode,l)):e=null}else if(s){const u={};c&8&&(u.classNames="mr-1.5 "+n[3]),e.$set(u)}},i(n){t||(e&&m(e.$$.fragment,n),t=!0)},o(n){e&&h(e.$$.fragment,n),t=!1},d(n){n&&i(l),e&&J(e,n)}}}function ca(o){let e,l;return e=new za({props:{classNames:"-mr-1 text-gray-500"}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function pa(o){let e,l;return e=new Xa({props:{classNames:o[6]+" "+(o[8]?"v2-dropdown-menu hidden":""),dropdownElement:o[10],forceAlignement:o[5],onClose:o[12],$$slots:{default:[qa]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&320&&(r.classNames=t[6]+" "+(t[8]?"v2-dropdown-menu hidden":"")),s&1024&&(r.dropdownElement=t[10]),s&32&&(r.forceAlignement=t[5]),s&262144&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function qa(o){let e;const l=o[15].menu,t=q(l,o,o[18],ra);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,r){t&&t.m(s,r),e=!0},p(s,r){t&&t.p&&(!e||r&262144)&&Q(t,l,s,s[18],e?D(l,s[18],r,Ea):S(s[18]),ra)},i(s){e||(m(t,s),e=!0)},o(s){h(t,s),e=!1},d(s){t&&t.d(s)}}}function Qa(o){let e,l,t,s,r,n,c,u,w,G;const v=[La,xa],C=[];function U(j,N){return j[13].button?0:1}t=U(o),s=C[t]=v[t](o);let b=(o[11]||o[8])&&pa(o);return{c(){e=_("div"),l=_("button"),s.c(),n=d(),b&&b.c(),this.h()},l(j){e=M(j,"DIV",{class:!0});var N=z(e);l=M(N,"BUTTON",{class:!0,type:!0});var X=z(l);s.l(X),X.forEach(i),n=g(N),b&&b.l(N),N.forEach(i),this.h()},h(){y(l,"class",r=""+o[1]+" "+(o[7]?"":"cursor-pointer w-full btn text-sm")+" "+(o[8]?"v2-dropdown-button":"")),y(l,"type","button"),y(e,"class",c="relative "+o[0]+" "+(o[8]?"v2-dropdown":""))},m(j,N){f(j,e,N),H(e,l),C[t].m(l,null),H(e,n),b&&b.m(e,null),o[17](e),u=!0,w||(G=wt(l,"click",o[16]),w=!0)},p(j,[N]){let X=t;t=U(j),t===X?C[t].p(j,N):(A(),h(C[X],1,1,()=>{C[X]=null}),x(),s=C[t],s?s.p(j,N):(s=C[t]=v[t](j),s.c()),m(s,1),s.m(l,null)),(!u||N&386&&r!==(r=""+j[1]+" "+(j[7]?"":"cursor-pointer w-full btn text-sm")+" "+(j[8]?"v2-dropdown-button":"")))&&y(l,"class",r),j[11]||j[8]?b?(b.p(j,N),N&2304&&m(b,1)):(b=pa(j),b.c(),m(b,1),b.m(e,null)):b&&(A(),h(b,1,1,()=>{b=null}),x()),(!u||N&257&&c!==(c="relative "+j[0]+" "+(j[8]?"v2-dropdown":"")))&&y(e,"class",c)},i(j){u||(m(s),m(b),u=!0)},o(j){h(s),h(b),u=!1},d(j){j&&i(e),C[t].d(),b&&b.d(),o[17](null),w=!1,G()}}}function Sa(o,e,l){let{$$slots:t={},$$scope:s}=e;const r=ka(t);let{classNames:n=""}=e,{btnClassNames:c=""}=e,{btnIcon:u=void 0}=e,{btnIconClassNames:w=""}=e,{btnLabel:G=""}=e,{forceMenuAlignement:v=void 0}=e,{menuClassNames:C=""}=e,{noBtnClass:U=void 0}=e,{selectedValue:b=void 0}=e,{useDeprecatedJS:j=!0}=e,{withBtnCaret:N=!1}=e,X,V=!1;function R(F){var E;F.target&&(E=F.target)!=null&&E.className.includes("do-not-close-dropdown")||l(11,V=!1)}const Z=()=>l(11,V=!V);function B(F){kt[F?"unshift":"push"](()=>{X=F,l(10,X)})}return o.$$set=F=>{"classNames"in F&&l(0,n=F.classNames),"btnClassNames"in F&&l(1,c=F.btnClassNames),"btnIcon"in F&&l(2,u=F.btnIcon),"btnIconClassNames"in F&&l(3,w=F.btnIconClassNames),"btnLabel"in F&&l(4,G=F.btnLabel),"forceMenuAlignement"in F&&l(5,v=F.forceMenuAlignement),"menuClassNames"in F&&l(6,C=F.menuClassNames),"noBtnClass"in F&&l(7,U=F.noBtnClass),"selectedValue"in F&&l(14,b=F.selectedValue),"useDeprecatedJS"in F&&l(8,j=F.useDeprecatedJS),"withBtnCaret"in F&&l(9,N=F.withBtnCaret),"$$scope"in F&&l(18,s=F.$$scope)},[n,c,u,w,G,v,C,U,j,N,X,V,R,r,b,t,Z,B,s]}class Ua extends is{constructor(e){super(),cs(this,e,Sa,Qa,os,{classNames:0,btnClassNames:1,btnIcon:2,btnIconClassNames:3,btnLabel:4,forceMenuAlignement:5,menuClassNames:6,noBtnClass:7,selectedValue:14,useDeprecatedJS:8,withBtnCaret:9})}}function Da(o){let e,l,t,s=o[5]&&ua(o);return{c(){s&&s.c(),e=d(),l=Ta(o[7])},l(r){s&&s.l(r),e=g(r),l=Ja(r,o[7])},m(r,n){s&&s.m(r,n),f(r,e,n),f(r,l,n),t=!0},p(r,n){r[5]?s?(s.p(r,n),n&32&&m(s,1)):(s=ua(r),s.c(),m(s,1),s.m(e.parentNode,e)):s&&(A(),h(s,1,1,()=>{s=null}),x()),(!t||n&128)&&$a(l,r[7])},i(r){t||(m(s),t=!0)},o(r){h(s),t=!1},d(r){r&&(i(e),i(l)),s&&s.d(r)}}}function Pa(o){let e;const l=o[15].default,t=q(l,o,o[14],null);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,r){t&&t.m(s,r),e=!0},p(s,r){t&&t.p&&(!e||r&16384)&&Q(t,l,s,s[14],e?D(l,s[14],r,null):S(s[14]),null)},i(s){e||(m(t,s),e=!0)},o(s){h(t,s),e=!1},d(s){t&&t.d(s)}}}function ua(o){let e,l,t;var s=o[5];function r(n,c){return{props:{classNames:"mr-1.5 "+n[6]}}}return s&&(e=dt(s,r(o))),{c(){e&&k(e.$$.fragment),l=L()},l(n){e&&$(e.$$.fragment,n),l=L()},m(n,c){e&&T(e,n,c),f(n,l,c),t=!0},p(n,c){if(c&32&&s!==(s=n[5])){if(e){A();const u=e;h(u.$$.fragment,1,0,()=>{J(u,1)}),x()}s?(e=dt(s,r(n)),k(e.$$.fragment),m(e.$$.fragment,1),T(e,l.parentNode,l)):e=null}else if(s){const u={};c&64&&(u.classNames="mr-1.5 "+n[6]),e.$set(u)}},i(n){t||(e&&m(e.$$.fragment,n),t=!0)},o(n){e&&h(e.$$.fragment,n),t=!1},d(n){n&&i(l),e&&J(e,n)}}}function Ka(o){let e,l,t,s,r,n,c,u,w,G;const v=[Pa,Da],C=[];function U(b,j){return b[13].default?0:1}return t=U(o),s=C[t]=v[t](o),{c(){e=_("li"),l=_("a"),s.c(),this.h()},l(b){e=M(b,"LI",{class:!0});var j=z(e);l=M(j,"A",{class:!0,"data-label":!0,"data-url":!0,"data-value":!0,href:!0,rel:!0,target:!0});var N=z(l);s.l(N),N.forEach(i),j.forEach(i),this.h()},h(){y(l,"class",r="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+o[0]+" "+(o[9]?"hover:underline":"")+" "+(o[12]?"v2-dropdown-entry":"")),y(l,"data-label",o[1]),y(l,"data-url",o[2]),y(l,"data-value",o[3]),y(l,"href",o[4]),y(l,"rel",n=o[8]?"nofollow":void 0),y(l,"target",c=o[11]?"_blank":void 0),y(e,"class","not-prose")},m(b,j){f(b,e,j),H(e,l),C[t].m(l,null),u=!0,w||(G=wt(l,"click",function(){ya(o[10])&&o[10].apply(this,arguments)}),w=!0)},p(b,[j]){o=b;let N=t;t=U(o),t===N?C[t].p(o,j):(A(),h(C[N],1,1,()=>{C[N]=null}),x(),s=C[t],s?s.p(o,j):(s=C[t]=v[t](o),s.c()),m(s,1),s.m(l,null)),(!u||j&4609&&r!==(r="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+o[0]+" "+(o[9]?"hover:underline":"")+" "+(o[12]?"v2-dropdown-entry":"")))&&y(l,"class",r),(!u||j&2)&&y(l,"data-label",o[1]),(!u||j&4)&&y(l,"data-url",o[2]),(!u||j&8)&&y(l,"data-value",o[3]),(!u||j&16)&&y(l,"href",o[4]),(!u||j&256&&n!==(n=o[8]?"nofollow":void 0))&&y(l,"rel",n),(!u||j&2048&&c!==(c=o[11]?"_blank":void 0))&&y(l,"target",c)},i(b){u||(m(s),u=!0)},o(b){h(s),u=!1},d(b){b&&i(e),C[t].d(),w=!1,G()}}}function Oa(o,e,l){let{$$slots:t={},$$scope:s}=e;const r=ka(t);let{classNames:n=""}=e,{dataLabel:c=void 0}=e,{dataUrl:u=void 0}=e,{dataValue:w=void 0}=e,{href:G=void 0}=e,{icon:v=void 0}=e,{iconClassNames:C=""}=e,{label:U=""}=e,{noFollow:b=!1}=e,{underline:j=!1}=e,{onClick:N=()=>{}}=e,{targetBlank:X=!1}=e,{useDeprecatedJS:V=!0}=e;return o.$$set=R=>{"classNames"in R&&l(0,n=R.classNames),"dataLabel"in R&&l(1,c=R.dataLabel),"dataUrl"in R&&l(2,u=R.dataUrl),"dataValue"in R&&l(3,w=R.dataValue),"href"in R&&l(4,G=R.href),"icon"in R&&l(5,v=R.icon),"iconClassNames"in R&&l(6,C=R.iconClassNames),"label"in R&&l(7,U=R.label),"noFollow"in R&&l(8,b=R.noFollow),"underline"in R&&l(9,j=R.underline),"onClick"in R&&l(10,N=R.onClick),"targetBlank"in R&&l(11,X=R.targetBlank),"useDeprecatedJS"in R&&l(12,V=R.useDeprecatedJS),"$$scope"in R&&l(14,s=R.$$scope)},[n,c,u,w,G,v,C,U,b,j,N,X,V,r,s,t]}class Ca extends is{constructor(e){super(),cs(this,e,Oa,Ka,os,{classNames:0,dataLabel:1,dataUrl:2,dataValue:3,href:4,icon:5,iconClassNames:6,label:7,noFollow:8,underline:9,onClick:10,targetBlank:11,useDeprecatedJS:12})}}const{window:el}=Fa,sl=o=>({}),fa=o=>({slot:"button"});function ma(o,e,l){const t=o.slice();return t[11]=e[l].label,t[12]=e[l].value,t}const tl=o=>({}),ha=o=>({slot:"menu"}),al=o=>({}),da=o=>({slot:"button"});function ga(o,e,l){const t=o.slice();return t[11]=e[l].label,t[12]=e[l].value,t}const ll=o=>({}),ba=o=>({slot:"menu"}),nl=o=>({}),wa=o=>({});function rl(o){let e,l;return e=new Ua({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[ul],button:[cl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&1024&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function ol(o){let e,l,t;return{c(){e=_("a"),l=_("img"),this.h()},l(s){e=M(s,"A",{href:!0,target:!0});var r=z(e);l=M(r,"IMG",{alt:!0,class:!0,src:!0}),r.forEach(i),this.h()},h(){y(l,"alt","Open In Colab"),y(l,"class","!m-0"),bt(l.src,t="https://colab.research.google.com/assets/colab-badge.svg")||y(l,"src",t),y(e,"href",o[2][0].value),y(e,"target","_blank")},m(s,r){f(s,e,r),H(e,l)},p:Y,i:Y,o:Y,d(s){s&&i(e)}}}function il(o){let e,l;return{c(){e=_("img"),this.h()},l(t){e=M(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){y(e,"alt","Open In Colab"),y(e,"class","!m-0"),bt(e.src,l="https://colab.research.google.com/assets/colab-badge.svg")||y(e,"src",l)},m(t,s){f(t,e,s)},p:Y,d(t){t&&i(e)}}}function cl(o){let e;const l=o[6].default,t=q(l,o,o[10],da),s=t||il();return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,al):S(r[10]),da)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function ja(o){let e,l;function t(){return o[7](o[12])}return e=new Ca({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:o[11],onClick:t,useDeprecatedJS:!1}}),{c(){k(e.$$.fragment)},l(s){$(e.$$.fragment,s)},m(s,r){T(e,s,r),l=!0},p(s,r){o=s},i(s){l||(m(e.$$.fragment,s),l=!0)},o(s){h(e.$$.fragment,s),l=!1},d(s){J(e,s)}}}function pl(o){let e,l,t=gt(o[2]),s=[];for(let n=0;n<t.length;n+=1)s[n]=ja(ga(o,t,n));const r=n=>h(s[n],1,1,()=>{s[n]=null});return{c(){for(let n=0;n<s.length;n+=1)s[n].c();e=L()},l(n){for(let c=0;c<s.length;c+=1)s[c].l(n);e=L()},m(n,c){for(let u=0;u<s.length;u+=1)s[u]&&s[u].m(n,c);f(n,e,c),l=!0},p(n,c){if(c&4){t=gt(n[2]);let u;for(u=0;u<t.length;u+=1){const w=ga(n,t,u);s[u]?(s[u].p(w,c),m(s[u],1)):(s[u]=ja(w),s[u].c(),m(s[u],1),s[u].m(e.parentNode,e))}for(A(),u=t.length;u<s.length;u+=1)r(u);x()}},i(n){if(!l){for(let c=0;c<t.length;c+=1)m(s[c]);l=!0}},o(n){s=s.filter(Boolean);for(let c=0;c<s.length;c+=1)h(s[c]);l=!1},d(n){n&&i(e),va(s,n)}}}function ul(o){let e;const l=o[6].default,t=q(l,o,o[10],ba),s=t||pl(o);return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,ll):S(r[10]),ba)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function fl(o){let e,l;return e=new Ua({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[bl],button:[dl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&1024&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function ml(o){let e,l,t;return{c(){e=_("a"),l=_("img"),this.h()},l(s){e=M(s,"A",{href:!0,target:!0});var r=z(e);l=M(r,"IMG",{alt:!0,class:!0,src:!0}),r.forEach(i),this.h()},h(){y(l,"alt","Open In Studio Lab"),y(l,"class","!m-0"),bt(l.src,t="https://studiolab.sagemaker.aws/studiolab.svg")||y(l,"src",t),y(e,"href",o[3][0].value),y(e,"target","_blank")},m(s,r){f(s,e,r),H(e,l)},p:Y,i:Y,o:Y,d(s){s&&i(e)}}}function hl(o){let e,l;return{c(){e=_("img"),this.h()},l(t){e=M(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){y(e,"alt","Open In Studio Lab"),y(e,"class","!m-0"),bt(e.src,l="https://studiolab.sagemaker.aws/studiolab.svg")||y(e,"src",l)},m(t,s){f(t,e,s)},p:Y,d(t){t&&i(e)}}}function dl(o){let e;const l=o[6].default,t=q(l,o,o[10],fa),s=t||hl();return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,sl):S(r[10]),fa)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function _a(o){let e,l;function t(){return o[8](o[12])}return e=new Ca({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:o[11],onClick:t,useDeprecatedJS:!1}}),{c(){k(e.$$.fragment)},l(s){$(e.$$.fragment,s)},m(s,r){T(e,s,r),l=!0},p(s,r){o=s},i(s){l||(m(e.$$.fragment,s),l=!0)},o(s){h(e.$$.fragment,s),l=!1},d(s){J(e,s)}}}function gl(o){let e,l,t=gt(o[3]),s=[];for(let n=0;n<t.length;n+=1)s[n]=_a(ma(o,t,n));const r=n=>h(s[n],1,1,()=>{s[n]=null});return{c(){for(let n=0;n<s.length;n+=1)s[n].c();e=L()},l(n){for(let c=0;c<s.length;c+=1)s[c].l(n);e=L()},m(n,c){for(let u=0;u<s.length;u+=1)s[u]&&s[u].m(n,c);f(n,e,c),l=!0},p(n,c){if(c&8){t=gt(n[3]);let u;for(u=0;u<t.length;u+=1){const w=ma(n,t,u);s[u]?(s[u].p(w,c),m(s[u],1)):(s[u]=_a(w),s[u].c(),m(s[u],1),s[u].m(e.parentNode,e))}for(A(),u=t.length;u<s.length;u+=1)r(u);x()}},i(n){if(!l){for(let c=0;c<t.length;c+=1)m(s[c]);l=!0}},o(n){s=s.filter(Boolean);for(let c=0;c<s.length;c+=1)h(s[c]);l=!1},d(n){n&&i(e),va(s,n)}}}function bl(o){let e;const l=o[6].default,t=q(l,o,o[10],ha),s=t||gl(o);return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,tl):S(r[10]),ha)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function wl(o){let e,l,t,s,r,n,c,u,w,G,v;const C=o[6].alwaysVisible,U=q(C,o,o[10],wa),b=[ol,rl],j=[];function N(Z,B){return Z[2].length===1?0:Z[2].length>1?1:-1}~(t=N(o))&&(s=j[t]=b[t](o));const X=[ml,fl],V=[];function R(Z,B){return Z[3].length===1?0:Z[3].length>1?1:-1}return~(n=R(o))&&(c=V[n]=X[n](o)),{c(){e=_("div"),U&&U.c(),l=d(),s&&s.c(),r=d(),c&&c.c(),this.h()},l(Z){e=M(Z,"DIV",{class:!0});var B=z(e);U&&U.l(B),l=g(B),s&&s.l(B),r=g(B),c&&c.l(B),B.forEach(i),this.h()},h(){y(e,"class",u="flex space-x-1 "+o[0])},m(Z,B){f(Z,e,B),U&&U.m(e,null),H(e,l),~t&&j[t].m(e,null),H(e,r),~n&&V[n].m(e,null),o[9](e),w=!0,G||(v=wt(el,"resize",o[4]),G=!0)},p(Z,[B]){U&&U.p&&(!w||B&1024)&&Q(U,C,Z,Z[10],w?D(C,Z[10],B,nl):S(Z[10]),wa),s&&s.p(Z,B),c&&c.p(Z,B),(!w||B&1&&u!==(u="flex space-x-1 "+Z[0]))&&y(e,"class",u)},i(Z){w||(m(U,Z),m(s),m(c),w=!0)},o(Z){h(U,Z),h(s),h(c),w=!1},d(Z){Z&&i(e),U&&U.d(Z),~t&&j[t].d(),~n&&V[n].d(),o[9](null),G=!1,v()}}}function Ma(o){window.open(o)}function jl(o,e,l){let{$$slots:t={},$$scope:s}=e,{options:r=[]}=e,{classNames:n=""}=e,c;const u=r.filter(b=>b.value.includes("colab.research.google.com")),w=r.filter(b=>b.value.includes("studiolab.sagemaker.aws"));function G(){const b=document.querySelector(".prose-doc h1"),j=document.querySelector(".prose-doc h1 > span");if(b&&j){const{width:N}=b.getBoundingClientRect(),{width:X}=j.getBoundingClientRect();let V=0;for(let Z=0;Z<c.children.length;Z++){const B=c.children.item(Z);B&&(V+=B.clientWidth)}const R=20;N-X<V+R?c.classList.remove("absolute"):c.classList.add("absolute")}}yt(()=>{(async()=>(await Ia(),G()))()});const v=b=>Ma(b),C=b=>Ma(b);function U(b){kt[b?"unshift":"push"](()=>{c=b,l(1,c)})}return o.$$set=b=>{"options"in b&&l(5,r=b.options),"classNames"in b&&l(0,n=b.classNames),"$$scope"in b&&l(10,s=b.$$scope)},[n,c,u,w,G,r,t,v,C,U,s]}class _l extends is{constructor(e){super(),cs(this,e,jl,wl,os,{options:5,classNames:0})}}function Ml(o){let e,l='Check out <a href="https://huggingface.co/course/chapter5/1?fw=pt" rel="nofollow">Chapter 5</a> of the Hugging Face course to learn more about other important topics such as loading remote or local datasets, tools for cleaning up a dataset, and creating your own dataset.';return{c(){e=_("p"),e.innerHTML=l},l(t){e=M(t,"P",{"data-svelte-h":!0}),I(e)!=="svelte-cjedd4"&&(e.innerHTML=l)},m(t,s){f(t,e,s)},p:Y,d(t){t&&i(e)}}}function yl(o){let e,l;return e=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRvcmNo",highlighted:"pip install torch",wrap:!1}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p:Y,i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function kl(o){let e,l;return e=new te({props:{$$slots:{default:[yl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Tl(o){let e,l;return e=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRlbnNvcmZsb3c=",highlighted:"pip install tensorflow",wrap:!1}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p:Y,i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Jl(o){let e,l;return e=new te({props:{$$slots:{default:[Tl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function $l(o){let e,l='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.set_format">set_format()</a> function to set the dataset format to <code>torch</code> and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in <a href="https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader" rel="nofollow"><code>torch.utils.data.DataLoader</code></a>:',t,s,r;return s=new W({props:{code:"ZnJvbSUyMHRvcmNoLnV0aWxzLmRhdGElMjBpbXBvcnQlMjBEYXRhTG9hZGVyJTBBJTBBZGF0YXNldC5zZXRfZm9ybWF0KHR5cGUlM0QlMjJ0b3JjaCUyMiUyQyUyMGNvbHVtbnMlM0QlNUIlMjJpbnB1dF92YWx1ZXMlMjIlMkMlMjAlMjJsYWJlbHMlMjIlNUQpJTBBZGF0YWxvYWRlciUyMCUzRCUyMERhdGFMb2FkZXIoZGF0YXNldCUyQyUyMGJhdGNoX3NpemUlM0Q0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_format(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;input_values&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">4</span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-z0rl04"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function vl(o){let e,l;return e=new te({props:{$$slots:{default:[$l]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Ul(o){let e,l=`Use the <a href="https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset" rel="nofollow">prepare_tf_dataset</a> method from ðŸ¤— Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a> as a <code>tf.data.Dataset</code>
with collation and batching, so one can pass it directly to Keras methods like <code>fit()</code> without further modification.`,t,s,r;return s=new W({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNENCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-1wenvpa"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Cl(o){let e,l;return e=new te({props:{$$slots:{default:[Ul]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Il(o){let e,l='Wrap the dataset in <a href="https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader" rel="nofollow"><code>torch.utils.data.DataLoader</code></a>. Youâ€™ll also need to create a collate function to collate the samples into batches:',t,s,r;return s=new W({props:{code:"ZnJvbSUyMHRvcmNoLnV0aWxzLmRhdGElMjBpbXBvcnQlMjBEYXRhTG9hZGVyJTBBJTBBZGVmJTIwY29sbGF0ZV9mbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBpbWFnZXMlMjAlM0QlMjAlNUIlNUQlMEElMjAlMjAlMjAlMjBsYWJlbHMlMjAlM0QlMjAlNUIlNUQlMEElMjAlMjAlMjAlMjBmb3IlMjBleGFtcGxlJTIwaW4lMjBleGFtcGxlcyUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGltYWdlcy5hcHBlbmQoKGV4YW1wbGUlNUIlMjJwaXhlbF92YWx1ZXMlMjIlNUQpKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxhYmVscy5hcHBlbmQoZXhhbXBsZSU1QiUyMmxhYmVscyUyMiU1RCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMEElMjAlMjAlMjAlMjBwaXhlbF92YWx1ZXMlMjAlM0QlMjB0b3JjaC5zdGFjayhpbWFnZXMpJTBBJTIwJTIwJTIwJTIwbGFiZWxzJTIwJTNEJTIwdG9yY2gudGVuc29yKGxhYmVscyklMEElMjAlMjAlMjAlMjByZXR1cm4lMjAlN0IlMjJwaXhlbF92YWx1ZXMlMjIlM0ElMjBwaXhlbF92YWx1ZXMlMkMlMjAlMjJsYWJlbHMlMjIlM0ElMjBsYWJlbHMlN0QlMEFkYXRhbG9hZGVyJTIwJTNEJTIwRGF0YUxvYWRlcihkYXRhc2V0JTJDJTIwY29sbGF0ZV9mbiUzRGNvbGxhdGVfZm4lMkMlMjBiYXRjaF9zaXplJTNENCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    images = []
<span class="hljs-meta">... </span>    labels = []
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> examples:
<span class="hljs-meta">... </span>        images.append((example[<span class="hljs-string">&quot;pixel_values&quot;</span>]))
<span class="hljs-meta">... </span>        labels.append(example[<span class="hljs-string">&quot;labels&quot;</span>])
<span class="hljs-meta">... </span>        
<span class="hljs-meta">... </span>    pixel_values = torch.stack(images)
<span class="hljs-meta">... </span>    labels = torch.tensor(labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;pixel_values&quot;</span>: pixel_values, <span class="hljs-string">&quot;labels&quot;</span>: labels}
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=<span class="hljs-number">4</span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-lbzzax"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Gl(o){let e,l;return e=new te({props:{$$slots:{default:[Il]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Rl(o){let e,l=`Use the <a href="https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset" rel="nofollow">prepare_tf_dataset</a> method from ðŸ¤— Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a> as a <code>tf.data.Dataset</code>
with collation and batching, so one can pass it directly to Keras methods like <code>fit()</code> without further modification.`,t,s,r="Before you start, make sure you have up-to-date versions of <code>albumentations</code> and <code>cv2</code> installed:",n,c,u,w,G;return c=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1VJTIwYWxidW1lbnRhdGlvbnMlMjBvcGVuY3YtcHl0aG9u",highlighted:"pip install -U albumentations opencv-python",wrap:!1}}),w=new W({props:{code:"aW1wb3J0JTIwYWxidW1lbnRhdGlvbnMlMEFpbXBvcnQlMjBudW1weSUyMGFzJTIwbnAlMEElMEF0cmFuc2Zvcm0lMjAlM0QlMjBhbGJ1bWVudGF0aW9ucy5Db21wb3NlKCU1QiUwQSUyMCUyMCUyMCUyMGFsYnVtZW50YXRpb25zLlJhbmRvbUNyb3Aod2lkdGglM0QyNTYlMkMlMjBoZWlnaHQlM0QyNTYpJTJDJTBBJTIwJTIwJTIwJTIwYWxidW1lbnRhdGlvbnMuSG9yaXpvbnRhbEZsaXAocCUzRDAuNSklMkMlMEElMjAlMjAlMjAlMjBhbGJ1bWVudGF0aW9ucy5SYW5kb21CcmlnaHRuZXNzQ29udHJhc3QocCUzRDAuMiklMkMlMEElNUQpJTBBJTBBZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHRyYW5zZm9ybShpbWFnZSUzRG5wLmFycmF5KGltYWdlKSklNUIlMjJpbWFnZSUyMiU1RCUyMGZvciUyMGltYWdlJTIwaW4lMjBleGFtcGxlcyU1QiUyMmltYWdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwJTVEJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwZXhhbXBsZXMlMEElMEFkYXRhc2V0LnNldF90cmFuc2Zvcm0odHJhbnNmb3JtcyklMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNENCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> albumentations
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-meta">&gt;&gt;&gt; </span>transform = albumentations.Compose([
<span class="hljs-meta">... </span>    albumentations.RandomCrop(width=<span class="hljs-number">256</span>, height=<span class="hljs-number">256</span>),
<span class="hljs-meta">... </span>    albumentations.HorizontalFlip(p=<span class="hljs-number">0.5</span>),
<span class="hljs-meta">... </span>    albumentations.RandomBrightnessContrast(p=<span class="hljs-number">0.2</span>),
<span class="hljs-meta">... </span>])

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [
<span class="hljs-meta">... </span>        transform(image=np.array(image))[<span class="hljs-string">&quot;image&quot;</span>] <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),s=_("p"),s.innerHTML=r,n=d(),k(c.$$.fragment),u=d(),k(w.$$.fragment)},l(v){e=M(v,"P",{"data-svelte-h":!0}),I(e)!=="svelte-9fpjyy"&&(e.innerHTML=l),t=g(v),s=M(v,"P",{"data-svelte-h":!0}),I(s)!=="svelte-1qtuikq"&&(s.innerHTML=r),n=g(v),$(c.$$.fragment,v),u=g(v),$(w.$$.fragment,v)},m(v,C){f(v,e,C),f(v,t,C),f(v,s,C),f(v,n,C),T(c,v,C),f(v,u,C),T(w,v,C),G=!0},p:Y,i(v){G||(m(c.$$.fragment,v),m(w.$$.fragment,v),G=!0)},o(v){h(c.$$.fragment,v),h(w.$$.fragment,v),G=!1},d(v){v&&(i(e),i(t),i(s),i(n),i(u)),J(c,v),J(w,v)}}}function Zl(o){let e,l;return e=new te({props:{$$slots:{default:[Rl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Nl(o){let e,l='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.set_format">set_format()</a> function to set the dataset format to <code>torch</code> and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in <a href="https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader" rel="nofollow"><code>torch.utils.data.DataLoader</code></a>:',t,s,r;return s=new W({props:{code:"aW1wb3J0JTIwdG9yY2glMEElMEFkYXRhc2V0LnNldF9mb3JtYXQodHlwZSUzRCUyMnRvcmNoJTIyJTJDJTIwY29sdW1ucyUzRCU1QiUyMmlucHV0X2lkcyUyMiUyQyUyMCUyMnRva2VuX3R5cGVfaWRzJTIyJTJDJTIwJTIyYXR0ZW50aW9uX21hc2slMjIlMkMlMjAlMjJsYWJlbHMlMjIlNUQpJTBBZGF0YWxvYWRlciUyMCUzRCUyMHRvcmNoLnV0aWxzLmRhdGEuRGF0YUxvYWRlcihkYXRhc2V0JTJDJTIwYmF0Y2hfc2l6ZSUzRDMyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_format(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="hljs-number">32</span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-z0rl04"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Fl(o){let e,l;return e=new te({props:{$$slots:{default:[Nl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Wl(o){let e,l=`Use the <a href="https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset" rel="nofollow">prepare_tf_dataset</a> method from ðŸ¤— Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a> as a <code>tf.data.Dataset</code>
with collation and batching, so one can pass it directly to Keras methods like <code>fit()</code> without further modification.`,t,s,r;return s=new W({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNENCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-1wenvpa"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Bl(o){let e,l;return e=new te({props:{$$slots:{default:[Wl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Vl(o){let e,l,t,s,r,n,c,u,w,G='This quickstart is intended for developers who are ready to dive into the code and see an example of how to integrate ðŸ¤— Datasets into their model training workflow. If youâ€™re a beginner, we recommend starting with our <a href="./tutorial">tutorials</a>, where youâ€™ll get a more thorough introduction.',v,C,U='Each dataset is unique, and depending on the task, some datasets may require additional steps to prepare it for training. But you can always use ðŸ¤— Datasets tools to load and process a dataset. The fastest and easiest way to get started is by loading an existing dataset from the <a href="https://huggingface.co/datasets" rel="nofollow">Hugging Face Hub</a>. There are thousands of datasets to choose from, spanning many tasks. Choose the type of dataset you want to work with, and letâ€™s get started!',b,j,N='<div class="w-full flex flex-col space-y-4 md:space-y-0 md:grid md:grid-cols-3 md:gap-y-4 md:gap-x-5"><a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#audio"><div class="w-full text-center bg-gradient-to-r from-violet-300 via-sky-400 to-green-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">Audio</div> <p class="text-gray-700">Resample an audio dataset and get it ready for a model to classify what type of banking issue a speaker is calling about.</p></a> <a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#vision"><div class="w-full text-center bg-gradient-to-r from-pink-400 via-purple-400 to-blue-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">Vision</div> <p class="text-gray-700">Apply data augmentation to an image dataset and get it ready for a model to diagnose disease in bean plants.</p></a> <a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#nlp"><div class="w-full text-center bg-gradient-to-r from-orange-300 via-red-400 to-violet-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">NLP</div> <p class="text-gray-700">Tokenize a dataset and get it ready for a model to determine whether a pair of sentences have the same meaning.</p></a></div>',X,V,R,Z,B="Start by installing ðŸ¤— Datasets:",F,E,fs,ae,Tt="ðŸ¤— Datasets also support audio and image data formats:",ms,P,le,ns,Jt='To work with audio datasets, install the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Audio">Audio</a> feature:',jt,ne,_t,re,rs,$t='To work with image datasets, install the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Image">Image</a> feature:',Mt,oe,hs,ie,vt="Besides ðŸ¤— Datasets, make sure your preferred machine learning framework is installed:",ds,K,gs,ce,bs,pe,Ut='Audio datasets are loaded just like text datasets. However, an audio dataset is preprocessed a bit differently. Instead of a tokenizer, youâ€™ll need a <a href="https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor" rel="nofollow">feature extractor</a>. An audio input may also require resampling its sampling rate to match the sampling rate of the pretrained model youâ€™re using. In this quickstart, youâ€™ll prepare the <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> dataset for a model train on and classify the banking issue a customer is having.',ws,ue,Ct='<strong>1</strong>. Load the MInDS-14 dataset by providing the <a href="/docs/datasets/v3.6.0/en/package_reference/loading_methods#datasets.load_dataset">load_dataset()</a> function with the dataset name, dataset configuration (not all datasets will have a configuration), and a dataset split:',js,fe,_s,me,It='<strong>2</strong>. Next, load a pretrained <a href="https://huggingface.co/facebook/wav2vec2-base" rel="nofollow">Wav2Vec2</a> model and its corresponding feature extractor from the <a href="https://huggingface.co/transformers/" rel="nofollow">ðŸ¤— Transformers</a> library. It is totally normal to see a warning after you load the model about some weights not being initialized. This is expected because you are loading this model checkpoint for training with another task.',Ms,he,ys,de,Gt='<strong>3</strong>. The <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> dataset card indicates the sampling rate is 8kHz, but the Wav2Vec2 model was pretrained on a sampling rate of 16kHZ. Youâ€™ll need to upsample the <code>audio</code> column with the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.cast_column">cast_column()</a> function and <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Audio">Audio</a> feature to match the modelâ€™s sampling rate.',ks,ge,Ts,be,Rt="<strong>4</strong>. Create a function to preprocess the audio <code>array</code> with the feature extractor, and truncate and pad the sequences into tidy rectangular tensors. The most important thing to remember is to call the audio <code>array</code> in the feature extractor since the <code>array</code> - the actual speech signal - is the model input.",Js,we,Zt='Once you have a preprocessing function, use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> function to speed up processing by applying the function to batches of examples in the dataset.',$s,je,vs,_e,Nt='<strong>5</strong>. Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.rename_column">rename_column()</a> function to rename the <code>intent_class</code> column to <code>labels</code>, which is the expected input name in <a href="https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification" rel="nofollow">Wav2Vec2ForSequenceClassification</a>:',Us,Me,Cs,ye,Ft="<strong>6</strong>. Set the dataset format according to the machine learning framework youâ€™re using.",Is,O,Gs,ke,Wt='<strong>7</strong>. Start training with your machine learning framework! Check out the ðŸ¤— Transformers <a href="https://huggingface.co/docs/transformers/tasks/audio_classification" rel="nofollow">audio classification guide</a> for an end-to-end example of how to train a model on an audio dataset.',Rs,Te,Zs,Je,Bt='Image datasets are loaded just like text datasets. However, instead of a tokenizer, youâ€™ll need a <a href="https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor" rel="nofollow">feature extractor</a> to preprocess the dataset. Applying data augmentation to an image is common in computer vision to make the model more robust against overfitting. Youâ€™re free to use any data augmentation library you want, and then you can apply the augmentations with ðŸ¤— Datasets. In this quickstart, youâ€™ll load the <a href="https://huggingface.co/datasets/beans" rel="nofollow">Beans</a> dataset and get it ready for the model to train on and identify disease from the leaf images.',Ns,$e,Vt='<strong>1</strong>. Load the Beans dataset by providing the <a href="/docs/datasets/v3.6.0/en/package_reference/loading_methods#datasets.load_dataset">load_dataset()</a> function with the dataset name and a dataset split:',Fs,ve,Ws,Ue,Xt='Most image models work with RBG images. If your dataset contains images in a different mode, you can use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.cast_column">cast_column()</a> function to set the mode to RGB:',Bs,Ce,Vs,Ie,Yt="The Beans dataset contains only RGB images, so this step is unnecessary here.",Xs,Ge,Ht='<strong>2</strong>. Now you can add some data augmentations with any library (<a href="https://albumentations.ai/" rel="nofollow">Albumentations</a>, <a href="https://imgaug.readthedocs.io/en/latest/" rel="nofollow">imgaug</a>, <a href="https://kornia.readthedocs.io/en/latest/" rel="nofollow">Kornia</a>) you like. Here, youâ€™ll use <a href="https://pytorch.org/vision/stable/transforms.html" rel="nofollow">torchvision</a> to randomly change the color properties of an image:',Ys,Re,Hs,Ze,zt="<strong>3</strong>. Create a function to apply your transform to the dataset and generate the model input: <code>pixel_values</code>.",zs,Ne,Es,Fe,Et='<strong>4</strong>. Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.with_transform">with_transform()</a> function to apply the data augmentations on-the-fly:',As,We,xs,Be,At="<strong>5</strong>. Set the dataset format according to the machine learning framework youâ€™re using.",Ls,ee,qs,Ve,xt='<strong>6</strong>. Start training with your machine learning framework! Check out the ðŸ¤— Transformers <a href="https://huggingface.co/docs/transformers/tasks/image_classification" rel="nofollow">image classification guide</a> for an end-to-end example of how to train a model on an image dataset.',Qs,Xe,Ss,Ye,Lt='Text needs to be tokenized into individual tokens by a <a href="https://huggingface.co/docs/transformers/main_classes/tokenizer" rel="nofollow">tokenizer</a>. For the quickstart, youâ€™ll load the <a href="https://huggingface.co/datasets/glue/viewer/mrpc" rel="nofollow">Microsoft Research Paraphrase Corpus (MRPC)</a> training dataset to train a model to determine whether a pair of sentences mean the same thing.',Ds,He,qt='<strong>1</strong>. Load the MRPC dataset by providing the <a href="/docs/datasets/v3.6.0/en/package_reference/loading_methods#datasets.load_dataset">load_dataset()</a> function with the dataset name, dataset configuration (not all datasets will have a configuration), and dataset split:',Ps,ze,Ks,Ee,Qt='<strong>2</strong>. Next, load a pretrained <a href="https://huggingface.co/bert-base-uncased" rel="nofollow">BERT</a> model and its corresponding tokenizer from the <a href="https://huggingface.co/transformers/" rel="nofollow">ðŸ¤— Transformers</a> library. It is totally normal to see a warning after you load the model about some weights not being initialized. This is expected because you are loading this model checkpoint for training with another task.',Os,Ae,et,xe,St="<strong>3</strong>. Create a function to tokenize the dataset, and you should also truncate and pad the text into tidy rectangular tensors. The tokenizer generates three new columns in the dataset: <code>input_ids</code>, <code>token_type_ids</code>, and an <code>attention_mask</code>. These are the model inputs.",st,Le,Dt='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> function to speed up processing by applying your tokenization function to batches of examples in the dataset:',tt,qe,at,Qe,Pt='<strong>4</strong>. Rename the <code>label</code> column to <code>labels</code>, which is the expected input name in <a href="https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification" rel="nofollow">BertForSequenceClassification</a>:',lt,Se,nt,De,Kt="<strong>5</strong>. Set the dataset format according to the machine learning framework youâ€™re using.",rt,se,ot,Pe,Ot='<strong>6</strong>. Start training with your machine learning framework! Check out the ðŸ¤— Transformers <a href="https://huggingface.co/docs/transformers/tasks/sequence_classification" rel="nofollow">text classification guide</a> for an end-to-end example of how to train a model on a text dataset.',it,Ke,ct,Oe,ea="This completes the ðŸ¤— Datasets quickstart! You can load any text, audio, or image dataset with a single function and get it ready for your model to train on.",pt,es,sa='For your next steps, take a look at our <a href="./how_to">How-to guides</a> and learn how to do more specific things like loading different dataset formats, aligning labels, and streaming large datasets. If youâ€™re interested in learning more about ðŸ¤— Datasets core concepts, grab a cup of coffee and read our <a href="./about_arrow">Conceptual Guides</a>!',ut,ss,ft,ps,mt;return r=new us({props:{title:"Quickstart",local:"quickstart",headingTag:"h1"}}),c=new _l({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/quickstart.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/pytorch/quickstart.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/tensorflow/quickstart.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/datasets_doc/en/quickstart.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/datasets_doc/en/pytorch/quickstart.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/datasets_doc/en/tensorflow/quickstart.ipynb"}]}}),V=new Za({props:{$$slots:{default:[Ml]},$$scope:{ctx:o}}}),E=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRz",highlighted:"pip install datasets",wrap:!1}}),ne=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRzJTVCYXVkaW8lNUQ=",highlighted:"pip install datasets[audio]",wrap:!1}}),oe=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRzJTVCdmlzaW9uJTVE",highlighted:"pip install datasets[vision]",wrap:!1}}),K=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Jl],pytorch:[kl]},$$scope:{ctx:o}}}),ce=new us({props:{title:"Audio",local:"audio",headingTag:"h2"}}),fe=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjAlMjJlbi1VUyUyMiUyQyUyMHNwbGl0JTNEJTIydHJhaW4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, <span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),he=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckF1ZGlvQ2xhc3NpZmljYXRpb24lMkMlMjBBdXRvRmVhdHVyZUV4dHJhY3RvciUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQXVkaW9DbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZ3YXYydmVjMi1iYXNlJTIyKSUwQWZlYXR1cmVfZXh0cmFjdG9yJTIwJTNEJTIwQXV0b0ZlYXR1cmVFeHRyYWN0b3IuZnJvbV9wcmV0cmFpbmVkKCUyMmZhY2Vib29rJTJGd2F2MnZlYzItYmFzZSUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForAudioClassification, AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`,wrap:!1}}),ge=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEMTYwMDApKSUwQWRhdGFzZXQlNUIwJTVEJTVCJTIyYXVkaW8lMjIlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">2.3443763e-05</span>,  <span class="hljs-number">2.1729663e-04</span>,  <span class="hljs-number">2.2145823e-04</span>, ...,
         <span class="hljs-number">3.8356509e-05</span>, -<span class="hljs-number">7.3497440e-06</span>, -<span class="hljs-number">2.1754686e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`,wrap:!1}}),je=new W({props:{code:"ZGVmJTIwcHJlcHJvY2Vzc19mdW5jdGlvbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBhdWRpb19hcnJheXMlMjAlM0QlMjAlNUJ4JTVCJTIyYXJyYXklMjIlNUQlMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlcyU1QiUyMmF1ZGlvJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwaW5wdXRzJTIwJTNEJTIwZmVhdHVyZV9leHRyYWN0b3IoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwYXVkaW9fYXJyYXlzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwc2FtcGxpbmdfcmF0ZSUzRDE2MDAwJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcGFkZGluZyUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNEMTAwMDAwJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjApJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW5wdXRzJTBBJTBBZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKHByZXByb2Nlc3NfZnVuY3Rpb24lMkMlMjBiYXRjaGVkJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    audio_arrays = [x[<span class="hljs-string">&quot;array&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;audio&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = feature_extractor(
<span class="hljs-meta">... </span>        audio_arrays,
<span class="hljs-meta">... </span>        sampling_rate=<span class="hljs-number">16000</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">100000</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)`,wrap:!1}}),Me=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQucmVuYW1lX2NvbHVtbiglMjJpbnRlbnRfY2xhc3MlMjIlMkMlMjAlMjJsYWJlbHMlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.rename_column(<span class="hljs-string">&quot;intent_class&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)',wrap:!1}}),O=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Cl],pytorch:[vl]},$$scope:{ctx:o}}}),Te=new us({props:{title:"Vision",local:"vision",headingTag:"h2"}}),ve=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwSW1hZ2UlMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMkFJLUxhYi1NYWtlcmVyZSUyRmJlYW5zJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;AI-Lab-Makerere/beans&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),Ce=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyaW1hZ2UlMjIlMkMlMjBJbWFnZShtb2RlJTNEJTIyUkdCJTIyKSk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;image&quot;</span>, Image(mode=<span class="hljs-string">&quot;RGB&quot;</span>))',wrap:!1}}),Re=new W({props:{code:"ZnJvbSUyMHRvcmNodmlzaW9uLnRyYW5zZm9ybXMlMjBpbXBvcnQlMjBDb21wb3NlJTJDJTIwQ29sb3JKaXR0ZXIlMkMlMjBUb1RlbnNvciUwQSUwQWppdHRlciUyMCUzRCUyMENvbXBvc2UoJTBBJTIwJTIwJTIwJTIwJTVCQ29sb3JKaXR0ZXIoYnJpZ2h0bmVzcyUzRDAuNSUyQyUyMGh1ZSUzRDAuNSklMkMlMjBUb1RlbnNvcigpJTVEJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>    [ColorJitter(brightness=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>), ToTensor()]
<span class="hljs-meta">... </span>)`,wrap:!1}}),Ne=new W({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QmppdHRlcihpbWFnZS5jb252ZXJ0KCUyMlJHQiUyMikpJTIwZm9yJTIwaW1hZ2UlMjBpbiUyMGV4YW1wbGVzJTVCJTIyaW1hZ2UlMjIlNUQlNUQlMEElMjAlMjAlMjAlMjByZXR1cm4lMjBleGFtcGxlcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`,wrap:!1}}),We=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQud2l0aF90cmFuc2Zvcm0odHJhbnNmb3Jtcyk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.with_transform(transforms)',wrap:!1}}),ee=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Zl],pytorch:[Gl]},$$scope:{ctx:o}}}),Xe=new us({props:{title:"NLP",local:"nlp",headingTag:"h2"}}),ze=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJueXUtbWxsJTJGZ2x1ZSUyMiUyQyUyMCUyMm1ycGMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;nyu-mll/glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),Ae=new Na({props:{group1:{id:"pt",code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMkMlMjBBdXRvVG9rZW5pemVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJiZXJ0LWJhc2UtdW5jYXNlZCUyMiklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)`},group2:{id:"tf",code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUyQyUyMEF1dG9Ub2tlbml6ZXIlMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)`},wrap:!1}}),qe=new W({props:{code:"ZGVmJTIwZW5jb2RlKGV4YW1wbGVzKSUzQSUwQSUyMCUyMCUyMCUyMHJldHVybiUyMHRva2VuaXplcihleGFtcGxlcyU1QiUyMnNlbnRlbmNlMSUyMiU1RCUyQyUyMGV4YW1wbGVzJTVCJTIyc2VudGVuY2UyJTIyJTVEJTJDJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMjBwYWRkaW5nJTNEJTIybWF4X2xlbmd0aCUyMiklMEElMEFkYXRhc2V0JTIwJTNEJTIwZGF0YXNldC5tYXAoZW5jb2RlJTJDJTIwYmF0Y2hlZCUzRFRydWUpJTBBZGF0YXNldCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;sentence1&quot;</span>], examples[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(encode, batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: <span class="hljs-string">&#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;</span>,
<span class="hljs-string">&#x27;sentence2&#x27;</span>: <span class="hljs-string">&#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;</span>,
<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>,
<span class="hljs-string">&#x27;idx&#x27;</span>: <span class="hljs-number">0</span>,
<span class="hljs-string">&#x27;input_ids&#x27;</span>: array([  <span class="hljs-number">101</span>,  <span class="hljs-number">7277</span>,  <span class="hljs-number">2180</span>,  <span class="hljs-number">5303</span>,  <span class="hljs-number">4806</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">1711</span>,   <span class="hljs-number">117</span>,  <span class="hljs-number">2292</span>, <span class="hljs-number">1119</span>,  <span class="hljs-number">1270</span>,   <span class="hljs-number">107</span>,  <span class="hljs-number">1103</span>,  <span class="hljs-number">7737</span>,   <span class="hljs-number">107</span>,   <span class="hljs-number">117</span>,  <span class="hljs-number">1104</span>,  <span class="hljs-number">9938</span>, <span class="hljs-number">4267</span>, <span class="hljs-number">12223</span>, <span class="hljs-number">21811</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">2554</span>,   <span class="hljs-number">119</span>,   <span class="hljs-number">102</span>, <span class="hljs-number">11336</span>,  <span class="hljs-number">6732</span>, <span class="hljs-number">3384</span>,  <span class="hljs-number">1106</span>,  <span class="hljs-number">1140</span>,  <span class="hljs-number">1112</span>,  <span class="hljs-number">1178</span>,   <span class="hljs-number">107</span>,  <span class="hljs-number">1103</span>,  <span class="hljs-number">7737</span>,   <span class="hljs-number">107</span>, <span class="hljs-number">117</span>,  <span class="hljs-number">7277</span>,  <span class="hljs-number">2180</span>,  <span class="hljs-number">5303</span>,  <span class="hljs-number">4806</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">1711</span>,  <span class="hljs-number">1104</span>,  <span class="hljs-number">9938</span>, <span class="hljs-number">4267</span>, <span class="hljs-number">12223</span>, <span class="hljs-number">21811</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">2554</span>,   <span class="hljs-number">119</span>,   <span class="hljs-number">102</span>]),
<span class="hljs-string">&#x27;token_type_ids&#x27;</span>: array([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]),
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: array([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`,wrap:!1}}),Se=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKGxhbWJkYSUyMGV4YW1wbGVzJTNBJTIwJTdCJTIybGFiZWxzJTIyJTNBJTIwZXhhbXBsZXMlNUIlMjJsYWJlbCUyMiU1RCU3RCUyQyUyMGJhdGNoZWQlM0RUcnVlKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> examples: {<span class="hljs-string">&quot;labels&quot;</span>: examples[<span class="hljs-string">&quot;label&quot;</span>]}, batched=<span class="hljs-literal">True</span>)',wrap:!1}}),se=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Bl],pytorch:[Fl]},$$scope:{ctx:o}}}),Ke=new us({props:{title:"Whatâ€™s next?",local:"whats-next",headingTag:"h2"}}),ss=new Wa({props:{source:"https://github.com/huggingface/datasets/blob/main/docs/source/quickstart.mdx"}}),{c(){e=_("meta"),l=d(),t=_("p"),s=d(),k(r.$$.fragment),n=d(),k(c.$$.fragment),u=d(),w=_("p"),w.innerHTML=G,v=d(),C=_("p"),C.innerHTML=U,b=d(),j=_("div"),j.innerHTML=N,X=d(),k(V.$$.fragment),R=d(),Z=_("p"),Z.textContent=B,F=d(),k(E.$$.fragment),fs=d(),ae=_("p"),ae.textContent=Tt,ms=d(),P=_("ul"),le=_("li"),ns=_("p"),ns.innerHTML=Jt,jt=d(),k(ne.$$.fragment),_t=d(),re=_("li"),rs=_("p"),rs.innerHTML=$t,Mt=d(),k(oe.$$.fragment),hs=d(),ie=_("p"),ie.textContent=vt,ds=d(),k(K.$$.fragment),gs=d(),k(ce.$$.fragment),bs=d(),pe=_("p"),pe.innerHTML=Ut,ws=d(),ue=_("p"),ue.innerHTML=Ct,js=d(),k(fe.$$.fragment),_s=d(),me=_("p"),me.innerHTML=It,Ms=d(),k(he.$$.fragment),ys=d(),de=_("p"),de.innerHTML=Gt,ks=d(),k(ge.$$.fragment),Ts=d(),be=_("p"),be.innerHTML=Rt,Js=d(),we=_("p"),we.innerHTML=Zt,$s=d(),k(je.$$.fragment),vs=d(),_e=_("p"),_e.innerHTML=Nt,Us=d(),k(Me.$$.fragment),Cs=d(),ye=_("p"),ye.innerHTML=Ft,Is=d(),k(O.$$.fragment),Gs=d(),ke=_("p"),ke.innerHTML=Wt,Rs=d(),k(Te.$$.fragment),Zs=d(),Je=_("p"),Je.innerHTML=Bt,Ns=d(),$e=_("p"),$e.innerHTML=Vt,Fs=d(),k(ve.$$.fragment),Ws=d(),Ue=_("p"),Ue.innerHTML=Xt,Bs=d(),k(Ce.$$.fragment),Vs=d(),Ie=_("p"),Ie.textContent=Yt,Xs=d(),Ge=_("p"),Ge.innerHTML=Ht,Ys=d(),k(Re.$$.fragment),Hs=d(),Ze=_("p"),Ze.innerHTML=zt,zs=d(),k(Ne.$$.fragment),Es=d(),Fe=_("p"),Fe.innerHTML=Et,As=d(),k(We.$$.fragment),xs=d(),Be=_("p"),Be.innerHTML=At,Ls=d(),k(ee.$$.fragment),qs=d(),Ve=_("p"),Ve.innerHTML=xt,Qs=d(),k(Xe.$$.fragment),Ss=d(),Ye=_("p"),Ye.innerHTML=Lt,Ds=d(),He=_("p"),He.innerHTML=qt,Ps=d(),k(ze.$$.fragment),Ks=d(),Ee=_("p"),Ee.innerHTML=Qt,Os=d(),k(Ae.$$.fragment),et=d(),xe=_("p"),xe.innerHTML=St,st=d(),Le=_("p"),Le.innerHTML=Dt,tt=d(),k(qe.$$.fragment),at=d(),Qe=_("p"),Qe.innerHTML=Pt,lt=d(),k(Se.$$.fragment),nt=d(),De=_("p"),De.innerHTML=Kt,rt=d(),k(se.$$.fragment),ot=d(),Pe=_("p"),Pe.innerHTML=Ot,it=d(),k(Ke.$$.fragment),ct=d(),Oe=_("p"),Oe.textContent=ea,pt=d(),es=_("p"),es.innerHTML=sa,ut=d(),k(ss.$$.fragment),ft=d(),ps=_("p"),this.h()},l(a){const p=Ra("svelte-u9bgzb",document.head);e=M(p,"META",{name:!0,content:!0}),p.forEach(i),l=g(a),t=M(a,"P",{}),z(t).forEach(i),s=g(a),$(r.$$.fragment,a),n=g(a),$(c.$$.fragment,a),u=g(a),w=M(a,"P",{"data-svelte-h":!0}),I(w)!=="svelte-1gql5oj"&&(w.innerHTML=G),v=g(a),C=M(a,"P",{"data-svelte-h":!0}),I(C)!=="svelte-1gca5uw"&&(C.innerHTML=U),b=g(a),j=M(a,"DIV",{class:!0,"data-svelte-h":!0}),I(j)!=="svelte-1o5x2pv"&&(j.innerHTML=N),X=g(a),$(V.$$.fragment,a),R=g(a),Z=M(a,"P",{"data-svelte-h":!0}),I(Z)!=="svelte-hoqk88"&&(Z.textContent=B),F=g(a),$(E.$$.fragment,a),fs=g(a),ae=M(a,"P",{"data-svelte-h":!0}),I(ae)!=="svelte-mhvkco"&&(ae.textContent=Tt),ms=g(a),P=M(a,"UL",{});var ts=z(P);le=M(ts,"LI",{});var as=z(le);ns=M(as,"P",{"data-svelte-h":!0}),I(ns)!=="svelte-1t6a7b8"&&(ns.innerHTML=Jt),jt=g(as),$(ne.$$.fragment,as),as.forEach(i),_t=g(ts),re=M(ts,"LI",{});var ls=z(re);rs=M(ls,"P",{"data-svelte-h":!0}),I(rs)!=="svelte-1ez1o9h"&&(rs.innerHTML=$t),Mt=g(ls),$(oe.$$.fragment,ls),ls.forEach(i),ts.forEach(i),hs=g(a),ie=M(a,"P",{"data-svelte-h":!0}),I(ie)!=="svelte-1ixvldz"&&(ie.textContent=vt),ds=g(a),$(K.$$.fragment,a),gs=g(a),$(ce.$$.fragment,a),bs=g(a),pe=M(a,"P",{"data-svelte-h":!0}),I(pe)!=="svelte-amoo34"&&(pe.innerHTML=Ut),ws=g(a),ue=M(a,"P",{"data-svelte-h":!0}),I(ue)!=="svelte-e5og20"&&(ue.innerHTML=Ct),js=g(a),$(fe.$$.fragment,a),_s=g(a),me=M(a,"P",{"data-svelte-h":!0}),I(me)!=="svelte-2lbv45"&&(me.innerHTML=It),Ms=g(a),$(he.$$.fragment,a),ys=g(a),de=M(a,"P",{"data-svelte-h":!0}),I(de)!=="svelte-nrn9g9"&&(de.innerHTML=Gt),ks=g(a),$(ge.$$.fragment,a),Ts=g(a),be=M(a,"P",{"data-svelte-h":!0}),I(be)!=="svelte-15ly327"&&(be.innerHTML=Rt),Js=g(a),we=M(a,"P",{"data-svelte-h":!0}),I(we)!=="svelte-b7r0be"&&(we.innerHTML=Zt),$s=g(a),$(je.$$.fragment,a),vs=g(a),_e=M(a,"P",{"data-svelte-h":!0}),I(_e)!=="svelte-11c1w2v"&&(_e.innerHTML=Nt),Us=g(a),$(Me.$$.fragment,a),Cs=g(a),ye=M(a,"P",{"data-svelte-h":!0}),I(ye)!=="svelte-1yhgs5r"&&(ye.innerHTML=Ft),Is=g(a),$(O.$$.fragment,a),Gs=g(a),ke=M(a,"P",{"data-svelte-h":!0}),I(ke)!=="svelte-e7a4ym"&&(ke.innerHTML=Wt),Rs=g(a),$(Te.$$.fragment,a),Zs=g(a),Je=M(a,"P",{"data-svelte-h":!0}),I(Je)!=="svelte-zqcdgz"&&(Je.innerHTML=Bt),Ns=g(a),$e=M(a,"P",{"data-svelte-h":!0}),I($e)!=="svelte-1un4iat"&&($e.innerHTML=Vt),Fs=g(a),$(ve.$$.fragment,a),Ws=g(a),Ue=M(a,"P",{"data-svelte-h":!0}),I(Ue)!=="svelte-svx4j9"&&(Ue.innerHTML=Xt),Bs=g(a),$(Ce.$$.fragment,a),Vs=g(a),Ie=M(a,"P",{"data-svelte-h":!0}),I(Ie)!=="svelte-1skemuq"&&(Ie.textContent=Yt),Xs=g(a),Ge=M(a,"P",{"data-svelte-h":!0}),I(Ge)!=="svelte-qj39jy"&&(Ge.innerHTML=Ht),Ys=g(a),$(Re.$$.fragment,a),Hs=g(a),Ze=M(a,"P",{"data-svelte-h":!0}),I(Ze)!=="svelte-1u5korr"&&(Ze.innerHTML=zt),zs=g(a),$(Ne.$$.fragment,a),Es=g(a),Fe=M(a,"P",{"data-svelte-h":!0}),I(Fe)!=="svelte-ss0lor"&&(Fe.innerHTML=Et),As=g(a),$(We.$$.fragment,a),xs=g(a),Be=M(a,"P",{"data-svelte-h":!0}),I(Be)!=="svelte-1f1vpgi"&&(Be.innerHTML=At),Ls=g(a),$(ee.$$.fragment,a),qs=g(a),Ve=M(a,"P",{"data-svelte-h":!0}),I(Ve)!=="svelte-1m7qjra"&&(Ve.innerHTML=xt),Qs=g(a),$(Xe.$$.fragment,a),Ss=g(a),Ye=M(a,"P",{"data-svelte-h":!0}),I(Ye)!=="svelte-1rpgba6"&&(Ye.innerHTML=Lt),Ds=g(a),He=M(a,"P",{"data-svelte-h":!0}),I(He)!=="svelte-hn87b8"&&(He.innerHTML=qt),Ps=g(a),$(ze.$$.fragment,a),Ks=g(a),Ee=M(a,"P",{"data-svelte-h":!0}),I(Ee)!=="svelte-9lbdnp"&&(Ee.innerHTML=Qt),Os=g(a),$(Ae.$$.fragment,a),et=g(a),xe=M(a,"P",{"data-svelte-h":!0}),I(xe)!=="svelte-ryi2zh"&&(xe.innerHTML=St),st=g(a),Le=M(a,"P",{"data-svelte-h":!0}),I(Le)!=="svelte-13qg5o2"&&(Le.innerHTML=Dt),tt=g(a),$(qe.$$.fragment,a),at=g(a),Qe=M(a,"P",{"data-svelte-h":!0}),I(Qe)!=="svelte-1jz0ya3"&&(Qe.innerHTML=Pt),lt=g(a),$(Se.$$.fragment,a),nt=g(a),De=M(a,"P",{"data-svelte-h":!0}),I(De)!=="svelte-1f1vpgi"&&(De.innerHTML=Kt),rt=g(a),$(se.$$.fragment,a),ot=g(a),Pe=M(a,"P",{"data-svelte-h":!0}),I(Pe)!=="svelte-11yp24k"&&(Pe.innerHTML=Ot),it=g(a),$(Ke.$$.fragment,a),ct=g(a),Oe=M(a,"P",{"data-svelte-h":!0}),I(Oe)!=="svelte-zs1nfs"&&(Oe.textContent=ea),pt=g(a),es=M(a,"P",{"data-svelte-h":!0}),I(es)!=="svelte-1jspkk5"&&(es.innerHTML=sa),ut=g(a),$(ss.$$.fragment,a),ft=g(a),ps=M(a,"P",{}),z(ps).forEach(i),this.h()},h(){y(e,"name","hf:doc:metadata"),y(e,"content",Xl),y(j,"class","mt-4")},m(a,p){H(document.head,e),f(a,l,p),f(a,t,p),f(a,s,p),T(r,a,p),f(a,n,p),T(c,a,p),f(a,u,p),f(a,w,p),f(a,v,p),f(a,C,p),f(a,b,p),f(a,j,p),f(a,X,p),T(V,a,p),f(a,R,p),f(a,Z,p),f(a,F,p),T(E,a,p),f(a,fs,p),f(a,ae,p),f(a,ms,p),f(a,P,p),H(P,le),H(le,ns),H(le,jt),T(ne,le,null),H(P,_t),H(P,re),H(re,rs),H(re,Mt),T(oe,re,null),f(a,hs,p),f(a,ie,p),f(a,ds,p),T(K,a,p),f(a,gs,p),T(ce,a,p),f(a,bs,p),f(a,pe,p),f(a,ws,p),f(a,ue,p),f(a,js,p),T(fe,a,p),f(a,_s,p),f(a,me,p),f(a,Ms,p),T(he,a,p),f(a,ys,p),f(a,de,p),f(a,ks,p),T(ge,a,p),f(a,Ts,p),f(a,be,p),f(a,Js,p),f(a,we,p),f(a,$s,p),T(je,a,p),f(a,vs,p),f(a,_e,p),f(a,Us,p),T(Me,a,p),f(a,Cs,p),f(a,ye,p),f(a,Is,p),T(O,a,p),f(a,Gs,p),f(a,ke,p),f(a,Rs,p),T(Te,a,p),f(a,Zs,p),f(a,Je,p),f(a,Ns,p),f(a,$e,p),f(a,Fs,p),T(ve,a,p),f(a,Ws,p),f(a,Ue,p),f(a,Bs,p),T(Ce,a,p),f(a,Vs,p),f(a,Ie,p),f(a,Xs,p),f(a,Ge,p),f(a,Ys,p),T(Re,a,p),f(a,Hs,p),f(a,Ze,p),f(a,zs,p),T(Ne,a,p),f(a,Es,p),f(a,Fe,p),f(a,As,p),T(We,a,p),f(a,xs,p),f(a,Be,p),f(a,Ls,p),T(ee,a,p),f(a,qs,p),f(a,Ve,p),f(a,Qs,p),T(Xe,a,p),f(a,Ss,p),f(a,Ye,p),f(a,Ds,p),f(a,He,p),f(a,Ps,p),T(ze,a,p),f(a,Ks,p),f(a,Ee,p),f(a,Os,p),T(Ae,a,p),f(a,et,p),f(a,xe,p),f(a,st,p),f(a,Le,p),f(a,tt,p),T(qe,a,p),f(a,at,p),f(a,Qe,p),f(a,lt,p),T(Se,a,p),f(a,nt,p),f(a,De,p),f(a,rt,p),T(se,a,p),f(a,ot,p),f(a,Pe,p),f(a,it,p),T(Ke,a,p),f(a,ct,p),f(a,Oe,p),f(a,pt,p),f(a,es,p),f(a,ut,p),T(ss,a,p),f(a,ft,p),f(a,ps,p),mt=!0},p(a,[p]){const ts={};p&2&&(ts.$$scope={dirty:p,ctx:a}),V.$set(ts);const as={};p&2&&(as.$$scope={dirty:p,ctx:a}),K.$set(as);const ls={};p&2&&(ls.$$scope={dirty:p,ctx:a}),O.$set(ls);const ta={};p&2&&(ta.$$scope={dirty:p,ctx:a}),ee.$set(ta);const aa={};p&2&&(aa.$$scope={dirty:p,ctx:a}),se.$set(aa)},i(a){mt||(m(r.$$.fragment,a),m(c.$$.fragment,a),m(V.$$.fragment,a),m(E.$$.fragment,a),m(ne.$$.fragment,a),m(oe.$$.fragment,a),m(K.$$.fragment,a),m(ce.$$.fragment,a),m(fe.$$.fragment,a),m(he.$$.fragment,a),m(ge.$$.fragment,a),m(je.$$.fragment,a),m(Me.$$.fragment,a),m(O.$$.fragment,a),m(Te.$$.fragment,a),m(ve.$$.fragment,a),m(Ce.$$.fragment,a),m(Re.$$.fragment,a),m(Ne.$$.fragment,a),m(We.$$.fragment,a),m(ee.$$.fragment,a),m(Xe.$$.fragment,a),m(ze.$$.fragment,a),m(Ae.$$.fragment,a),m(qe.$$.fragment,a),m(Se.$$.fragment,a),m(se.$$.fragment,a),m(Ke.$$.fragment,a),m(ss.$$.fragment,a),mt=!0)},o(a){h(r.$$.fragment,a),h(c.$$.fragment,a),h(V.$$.fragment,a),h(E.$$.fragment,a),h(ne.$$.fragment,a),h(oe.$$.fragment,a),h(K.$$.fragment,a),h(ce.$$.fragment,a),h(fe.$$.fragment,a),h(he.$$.fragment,a),h(ge.$$.fragment,a),h(je.$$.fragment,a),h(Me.$$.fragment,a),h(O.$$.fragment,a),h(Te.$$.fragment,a),h(ve.$$.fragment,a),h(Ce.$$.fragment,a),h(Re.$$.fragment,a),h(Ne.$$.fragment,a),h(We.$$.fragment,a),h(ee.$$.fragment,a),h(Xe.$$.fragment,a),h(ze.$$.fragment,a),h(Ae.$$.fragment,a),h(qe.$$.fragment,a),h(Se.$$.fragment,a),h(se.$$.fragment,a),h(Ke.$$.fragment,a),h(ss.$$.fragment,a),mt=!1},d(a){a&&(i(l),i(t),i(s),i(n),i(u),i(w),i(v),i(C),i(b),i(j),i(X),i(R),i(Z),i(F),i(fs),i(ae),i(ms),i(P),i(hs),i(ie),i(ds),i(gs),i(bs),i(pe),i(ws),i(ue),i(js),i(_s),i(me),i(Ms),i(ys),i(de),i(ks),i(Ts),i(be),i(Js),i(we),i($s),i(vs),i(_e),i(Us),i(Cs),i(ye),i(Is),i(Gs),i(ke),i(Rs),i(Zs),i(Je),i(Ns),i($e),i(Fs),i(Ws),i(Ue),i(Bs),i(Vs),i(Ie),i(Xs),i(Ge),i(Ys),i(Hs),i(Ze),i(zs),i(Es),i(Fe),i(As),i(xs),i(Be),i(Ls),i(qs),i(Ve),i(Qs),i(Ss),i(Ye),i(Ds),i(He),i(Ps),i(Ks),i(Ee),i(Os),i(et),i(xe),i(st),i(Le),i(tt),i(at),i(Qe),i(lt),i(nt),i(De),i(rt),i(ot),i(Pe),i(it),i(ct),i(Oe),i(pt),i(es),i(ut),i(ft),i(ps)),i(e),J(r,a),J(c,a),J(V,a),J(E,a),J(ne),J(oe),J(K,a),J(ce,a),J(fe,a),J(he,a),J(ge,a),J(je,a),J(Me,a),J(O,a),J(Te,a),J(ve,a),J(Ce,a),J(Re,a),J(Ne,a),J(We,a),J(ee,a),J(Xe,a),J(ze,a),J(Ae,a),J(qe,a),J(Se,a),J(se,a),J(Ke,a),J(ss,a)}}}const Xl='{"title":"Quickstart","local":"quickstart","sections":[{"title":"Audio","local":"audio","sections":[],"depth":2},{"title":"Vision","local":"vision","sections":[],"depth":2},{"title":"NLP","local":"nlp","sections":[],"depth":2},{"title":"Whatâ€™s next?","local":"whats-next","sections":[],"depth":2}],"depth":1}';function Yl(o){return yt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Dl extends is{constructor(e){super(),cs(this,e,Yl,Vl,os,{})}}export{Dl as component};
