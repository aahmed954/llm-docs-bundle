import{s as os,c as q,j as ya,u as Q,g as S,d as D,o as yt,b as kt,n as Y,B as ka,t as Ia,f as bt}from"../chunks/scheduler.bdbef820.js";import{S as is,i as cs,g as _,h as M,j as z,f as i,k as y,a as f,y as H,D as wt,d as m,t as h,B as la,C as na,l as Ga,s as d,c as g,p as A,b as x,r as k,u as $,v as T,w as J,m as Ta,e as L,n as Ja,o as $a,q as dt,z as va,A as Ra,x as I}from"../chunks/index.c0aea24a.js";import{T as Za}from"../chunks/Tip.31005f7d.js";import{C as W}from"../chunks/CodeBlock.e814ab8d.js";import{C as Na}from"../chunks/CodeBlockFw.ce0c10d4.js";import{g as Fa}from"../chunks/globals.7f7f1b26.js";import{e as gt}from"../chunks/each.e59479a4.js";import{F as ht,M as te}from"../chunks/Markdown.1f17db59.js";import{H as us,E as Wa}from"../chunks/index.89e522f3.js";function Ba(o){let e,l,t,s,r,n;const c=o[7].default,u=q(c,o,o[6],null);return{c(){e=_("div"),l=_("ul"),u&&u.c(),this.h()},l(w){e=M(w,"DIV",{class:!0});var G=z(e);l=M(G,"UL",{class:!0});var v=z(l);u&&u.l(v),v.forEach(i),G.forEach(i),this.h()},h(){y(l,"class","min-w-full w-auto"),y(e,"class",t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(o[2]==="right"?"right-0":"left-0")+" "+o[0])},m(w,G){f(w,e,G),H(e,l),u&&u.m(l,null),o[8](e),s=!0,r||(n=wt(e,"click",function(){ya(o[1])&&o[1].apply(this,arguments)}),r=!0)},p(w,[G]){o=w,u&&u.p&&(!s||G&64)&&Q(u,c,o,o[6],s?D(c,o[6],G,null):S(o[6]),null),(!s||G&5&&t!==(t="absolute top-full mt-1 min-w-full w-auto bg-white rounded-xl overflow-hidden shadow-lg z-10 border border-gray-100 "+(o[2]==="right"?"right-0":"left-0")+" "+o[0]))&&y(e,"class",t)},i(w){s||(m(u,w),s=!0)},o(w){h(u,w),s=!1},d(w){w&&i(e),u&&u.d(w),o[8](null),r=!1,n()}}}function Va(o,e,l){let{$$slots:t={},$$scope:s}=e,{classNames:r=""}=e,{dropdownElement:n=void 0}=e,{forceAlignement:c=void 0}=e,{onClose:u}=e,w=c??"left",G;yt(()=>{if(document.addEventListener("click",v),!c){const U=document.documentElement.clientWidth,b=G==null?void 0:G.getBoundingClientRect(),j=(b==null?void 0:b.left)??0,N=(b==null?void 0:b.width)??0;l(2,w=j+N>U?"right":"left")}return()=>{document.removeEventListener("click",v)}});function v(U){const b=U.target;b!==n&&!(n!=null&&n.contains(b))&&u(U)}function C(U){kt[U?"unshift":"push"](()=>{G=U,l(3,G)})}return o.$$set=U=>{"classNames"in U&&l(0,r=U.classNames),"dropdownElement"in U&&l(4,n=U.dropdownElement),"forceAlignement"in U&&l(5,c=U.forceAlignement),"onClose"in U&&l(1,u=U.onClose),"$$scope"in U&&l(6,s=U.$$scope)},[r,u,w,G,n,c,s,t,C]}class Xa extends is{constructor(e){super(),cs(this,e,Va,Ba,os,{classNames:0,dropdownElement:4,forceAlignement:5,onClose:1})}}function Ya(o){let e,l;return{c(){e=la("svg"),l=la("path"),this.h()},l(t){e=na(t,"svg",{class:!0,xmlns:!0,"xmlns:xlink":!0,"aria-hidden":!0,focusable:!0,role:!0,width:!0,height:!0,preserveAspectRatio:!0,viewBox:!0,style:!0});var s=z(e);l=na(s,"path",{d:!0,fill:!0}),z(l).forEach(i),s.forEach(i),this.h()},h(){y(l,"d","M7 10l5 5l5-5z"),y(l,"fill","currentColor"),y(e,"class",o[0]),y(e,"xmlns","http://www.w3.org/2000/svg"),y(e,"xmlns:xlink","http://www.w3.org/1999/xlink"),y(e,"aria-hidden","true"),y(e,"focusable","false"),y(e,"role","img"),y(e,"width","1em"),y(e,"height","1em"),y(e,"preserveAspectRatio","xMidYMid meet"),y(e,"viewBox","0 0 24 24"),Ga(e,"transform","rotate(360deg)")},m(t,s){f(t,e,s),H(e,l)},p(t,[s]){s&1&&y(e,"class",t[0])},i:Y,o:Y,d(t){t&&i(e)}}}function Ha(o,e,l){let{classNames:t=""}=e;return o.$$set=s=>{"classNames"in s&&l(0,t=s.classNames)},[t]}class za extends is{constructor(e){super(),cs(this,e,Ha,Ya,os,{classNames:0})}}const Ea=o=>({}),ra=o=>({}),Aa=o=>({}),oa=o=>({});function xa(o){let e,l,t,s,r,n=o[2]&&ia(o),c=o[9]&&ca();return{c(){n&&n.c(),e=d(),l=Ta(o[4]),t=d(),c&&c.c(),s=L()},l(u){n&&n.l(u),e=g(u),l=Ja(u,o[4]),t=g(u),c&&c.l(u),s=L()},m(u,w){n&&n.m(u,w),f(u,e,w),f(u,l,w),f(u,t,w),c&&c.m(u,w),f(u,s,w),r=!0},p(u,w){u[2]?n?(n.p(u,w),w&4&&m(n,1)):(n=ia(u),n.c(),m(n,1),n.m(e.parentNode,e)):n&&(A(),h(n,1,1,()=>{n=null}),x()),(!r||w&16)&&$a(l,u[4]),u[9]?c?w&512&&m(c,1):(c=ca(),c.c(),m(c,1),c.m(s.parentNode,s)):c&&(A(),h(c,1,1,()=>{c=null}),x())},i(u){r||(m(n),m(c),r=!0)},o(u){h(n),h(c),r=!1},d(u){u&&(i(e),i(l),i(t),i(s)),n&&n.d(u),c&&c.d(u)}}}function La(o){let e;const l=o[15].button,t=q(l,o,o[18],oa);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,r){t&&t.m(s,r),e=!0},p(s,r){t&&t.p&&(!e||r&262144)&&Q(t,l,s,s[18],e?D(l,s[18],r,Aa):S(s[18]),oa)},i(s){e||(m(t,s),e=!0)},o(s){h(t,s),e=!1},d(s){t&&t.d(s)}}}function ia(o){let e,l,t;var s=o[2];function r(n,c){return{props:{classNames:"mr-1.5 "+n[3]}}}return s&&(e=dt(s,r(o))),{c(){e&&k(e.$$.fragment),l=L()},l(n){e&&$(e.$$.fragment,n),l=L()},m(n,c){e&&T(e,n,c),f(n,l,c),t=!0},p(n,c){if(c&4&&s!==(s=n[2])){if(e){A();const u=e;h(u.$$.fragment,1,0,()=>{J(u,1)}),x()}s?(e=dt(s,r(n)),k(e.$$.fragment),m(e.$$.fragment,1),T(e,l.parentNode,l)):e=null}else if(s){const u={};c&8&&(u.classNames="mr-1.5 "+n[3]),e.$set(u)}},i(n){t||(e&&m(e.$$.fragment,n),t=!0)},o(n){e&&h(e.$$.fragment,n),t=!1},d(n){n&&i(l),e&&J(e,n)}}}function ca(o){let e,l;return e=new za({props:{classNames:"-mr-1 text-gray-500"}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function pa(o){let e,l;return e=new Xa({props:{classNames:o[6]+" "+(o[8]?"v2-dropdown-menu hidden":""),dropdownElement:o[10],forceAlignement:o[5],onClose:o[12],$$slots:{default:[qa]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&320&&(r.classNames=t[6]+" "+(t[8]?"v2-dropdown-menu hidden":"")),s&1024&&(r.dropdownElement=t[10]),s&32&&(r.forceAlignement=t[5]),s&262144&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function qa(o){let e;const l=o[15].menu,t=q(l,o,o[18],ra);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,r){t&&t.m(s,r),e=!0},p(s,r){t&&t.p&&(!e||r&262144)&&Q(t,l,s,s[18],e?D(l,s[18],r,Ea):S(s[18]),ra)},i(s){e||(m(t,s),e=!0)},o(s){h(t,s),e=!1},d(s){t&&t.d(s)}}}function Qa(o){let e,l,t,s,r,n,c,u,w,G;const v=[La,xa],C=[];function U(j,N){return j[13].button?0:1}t=U(o),s=C[t]=v[t](o);let b=(o[11]||o[8])&&pa(o);return{c(){e=_("div"),l=_("button"),s.c(),n=d(),b&&b.c(),this.h()},l(j){e=M(j,"DIV",{class:!0});var N=z(e);l=M(N,"BUTTON",{class:!0,type:!0});var X=z(l);s.l(X),X.forEach(i),n=g(N),b&&b.l(N),N.forEach(i),this.h()},h(){y(l,"class",r=""+o[1]+" "+(o[7]?"":"cursor-pointer w-full btn text-sm")+" "+(o[8]?"v2-dropdown-button":"")),y(l,"type","button"),y(e,"class",c="relative "+o[0]+" "+(o[8]?"v2-dropdown":""))},m(j,N){f(j,e,N),H(e,l),C[t].m(l,null),H(e,n),b&&b.m(e,null),o[17](e),u=!0,w||(G=wt(l,"click",o[16]),w=!0)},p(j,[N]){let X=t;t=U(j),t===X?C[t].p(j,N):(A(),h(C[X],1,1,()=>{C[X]=null}),x(),s=C[t],s?s.p(j,N):(s=C[t]=v[t](j),s.c()),m(s,1),s.m(l,null)),(!u||N&386&&r!==(r=""+j[1]+" "+(j[7]?"":"cursor-pointer w-full btn text-sm")+" "+(j[8]?"v2-dropdown-button":"")))&&y(l,"class",r),j[11]||j[8]?b?(b.p(j,N),N&2304&&m(b,1)):(b=pa(j),b.c(),m(b,1),b.m(e,null)):b&&(A(),h(b,1,1,()=>{b=null}),x()),(!u||N&257&&c!==(c="relative "+j[0]+" "+(j[8]?"v2-dropdown":"")))&&y(e,"class",c)},i(j){u||(m(s),m(b),u=!0)},o(j){h(s),h(b),u=!1},d(j){j&&i(e),C[t].d(),b&&b.d(),o[17](null),w=!1,G()}}}function Sa(o,e,l){let{$$slots:t={},$$scope:s}=e;const r=ka(t);let{classNames:n=""}=e,{btnClassNames:c=""}=e,{btnIcon:u=void 0}=e,{btnIconClassNames:w=""}=e,{btnLabel:G=""}=e,{forceMenuAlignement:v=void 0}=e,{menuClassNames:C=""}=e,{noBtnClass:U=void 0}=e,{selectedValue:b=void 0}=e,{useDeprecatedJS:j=!0}=e,{withBtnCaret:N=!1}=e,X,V=!1;function R(F){var E;F.target&&(E=F.target)!=null&&E.className.includes("do-not-close-dropdown")||l(11,V=!1)}const Z=()=>l(11,V=!V);function B(F){kt[F?"unshift":"push"](()=>{X=F,l(10,X)})}return o.$$set=F=>{"classNames"in F&&l(0,n=F.classNames),"btnClassNames"in F&&l(1,c=F.btnClassNames),"btnIcon"in F&&l(2,u=F.btnIcon),"btnIconClassNames"in F&&l(3,w=F.btnIconClassNames),"btnLabel"in F&&l(4,G=F.btnLabel),"forceMenuAlignement"in F&&l(5,v=F.forceMenuAlignement),"menuClassNames"in F&&l(6,C=F.menuClassNames),"noBtnClass"in F&&l(7,U=F.noBtnClass),"selectedValue"in F&&l(14,b=F.selectedValue),"useDeprecatedJS"in F&&l(8,j=F.useDeprecatedJS),"withBtnCaret"in F&&l(9,N=F.withBtnCaret),"$$scope"in F&&l(18,s=F.$$scope)},[n,c,u,w,G,v,C,U,j,N,X,V,R,r,b,t,Z,B,s]}class Ua extends is{constructor(e){super(),cs(this,e,Sa,Qa,os,{classNames:0,btnClassNames:1,btnIcon:2,btnIconClassNames:3,btnLabel:4,forceMenuAlignement:5,menuClassNames:6,noBtnClass:7,selectedValue:14,useDeprecatedJS:8,withBtnCaret:9})}}function Da(o){let e,l,t,s=o[5]&&ua(o);return{c(){s&&s.c(),e=d(),l=Ta(o[7])},l(r){s&&s.l(r),e=g(r),l=Ja(r,o[7])},m(r,n){s&&s.m(r,n),f(r,e,n),f(r,l,n),t=!0},p(r,n){r[5]?s?(s.p(r,n),n&32&&m(s,1)):(s=ua(r),s.c(),m(s,1),s.m(e.parentNode,e)):s&&(A(),h(s,1,1,()=>{s=null}),x()),(!t||n&128)&&$a(l,r[7])},i(r){t||(m(s),t=!0)},o(r){h(s),t=!1},d(r){r&&(i(e),i(l)),s&&s.d(r)}}}function Pa(o){let e;const l=o[15].default,t=q(l,o,o[14],null);return{c(){t&&t.c()},l(s){t&&t.l(s)},m(s,r){t&&t.m(s,r),e=!0},p(s,r){t&&t.p&&(!e||r&16384)&&Q(t,l,s,s[14],e?D(l,s[14],r,null):S(s[14]),null)},i(s){e||(m(t,s),e=!0)},o(s){h(t,s),e=!1},d(s){t&&t.d(s)}}}function ua(o){let e,l,t;var s=o[5];function r(n,c){return{props:{classNames:"mr-1.5 "+n[6]}}}return s&&(e=dt(s,r(o))),{c(){e&&k(e.$$.fragment),l=L()},l(n){e&&$(e.$$.fragment,n),l=L()},m(n,c){e&&T(e,n,c),f(n,l,c),t=!0},p(n,c){if(c&32&&s!==(s=n[5])){if(e){A();const u=e;h(u.$$.fragment,1,0,()=>{J(u,1)}),x()}s?(e=dt(s,r(n)),k(e.$$.fragment),m(e.$$.fragment,1),T(e,l.parentNode,l)):e=null}else if(s){const u={};c&64&&(u.classNames="mr-1.5 "+n[6]),e.$set(u)}},i(n){t||(e&&m(e.$$.fragment,n),t=!0)},o(n){e&&h(e.$$.fragment,n),t=!1},d(n){n&&i(l),e&&J(e,n)}}}function Ka(o){let e,l,t,s,r,n,c,u,w,G;const v=[Pa,Da],C=[];function U(b,j){return b[13].default?0:1}return t=U(o),s=C[t]=v[t](o),{c(){e=_("li"),l=_("a"),s.c(),this.h()},l(b){e=M(b,"LI",{class:!0});var j=z(e);l=M(j,"A",{class:!0,"data-label":!0,"data-url":!0,"data-value":!0,href:!0,rel:!0,target:!0});var N=z(l);s.l(N),N.forEach(i),j.forEach(i),this.h()},h(){y(l,"class",r="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+o[0]+" "+(o[9]?"hover:underline":"")+" "+(o[12]?"v2-dropdown-entry":"")),y(l,"data-label",o[1]),y(l,"data-url",o[2]),y(l,"data-value",o[3]),y(l,"href",o[4]),y(l,"rel",n=o[8]?"nofollow":void 0),y(l,"target",c=o[11]?"_blank":void 0),y(e,"class","not-prose")},m(b,j){f(b,e,j),H(e,l),C[t].m(l,null),u=!0,w||(G=wt(l,"click",function(){ya(o[10])&&o[10].apply(this,arguments)}),w=!0)},p(b,[j]){o=b;let N=t;t=U(o),t===N?C[t].p(o,j):(A(),h(C[N],1,1,()=>{C[N]=null}),x(),s=C[t],s?s.p(o,j):(s=C[t]=v[t](o),s.c()),m(s,1),s.m(l,null)),(!u||j&4609&&r!==(r="flex items-center hover:bg-gray-50 dark:hover:bg-gray-800 cursor-pointer px-3 py-1.5 whitespace-nowrap "+o[0]+" "+(o[9]?"hover:underline":"")+" "+(o[12]?"v2-dropdown-entry":"")))&&y(l,"class",r),(!u||j&2)&&y(l,"data-label",o[1]),(!u||j&4)&&y(l,"data-url",o[2]),(!u||j&8)&&y(l,"data-value",o[3]),(!u||j&16)&&y(l,"href",o[4]),(!u||j&256&&n!==(n=o[8]?"nofollow":void 0))&&y(l,"rel",n),(!u||j&2048&&c!==(c=o[11]?"_blank":void 0))&&y(l,"target",c)},i(b){u||(m(s),u=!0)},o(b){h(s),u=!1},d(b){b&&i(e),C[t].d(),w=!1,G()}}}function Oa(o,e,l){let{$$slots:t={},$$scope:s}=e;const r=ka(t);let{classNames:n=""}=e,{dataLabel:c=void 0}=e,{dataUrl:u=void 0}=e,{dataValue:w=void 0}=e,{href:G=void 0}=e,{icon:v=void 0}=e,{iconClassNames:C=""}=e,{label:U=""}=e,{noFollow:b=!1}=e,{underline:j=!1}=e,{onClick:N=()=>{}}=e,{targetBlank:X=!1}=e,{useDeprecatedJS:V=!0}=e;return o.$$set=R=>{"classNames"in R&&l(0,n=R.classNames),"dataLabel"in R&&l(1,c=R.dataLabel),"dataUrl"in R&&l(2,u=R.dataUrl),"dataValue"in R&&l(3,w=R.dataValue),"href"in R&&l(4,G=R.href),"icon"in R&&l(5,v=R.icon),"iconClassNames"in R&&l(6,C=R.iconClassNames),"label"in R&&l(7,U=R.label),"noFollow"in R&&l(8,b=R.noFollow),"underline"in R&&l(9,j=R.underline),"onClick"in R&&l(10,N=R.onClick),"targetBlank"in R&&l(11,X=R.targetBlank),"useDeprecatedJS"in R&&l(12,V=R.useDeprecatedJS),"$$scope"in R&&l(14,s=R.$$scope)},[n,c,u,w,G,v,C,U,b,j,N,X,V,r,s,t]}class Ca extends is{constructor(e){super(),cs(this,e,Oa,Ka,os,{classNames:0,dataLabel:1,dataUrl:2,dataValue:3,href:4,icon:5,iconClassNames:6,label:7,noFollow:8,underline:9,onClick:10,targetBlank:11,useDeprecatedJS:12})}}const{window:el}=Fa,sl=o=>({}),fa=o=>({slot:"button"});function ma(o,e,l){const t=o.slice();return t[11]=e[l].label,t[12]=e[l].value,t}const tl=o=>({}),ha=o=>({slot:"menu"}),al=o=>({}),da=o=>({slot:"button"});function ga(o,e,l){const t=o.slice();return t[11]=e[l].label,t[12]=e[l].value,t}const ll=o=>({}),ba=o=>({slot:"menu"}),nl=o=>({}),wa=o=>({});function rl(o){let e,l;return e=new Ua({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[ul],button:[cl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&1024&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function ol(o){let e,l,t;return{c(){e=_("a"),l=_("img"),this.h()},l(s){e=M(s,"A",{href:!0,target:!0});var r=z(e);l=M(r,"IMG",{alt:!0,class:!0,src:!0}),r.forEach(i),this.h()},h(){y(l,"alt","Open In Colab"),y(l,"class","!m-0"),bt(l.src,t="https://colab.research.google.com/assets/colab-badge.svg")||y(l,"src",t),y(e,"href",o[2][0].value),y(e,"target","_blank")},m(s,r){f(s,e,r),H(e,l)},p:Y,i:Y,o:Y,d(s){s&&i(e)}}}function il(o){let e,l;return{c(){e=_("img"),this.h()},l(t){e=M(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){y(e,"alt","Open In Colab"),y(e,"class","!m-0"),bt(e.src,l="https://colab.research.google.com/assets/colab-badge.svg")||y(e,"src",l)},m(t,s){f(t,e,s)},p:Y,d(t){t&&i(e)}}}function cl(o){let e;const l=o[6].default,t=q(l,o,o[10],da),s=t||il();return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,al):S(r[10]),da)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function ja(o){let e,l;function t(){return o[7](o[12])}return e=new Ca({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:o[11],onClick:t,useDeprecatedJS:!1}}),{c(){k(e.$$.fragment)},l(s){$(e.$$.fragment,s)},m(s,r){T(e,s,r),l=!0},p(s,r){o=s},i(s){l||(m(e.$$.fragment,s),l=!0)},o(s){h(e.$$.fragment,s),l=!1},d(s){J(e,s)}}}function pl(o){let e,l,t=gt(o[2]),s=[];for(let n=0;n<t.length;n+=1)s[n]=ja(ga(o,t,n));const r=n=>h(s[n],1,1,()=>{s[n]=null});return{c(){for(let n=0;n<s.length;n+=1)s[n].c();e=L()},l(n){for(let c=0;c<s.length;c+=1)s[c].l(n);e=L()},m(n,c){for(let u=0;u<s.length;u+=1)s[u]&&s[u].m(n,c);f(n,e,c),l=!0},p(n,c){if(c&4){t=gt(n[2]);let u;for(u=0;u<t.length;u+=1){const w=ga(n,t,u);s[u]?(s[u].p(w,c),m(s[u],1)):(s[u]=ja(w),s[u].c(),m(s[u],1),s[u].m(e.parentNode,e))}for(A(),u=t.length;u<s.length;u+=1)r(u);x()}},i(n){if(!l){for(let c=0;c<t.length;c+=1)m(s[c]);l=!0}},o(n){s=s.filter(Boolean);for(let c=0;c<s.length;c+=1)h(s[c]);l=!1},d(n){n&&i(e),va(s,n)}}}function ul(o){let e;const l=o[6].default,t=q(l,o,o[10],ba),s=t||pl(o);return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,ll):S(r[10]),ba)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function fl(o){let e,l;return e=new Ua({props:{btnLabel:"",classNames:"colab-dropdown",noBtnClass:!0,useDeprecatedJS:!1,$$slots:{menu:[bl],button:[dl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&1024&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function ml(o){let e,l,t;return{c(){e=_("a"),l=_("img"),this.h()},l(s){e=M(s,"A",{href:!0,target:!0});var r=z(e);l=M(r,"IMG",{alt:!0,class:!0,src:!0}),r.forEach(i),this.h()},h(){y(l,"alt","Open In Studio Lab"),y(l,"class","!m-0"),bt(l.src,t="https://studiolab.sagemaker.aws/studiolab.svg")||y(l,"src",t),y(e,"href",o[3][0].value),y(e,"target","_blank")},m(s,r){f(s,e,r),H(e,l)},p:Y,i:Y,o:Y,d(s){s&&i(e)}}}function hl(o){let e,l;return{c(){e=_("img"),this.h()},l(t){e=M(t,"IMG",{alt:!0,class:!0,src:!0}),this.h()},h(){y(e,"alt","Open In Studio Lab"),y(e,"class","!m-0"),bt(e.src,l="https://studiolab.sagemaker.aws/studiolab.svg")||y(e,"src",l)},m(t,s){f(t,e,s)},p:Y,d(t){t&&i(e)}}}function dl(o){let e;const l=o[6].default,t=q(l,o,o[10],fa),s=t||hl();return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,sl):S(r[10]),fa)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function _a(o){let e,l;function t(){return o[8](o[12])}return e=new Ca({props:{classNames:"text-sm !no-underline",iconClassNames:"text-gray-500",label:o[11],onClick:t,useDeprecatedJS:!1}}),{c(){k(e.$$.fragment)},l(s){$(e.$$.fragment,s)},m(s,r){T(e,s,r),l=!0},p(s,r){o=s},i(s){l||(m(e.$$.fragment,s),l=!0)},o(s){h(e.$$.fragment,s),l=!1},d(s){J(e,s)}}}function gl(o){let e,l,t=gt(o[3]),s=[];for(let n=0;n<t.length;n+=1)s[n]=_a(ma(o,t,n));const r=n=>h(s[n],1,1,()=>{s[n]=null});return{c(){for(let n=0;n<s.length;n+=1)s[n].c();e=L()},l(n){for(let c=0;c<s.length;c+=1)s[c].l(n);e=L()},m(n,c){for(let u=0;u<s.length;u+=1)s[u]&&s[u].m(n,c);f(n,e,c),l=!0},p(n,c){if(c&8){t=gt(n[3]);let u;for(u=0;u<t.length;u+=1){const w=ma(n,t,u);s[u]?(s[u].p(w,c),m(s[u],1)):(s[u]=_a(w),s[u].c(),m(s[u],1),s[u].m(e.parentNode,e))}for(A(),u=t.length;u<s.length;u+=1)r(u);x()}},i(n){if(!l){for(let c=0;c<t.length;c+=1)m(s[c]);l=!0}},o(n){s=s.filter(Boolean);for(let c=0;c<s.length;c+=1)h(s[c]);l=!1},d(n){n&&i(e),va(s,n)}}}function bl(o){let e;const l=o[6].default,t=q(l,o,o[10],ha),s=t||gl(o);return{c(){s&&s.c()},l(r){s&&s.l(r)},m(r,n){s&&s.m(r,n),e=!0},p(r,n){t&&t.p&&(!e||n&1024)&&Q(t,l,r,r[10],e?D(l,r[10],n,tl):S(r[10]),ha)},i(r){e||(m(s,r),e=!0)},o(r){h(s,r),e=!1},d(r){s&&s.d(r)}}}function wl(o){let e,l,t,s,r,n,c,u,w,G,v;const C=o[6].alwaysVisible,U=q(C,o,o[10],wa),b=[ol,rl],j=[];function N(Z,B){return Z[2].length===1?0:Z[2].length>1?1:-1}~(t=N(o))&&(s=j[t]=b[t](o));const X=[ml,fl],V=[];function R(Z,B){return Z[3].length===1?0:Z[3].length>1?1:-1}return~(n=R(o))&&(c=V[n]=X[n](o)),{c(){e=_("div"),U&&U.c(),l=d(),s&&s.c(),r=d(),c&&c.c(),this.h()},l(Z){e=M(Z,"DIV",{class:!0});var B=z(e);U&&U.l(B),l=g(B),s&&s.l(B),r=g(B),c&&c.l(B),B.forEach(i),this.h()},h(){y(e,"class",u="flex space-x-1 "+o[0])},m(Z,B){f(Z,e,B),U&&U.m(e,null),H(e,l),~t&&j[t].m(e,null),H(e,r),~n&&V[n].m(e,null),o[9](e),w=!0,G||(v=wt(el,"resize",o[4]),G=!0)},p(Z,[B]){U&&U.p&&(!w||B&1024)&&Q(U,C,Z,Z[10],w?D(C,Z[10],B,nl):S(Z[10]),wa),s&&s.p(Z,B),c&&c.p(Z,B),(!w||B&1&&u!==(u="flex space-x-1 "+Z[0]))&&y(e,"class",u)},i(Z){w||(m(U,Z),m(s),m(c),w=!0)},o(Z){h(U,Z),h(s),h(c),w=!1},d(Z){Z&&i(e),U&&U.d(Z),~t&&j[t].d(),~n&&V[n].d(),o[9](null),G=!1,v()}}}function Ma(o){window.open(o)}function jl(o,e,l){let{$$slots:t={},$$scope:s}=e,{options:r=[]}=e,{classNames:n=""}=e,c;const u=r.filter(b=>b.value.includes("colab.research.google.com")),w=r.filter(b=>b.value.includes("studiolab.sagemaker.aws"));function G(){const b=document.querySelector(".prose-doc h1"),j=document.querySelector(".prose-doc h1 > span");if(b&&j){const{width:N}=b.getBoundingClientRect(),{width:X}=j.getBoundingClientRect();let V=0;for(let Z=0;Z<c.children.length;Z++){const B=c.children.item(Z);B&&(V+=B.clientWidth)}const R=20;N-X<V+R?c.classList.remove("absolute"):c.classList.add("absolute")}}yt(()=>{(async()=>(await Ia(),G()))()});const v=b=>Ma(b),C=b=>Ma(b);function U(b){kt[b?"unshift":"push"](()=>{c=b,l(1,c)})}return o.$$set=b=>{"options"in b&&l(5,r=b.options),"classNames"in b&&l(0,n=b.classNames),"$$scope"in b&&l(10,s=b.$$scope)},[n,c,u,w,G,r,t,v,C,U,s]}class _l extends is{constructor(e){super(),cs(this,e,jl,wl,os,{options:5,classNames:0})}}function Ml(o){let e,l='Check out <a href="https://huggingface.co/course/chapter5/1?fw=pt" rel="nofollow">Chapter 5</a> of the Hugging Face course to learn more about other important topics such as loading remote or local datasets, tools for cleaning up a dataset, and creating your own dataset.';return{c(){e=_("p"),e.innerHTML=l},l(t){e=M(t,"P",{"data-svelte-h":!0}),I(e)!=="svelte-cjedd4"&&(e.innerHTML=l)},m(t,s){f(t,e,s)},p:Y,d(t){t&&i(e)}}}function yl(o){let e,l;return e=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRvcmNo",highlighted:"pip install torch",wrap:!1}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p:Y,i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function kl(o){let e,l;return e=new te({props:{$$slots:{default:[yl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Tl(o){let e,l;return e=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRlbnNvcmZsb3c=",highlighted:"pip install tensorflow",wrap:!1}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p:Y,i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Jl(o){let e,l;return e=new te({props:{$$slots:{default:[Tl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function $l(o){let e,l='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.set_format">set_format()</a> function to set the dataset format to <code>torch</code> and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in <a href="https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader" rel="nofollow"><code>torch.utils.data.DataLoader</code></a>:',t,s,r;return s=new W({props:{code:"ZnJvbSUyMHRvcmNoLnV0aWxzLmRhdGElMjBpbXBvcnQlMjBEYXRhTG9hZGVyJTBBJTBBZGF0YXNldC5zZXRfZm9ybWF0KHR5cGUlM0QlMjJ0b3JjaCUyMiUyQyUyMGNvbHVtbnMlM0QlNUIlMjJpbnB1dF92YWx1ZXMlMjIlMkMlMjAlMjJsYWJlbHMlMjIlNUQpJTBBZGF0YWxvYWRlciUyMCUzRCUyMERhdGFMb2FkZXIoZGF0YXNldCUyQyUyMGJhdGNoX3NpemUlM0Q0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_format(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;input_values&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, batch_size=<span class="hljs-number">4</span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-z0rl04"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function vl(o){let e,l;return e=new te({props:{$$slots:{default:[$l]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Ul(o){let e,l=`Use the <a href="https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset" rel="nofollow">prepare_tf_dataset</a> method from 🤗 Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a> as a <code>tf.data.Dataset</code>
with collation and batching, so one can pass it directly to Keras methods like <code>fit()</code> without further modification.`,t,s,r;return s=new W({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNENCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-1wenvpa"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Cl(o){let e,l;return e=new te({props:{$$slots:{default:[Ul]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Il(o){let e,l='Wrap the dataset in <a href="https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader" rel="nofollow"><code>torch.utils.data.DataLoader</code></a>. You’ll also need to create a collate function to collate the samples into batches:',t,s,r;return s=new W({props:{code:"ZnJvbSUyMHRvcmNoLnV0aWxzLmRhdGElMjBpbXBvcnQlMjBEYXRhTG9hZGVyJTBBJTBBZGVmJTIwY29sbGF0ZV9mbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBpbWFnZXMlMjAlM0QlMjAlNUIlNUQlMEElMjAlMjAlMjAlMjBsYWJlbHMlMjAlM0QlMjAlNUIlNUQlMEElMjAlMjAlMjAlMjBmb3IlMjBleGFtcGxlJTIwaW4lMjBleGFtcGxlcyUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGltYWdlcy5hcHBlbmQoKGV4YW1wbGUlNUIlMjJwaXhlbF92YWx1ZXMlMjIlNUQpKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxhYmVscy5hcHBlbmQoZXhhbXBsZSU1QiUyMmxhYmVscyUyMiU1RCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMEElMjAlMjAlMjAlMjBwaXhlbF92YWx1ZXMlMjAlM0QlMjB0b3JjaC5zdGFjayhpbWFnZXMpJTBBJTIwJTIwJTIwJTIwbGFiZWxzJTIwJTNEJTIwdG9yY2gudGVuc29yKGxhYmVscyklMEElMjAlMjAlMjAlMjByZXR1cm4lMjAlN0IlMjJwaXhlbF92YWx1ZXMlMjIlM0ElMjBwaXhlbF92YWx1ZXMlMkMlMjAlMjJsYWJlbHMlMjIlM0ElMjBsYWJlbHMlN0QlMEFkYXRhbG9hZGVyJTIwJTNEJTIwRGF0YUxvYWRlcihkYXRhc2V0JTJDJTIwY29sbGF0ZV9mbiUzRGNvbGxhdGVfZm4lMkMlMjBiYXRjaF9zaXplJTNENCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    images = []
<span class="hljs-meta">... </span>    labels = []
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> examples:
<span class="hljs-meta">... </span>        images.append((example[<span class="hljs-string">&quot;pixel_values&quot;</span>]))
<span class="hljs-meta">... </span>        labels.append(example[<span class="hljs-string">&quot;labels&quot;</span>])
<span class="hljs-meta">... </span>        
<span class="hljs-meta">... </span>    pixel_values = torch.stack(images)
<span class="hljs-meta">... </span>    labels = torch.tensor(labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;pixel_values&quot;</span>: pixel_values, <span class="hljs-string">&quot;labels&quot;</span>: labels}
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=<span class="hljs-number">4</span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-lbzzax"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Gl(o){let e,l;return e=new te({props:{$$slots:{default:[Il]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Rl(o){let e,l=`Use the <a href="https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset" rel="nofollow">prepare_tf_dataset</a> method from 🤗 Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a> as a <code>tf.data.Dataset</code>
with collation and batching, so one can pass it directly to Keras methods like <code>fit()</code> without further modification.`,t,s,r="Before you start, make sure you have up-to-date versions of <code>albumentations</code> and <code>cv2</code> installed:",n,c,u,w,G;return c=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1VJTIwYWxidW1lbnRhdGlvbnMlMjBvcGVuY3YtcHl0aG9u",highlighted:"pip install -U albumentations opencv-python",wrap:!1}}),w=new W({props:{code:"aW1wb3J0JTIwYWxidW1lbnRhdGlvbnMlMEFpbXBvcnQlMjBudW1weSUyMGFzJTIwbnAlMEElMEF0cmFuc2Zvcm0lMjAlM0QlMjBhbGJ1bWVudGF0aW9ucy5Db21wb3NlKCU1QiUwQSUyMCUyMCUyMCUyMGFsYnVtZW50YXRpb25zLlJhbmRvbUNyb3Aod2lkdGglM0QyNTYlMkMlMjBoZWlnaHQlM0QyNTYpJTJDJTBBJTIwJTIwJTIwJTIwYWxidW1lbnRhdGlvbnMuSG9yaXpvbnRhbEZsaXAocCUzRDAuNSklMkMlMEElMjAlMjAlMjAlMjBhbGJ1bWVudGF0aW9ucy5SYW5kb21CcmlnaHRuZXNzQ29udHJhc3QocCUzRDAuMiklMkMlMEElNUQpJTBBJTBBZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHRyYW5zZm9ybShpbWFnZSUzRG5wLmFycmF5KGltYWdlKSklNUIlMjJpbWFnZSUyMiU1RCUyMGZvciUyMGltYWdlJTIwaW4lMjBleGFtcGxlcyU1QiUyMmltYWdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwJTVEJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwZXhhbXBsZXMlMEElMEFkYXRhc2V0LnNldF90cmFuc2Zvcm0odHJhbnNmb3JtcyklMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNENCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> albumentations
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-meta">&gt;&gt;&gt; </span>transform = albumentations.Compose([
<span class="hljs-meta">... </span>    albumentations.RandomCrop(width=<span class="hljs-number">256</span>, height=<span class="hljs-number">256</span>),
<span class="hljs-meta">... </span>    albumentations.HorizontalFlip(p=<span class="hljs-number">0.5</span>),
<span class="hljs-meta">... </span>    albumentations.RandomBrightnessContrast(p=<span class="hljs-number">0.2</span>),
<span class="hljs-meta">... </span>])

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [
<span class="hljs-meta">... </span>        transform(image=np.array(image))[<span class="hljs-string">&quot;image&quot;</span>] <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),s=_("p"),s.innerHTML=r,n=d(),k(c.$$.fragment),u=d(),k(w.$$.fragment)},l(v){e=M(v,"P",{"data-svelte-h":!0}),I(e)!=="svelte-9fpjyy"&&(e.innerHTML=l),t=g(v),s=M(v,"P",{"data-svelte-h":!0}),I(s)!=="svelte-1qtuikq"&&(s.innerHTML=r),n=g(v),$(c.$$.fragment,v),u=g(v),$(w.$$.fragment,v)},m(v,C){f(v,e,C),f(v,t,C),f(v,s,C),f(v,n,C),T(c,v,C),f(v,u,C),T(w,v,C),G=!0},p:Y,i(v){G||(m(c.$$.fragment,v),m(w.$$.fragment,v),G=!0)},o(v){h(c.$$.fragment,v),h(w.$$.fragment,v),G=!1},d(v){v&&(i(e),i(t),i(s),i(n),i(u)),J(c,v),J(w,v)}}}function Zl(o){let e,l;return e=new te({props:{$$slots:{default:[Rl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Nl(o){let e,l='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.set_format">set_format()</a> function to set the dataset format to <code>torch</code> and specify the columns you want to format. This function applies formatting on-the-fly. After converting to PyTorch tensors, wrap the dataset in <a href="https://alband.github.io/doc_view/data.html?highlight=torch%20utils%20data%20dataloader#torch.utils.data.DataLoader" rel="nofollow"><code>torch.utils.data.DataLoader</code></a>:',t,s,r;return s=new W({props:{code:"aW1wb3J0JTIwdG9yY2glMEElMEFkYXRhc2V0LnNldF9mb3JtYXQodHlwZSUzRCUyMnRvcmNoJTIyJTJDJTIwY29sdW1ucyUzRCU1QiUyMmlucHV0X2lkcyUyMiUyQyUyMCUyMnRva2VuX3R5cGVfaWRzJTIyJTJDJTIwJTIyYXR0ZW50aW9uX21hc2slMjIlMkMlMjAlMjJsYWJlbHMlMjIlNUQpJTBBZGF0YWxvYWRlciUyMCUzRCUyMHRvcmNoLnV0aWxzLmRhdGEuRGF0YUxvYWRlcihkYXRhc2V0JTJDJTIwYmF0Y2hfc2l6ZSUzRDMyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_format(<span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="hljs-number">32</span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-z0rl04"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Fl(o){let e,l;return e=new te({props:{$$slots:{default:[Nl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Wl(o){let e,l=`Use the <a href="https://huggingface.co/docs/transformers/v4.51.3/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset" rel="nofollow">prepare_tf_dataset</a> method from 🤗 Transformers to prepare the dataset to be compatible with
TensorFlow, and ready to train/fine-tune a model, as it wraps a HuggingFace <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a> as a <code>tf.data.Dataset</code>
with collation and batching, so one can pass it directly to Keras methods like <code>fit()</code> without further modification.`,t,s,r;return s=new W({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNENCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){e=_("p"),e.innerHTML=l,t=d(),k(s.$$.fragment)},l(n){e=M(n,"P",{"data-svelte-h":!0}),I(e)!=="svelte-1wenvpa"&&(e.innerHTML=l),t=g(n),$(s.$$.fragment,n)},m(n,c){f(n,e,c),f(n,t,c),T(s,n,c),r=!0},p:Y,i(n){r||(m(s.$$.fragment,n),r=!0)},o(n){h(s.$$.fragment,n),r=!1},d(n){n&&(i(e),i(t)),J(s,n)}}}function Bl(o){let e,l;return e=new te({props:{$$slots:{default:[Wl]},$$scope:{ctx:o}}}),{c(){k(e.$$.fragment)},l(t){$(e.$$.fragment,t)},m(t,s){T(e,t,s),l=!0},p(t,s){const r={};s&2&&(r.$$scope={dirty:s,ctx:t}),e.$set(r)},i(t){l||(m(e.$$.fragment,t),l=!0)},o(t){h(e.$$.fragment,t),l=!1},d(t){J(e,t)}}}function Vl(o){let e,l,t,s,r,n,c,u,w,G='This quickstart is intended for developers who are ready to dive into the code and see an example of how to integrate 🤗 Datasets into their model training workflow. If you’re a beginner, we recommend starting with our <a href="./tutorial">tutorials</a>, where you’ll get a more thorough introduction.',v,C,U='Each dataset is unique, and depending on the task, some datasets may require additional steps to prepare it for training. But you can always use 🤗 Datasets tools to load and process a dataset. The fastest and easiest way to get started is by loading an existing dataset from the <a href="https://huggingface.co/datasets" rel="nofollow">Hugging Face Hub</a>. There are thousands of datasets to choose from, spanning many tasks. Choose the type of dataset you want to work with, and let’s get started!',b,j,N='<div class="w-full flex flex-col space-y-4 md:space-y-0 md:grid md:grid-cols-3 md:gap-y-4 md:gap-x-5"><a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#audio"><div class="w-full text-center bg-gradient-to-r from-violet-300 via-sky-400 to-green-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">Audio</div> <p class="text-gray-700">Resample an audio dataset and get it ready for a model to classify what type of banking issue a speaker is calling about.</p></a> <a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#vision"><div class="w-full text-center bg-gradient-to-r from-pink-400 via-purple-400 to-blue-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">Vision</div> <p class="text-gray-700">Apply data augmentation to an image dataset and get it ready for a model to diagnose disease in bean plants.</p></a> <a class="!no-underline border dark:border-gray-700 p-5 rounded-lg shadow hover:shadow-lg" href="#nlp"><div class="w-full text-center bg-gradient-to-r from-orange-300 via-red-400 to-violet-500 rounded-lg py-1.5 font-semibold mb-5 text-white text-lg leading-relaxed">NLP</div> <p class="text-gray-700">Tokenize a dataset and get it ready for a model to determine whether a pair of sentences have the same meaning.</p></a></div>',X,V,R,Z,B="Start by installing 🤗 Datasets:",F,E,fs,ae,Tt="🤗 Datasets also support audio and image data formats:",ms,P,le,ns,Jt='To work with audio datasets, install the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Audio">Audio</a> feature:',jt,ne,_t,re,rs,$t='To work with image datasets, install the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Image">Image</a> feature:',Mt,oe,hs,ie,vt="Besides 🤗 Datasets, make sure your preferred machine learning framework is installed:",ds,K,gs,ce,bs,pe,Ut='Audio datasets are loaded just like text datasets. However, an audio dataset is preprocessed a bit differently. Instead of a tokenizer, you’ll need a <a href="https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor" rel="nofollow">feature extractor</a>. An audio input may also require resampling its sampling rate to match the sampling rate of the pretrained model you’re using. In this quickstart, you’ll prepare the <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> dataset for a model train on and classify the banking issue a customer is having.',ws,ue,Ct='<strong>1</strong>. Load the MInDS-14 dataset by providing the <a href="/docs/datasets/v3.6.0/en/package_reference/loading_methods#datasets.load_dataset">load_dataset()</a> function with the dataset name, dataset configuration (not all datasets will have a configuration), and a dataset split:',js,fe,_s,me,It='<strong>2</strong>. Next, load a pretrained <a href="https://huggingface.co/facebook/wav2vec2-base" rel="nofollow">Wav2Vec2</a> model and its corresponding feature extractor from the <a href="https://huggingface.co/transformers/" rel="nofollow">🤗 Transformers</a> library. It is totally normal to see a warning after you load the model about some weights not being initialized. This is expected because you are loading this model checkpoint for training with another task.',Ms,he,ys,de,Gt='<strong>3</strong>. The <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> dataset card indicates the sampling rate is 8kHz, but the Wav2Vec2 model was pretrained on a sampling rate of 16kHZ. You’ll need to upsample the <code>audio</code> column with the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.cast_column">cast_column()</a> function and <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Audio">Audio</a> feature to match the model’s sampling rate.',ks,ge,Ts,be,Rt="<strong>4</strong>. Create a function to preprocess the audio <code>array</code> with the feature extractor, and truncate and pad the sequences into tidy rectangular tensors. The most important thing to remember is to call the audio <code>array</code> in the feature extractor since the <code>array</code> - the actual speech signal - is the model input.",Js,we,Zt='Once you have a preprocessing function, use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> function to speed up processing by applying the function to batches of examples in the dataset.',$s,je,vs,_e,Nt='<strong>5</strong>. Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.rename_column">rename_column()</a> function to rename the <code>intent_class</code> column to <code>labels</code>, which is the expected input name in <a href="https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification" rel="nofollow">Wav2Vec2ForSequenceClassification</a>:',Us,Me,Cs,ye,Ft="<strong>6</strong>. Set the dataset format according to the machine learning framework you’re using.",Is,O,Gs,ke,Wt='<strong>7</strong>. Start training with your machine learning framework! Check out the 🤗 Transformers <a href="https://huggingface.co/docs/transformers/tasks/audio_classification" rel="nofollow">audio classification guide</a> for an end-to-end example of how to train a model on an audio dataset.',Rs,Te,Zs,Je,Bt='Image datasets are loaded just like text datasets. However, instead of a tokenizer, you’ll need a <a href="https://huggingface.co/docs/transformers/main_classes/feature_extractor#feature-extractor" rel="nofollow">feature extractor</a> to preprocess the dataset. Applying data augmentation to an image is common in computer vision to make the model more robust against overfitting. You’re free to use any data augmentation library you want, and then you can apply the augmentations with 🤗 Datasets. In this quickstart, you’ll load the <a href="https://huggingface.co/datasets/beans" rel="nofollow">Beans</a> dataset and get it ready for the model to train on and identify disease from the leaf images.',Ns,$e,Vt='<strong>1</strong>. Load the Beans dataset by providing the <a href="/docs/datasets/v3.6.0/en/package_reference/loading_methods#datasets.load_dataset">load_dataset()</a> function with the dataset name and a dataset split:',Fs,ve,Ws,Ue,Xt='Most image models work with RBG images. If your dataset contains images in a different mode, you can use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.cast_column">cast_column()</a> function to set the mode to RGB:',Bs,Ce,Vs,Ie,Yt="The Beans dataset contains only RGB images, so this step is unnecessary here.",Xs,Ge,Ht='<strong>2</strong>. Now you can add some data augmentations with any library (<a href="https://albumentations.ai/" rel="nofollow">Albumentations</a>, <a href="https://imgaug.readthedocs.io/en/latest/" rel="nofollow">imgaug</a>, <a href="https://kornia.readthedocs.io/en/latest/" rel="nofollow">Kornia</a>) you like. Here, you’ll use <a href="https://pytorch.org/vision/stable/transforms.html" rel="nofollow">torchvision</a> to randomly change the color properties of an image:',Ys,Re,Hs,Ze,zt="<strong>3</strong>. Create a function to apply your transform to the dataset and generate the model input: <code>pixel_values</code>.",zs,Ne,Es,Fe,Et='<strong>4</strong>. Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.with_transform">with_transform()</a> function to apply the data augmentations on-the-fly:',As,We,xs,Be,At="<strong>5</strong>. Set the dataset format according to the machine learning framework you’re using.",Ls,ee,qs,Ve,xt='<strong>6</strong>. Start training with your machine learning framework! Check out the 🤗 Transformers <a href="https://huggingface.co/docs/transformers/tasks/image_classification" rel="nofollow">image classification guide</a> for an end-to-end example of how to train a model on an image dataset.',Qs,Xe,Ss,Ye,Lt='Text needs to be tokenized into individual tokens by a <a href="https://huggingface.co/docs/transformers/main_classes/tokenizer" rel="nofollow">tokenizer</a>. For the quickstart, you’ll load the <a href="https://huggingface.co/datasets/glue/viewer/mrpc" rel="nofollow">Microsoft Research Paraphrase Corpus (MRPC)</a> training dataset to train a model to determine whether a pair of sentences mean the same thing.',Ds,He,qt='<strong>1</strong>. Load the MRPC dataset by providing the <a href="/docs/datasets/v3.6.0/en/package_reference/loading_methods#datasets.load_dataset">load_dataset()</a> function with the dataset name, dataset configuration (not all datasets will have a configuration), and dataset split:',Ps,ze,Ks,Ee,Qt='<strong>2</strong>. Next, load a pretrained <a href="https://huggingface.co/bert-base-uncased" rel="nofollow">BERT</a> model and its corresponding tokenizer from the <a href="https://huggingface.co/transformers/" rel="nofollow">🤗 Transformers</a> library. It is totally normal to see a warning after you load the model about some weights not being initialized. This is expected because you are loading this model checkpoint for training with another task.',Os,Ae,et,xe,St="<strong>3</strong>. Create a function to tokenize the dataset, and you should also truncate and pad the text into tidy rectangular tensors. The tokenizer generates three new columns in the dataset: <code>input_ids</code>, <code>token_type_ids</code>, and an <code>attention_mask</code>. These are the model inputs.",st,Le,Dt='Use the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> function to speed up processing by applying your tokenization function to batches of examples in the dataset:',tt,qe,at,Qe,Pt='<strong>4</strong>. Rename the <code>label</code> column to <code>labels</code>, which is the expected input name in <a href="https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification" rel="nofollow">BertForSequenceClassification</a>:',lt,Se,nt,De,Kt="<strong>5</strong>. Set the dataset format according to the machine learning framework you’re using.",rt,se,ot,Pe,Ot='<strong>6</strong>. Start training with your machine learning framework! Check out the 🤗 Transformers <a href="https://huggingface.co/docs/transformers/tasks/sequence_classification" rel="nofollow">text classification guide</a> for an end-to-end example of how to train a model on a text dataset.',it,Ke,ct,Oe,ea="This completes the 🤗 Datasets quickstart! You can load any text, audio, or image dataset with a single function and get it ready for your model to train on.",pt,es,sa='For your next steps, take a look at our <a href="./how_to">How-to guides</a> and learn how to do more specific things like loading different dataset formats, aligning labels, and streaming large datasets. If you’re interested in learning more about 🤗 Datasets core concepts, grab a cup of coffee and read our <a href="./about_arrow">Conceptual Guides</a>!',ut,ss,ft,ps,mt;return r=new us({props:{title:"Quickstart",local:"quickstart",headingTag:"h1"}}),c=new _l({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/quickstart.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/pytorch/quickstart.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/tensorflow/quickstart.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/datasets_doc/en/quickstart.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/datasets_doc/en/pytorch/quickstart.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/datasets_doc/en/tensorflow/quickstart.ipynb"}]}}),V=new Za({props:{$$slots:{default:[Ml]},$$scope:{ctx:o}}}),E=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRz",highlighted:"pip install datasets",wrap:!1}}),ne=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRzJTVCYXVkaW8lNUQ=",highlighted:"pip install datasets[audio]",wrap:!1}}),oe=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRzJTVCdmlzaW9uJTVE",highlighted:"pip install datasets[vision]",wrap:!1}}),K=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Jl],pytorch:[kl]},$$scope:{ctx:o}}}),ce=new us({props:{title:"Audio",local:"audio",headingTag:"h2"}}),fe=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjAlMjJlbi1VUyUyMiUyQyUyMHNwbGl0JTNEJTIydHJhaW4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, <span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),he=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckF1ZGlvQ2xhc3NpZmljYXRpb24lMkMlMjBBdXRvRmVhdHVyZUV4dHJhY3RvciUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQXVkaW9DbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZ3YXYydmVjMi1iYXNlJTIyKSUwQWZlYXR1cmVfZXh0cmFjdG9yJTIwJTNEJTIwQXV0b0ZlYXR1cmVFeHRyYWN0b3IuZnJvbV9wcmV0cmFpbmVkKCUyMmZhY2Vib29rJTJGd2F2MnZlYzItYmFzZSUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForAudioClassification, AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`,wrap:!1}}),ge=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEMTYwMDApKSUwQWRhdGFzZXQlNUIwJTVEJTVCJTIyYXVkaW8lMjIlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">2.3443763e-05</span>,  <span class="hljs-number">2.1729663e-04</span>,  <span class="hljs-number">2.2145823e-04</span>, ...,
         <span class="hljs-number">3.8356509e-05</span>, -<span class="hljs-number">7.3497440e-06</span>, -<span class="hljs-number">2.1754686e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`,wrap:!1}}),je=new W({props:{code:"ZGVmJTIwcHJlcHJvY2Vzc19mdW5jdGlvbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBhdWRpb19hcnJheXMlMjAlM0QlMjAlNUJ4JTVCJTIyYXJyYXklMjIlNUQlMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlcyU1QiUyMmF1ZGlvJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwaW5wdXRzJTIwJTNEJTIwZmVhdHVyZV9leHRyYWN0b3IoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwYXVkaW9fYXJyYXlzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwc2FtcGxpbmdfcmF0ZSUzRDE2MDAwJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcGFkZGluZyUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNEMTAwMDAwJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjApJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW5wdXRzJTBBJTBBZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKHByZXByb2Nlc3NfZnVuY3Rpb24lMkMlMjBiYXRjaGVkJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    audio_arrays = [x[<span class="hljs-string">&quot;array&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;audio&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = feature_extractor(
<span class="hljs-meta">... </span>        audio_arrays,
<span class="hljs-meta">... </span>        sampling_rate=<span class="hljs-number">16000</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">100000</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)`,wrap:!1}}),Me=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQucmVuYW1lX2NvbHVtbiglMjJpbnRlbnRfY2xhc3MlMjIlMkMlMjAlMjJsYWJlbHMlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.rename_column(<span class="hljs-string">&quot;intent_class&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)',wrap:!1}}),O=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Cl],pytorch:[vl]},$$scope:{ctx:o}}}),Te=new us({props:{title:"Vision",local:"vision",headingTag:"h2"}}),ve=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwSW1hZ2UlMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMkFJLUxhYi1NYWtlcmVyZSUyRmJlYW5zJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Image

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;AI-Lab-Makerere/beans&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),Ce=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyaW1hZ2UlMjIlMkMlMjBJbWFnZShtb2RlJTNEJTIyUkdCJTIyKSk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;image&quot;</span>, Image(mode=<span class="hljs-string">&quot;RGB&quot;</span>))',wrap:!1}}),Re=new W({props:{code:"ZnJvbSUyMHRvcmNodmlzaW9uLnRyYW5zZm9ybXMlMjBpbXBvcnQlMjBDb21wb3NlJTJDJTIwQ29sb3JKaXR0ZXIlMkMlMjBUb1RlbnNvciUwQSUwQWppdHRlciUyMCUzRCUyMENvbXBvc2UoJTBBJTIwJTIwJTIwJTIwJTVCQ29sb3JKaXR0ZXIoYnJpZ2h0bmVzcyUzRDAuNSUyQyUyMGh1ZSUzRDAuNSklMkMlMjBUb1RlbnNvcigpJTVEJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Compose, ColorJitter, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = Compose(
<span class="hljs-meta">... </span>    [ColorJitter(brightness=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>), ToTensor()]
<span class="hljs-meta">... </span>)`,wrap:!1}}),Ne=new W({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QmppdHRlcihpbWFnZS5jb252ZXJ0KCUyMlJHQiUyMikpJTIwZm9yJTIwaW1hZ2UlMjBpbiUyMGV4YW1wbGVzJTVCJTIyaW1hZ2UlMjIlNUQlNUQlMEElMjAlMjAlMjAlMjByZXR1cm4lMjBleGFtcGxlcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [jitter(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`,wrap:!1}}),We=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQud2l0aF90cmFuc2Zvcm0odHJhbnNmb3Jtcyk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.with_transform(transforms)',wrap:!1}}),ee=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Zl],pytorch:[Gl]},$$scope:{ctx:o}}}),Xe=new us({props:{title:"NLP",local:"nlp",headingTag:"h2"}}),ze=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJueXUtbWxsJTJGZ2x1ZSUyMiUyQyUyMCUyMm1ycGMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;nyu-mll/glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),Ae=new Na({props:{group1:{id:"pt",code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMkMlMjBBdXRvVG9rZW5pemVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJiZXJ0LWJhc2UtdW5jYXNlZCUyMiklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)`},group2:{id:"tf",code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUyQyUyMEF1dG9Ub2tlbml6ZXIlMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)`},wrap:!1}}),qe=new W({props:{code:"ZGVmJTIwZW5jb2RlKGV4YW1wbGVzKSUzQSUwQSUyMCUyMCUyMCUyMHJldHVybiUyMHRva2VuaXplcihleGFtcGxlcyU1QiUyMnNlbnRlbmNlMSUyMiU1RCUyQyUyMGV4YW1wbGVzJTVCJTIyc2VudGVuY2UyJTIyJTVEJTJDJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMjBwYWRkaW5nJTNEJTIybWF4X2xlbmd0aCUyMiklMEElMEFkYXRhc2V0JTIwJTNEJTIwZGF0YXNldC5tYXAoZW5jb2RlJTJDJTIwYmF0Y2hlZCUzRFRydWUpJTBBZGF0YXNldCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;sentence1&quot;</span>], examples[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>, padding=<span class="hljs-string">&quot;max_length&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(encode, batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;sentence1&#x27;</span>: <span class="hljs-string">&#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;</span>,
<span class="hljs-string">&#x27;sentence2&#x27;</span>: <span class="hljs-string">&#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;</span>,
<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>,
<span class="hljs-string">&#x27;idx&#x27;</span>: <span class="hljs-number">0</span>,
<span class="hljs-string">&#x27;input_ids&#x27;</span>: array([  <span class="hljs-number">101</span>,  <span class="hljs-number">7277</span>,  <span class="hljs-number">2180</span>,  <span class="hljs-number">5303</span>,  <span class="hljs-number">4806</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">1711</span>,   <span class="hljs-number">117</span>,  <span class="hljs-number">2292</span>, <span class="hljs-number">1119</span>,  <span class="hljs-number">1270</span>,   <span class="hljs-number">107</span>,  <span class="hljs-number">1103</span>,  <span class="hljs-number">7737</span>,   <span class="hljs-number">107</span>,   <span class="hljs-number">117</span>,  <span class="hljs-number">1104</span>,  <span class="hljs-number">9938</span>, <span class="hljs-number">4267</span>, <span class="hljs-number">12223</span>, <span class="hljs-number">21811</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">2554</span>,   <span class="hljs-number">119</span>,   <span class="hljs-number">102</span>, <span class="hljs-number">11336</span>,  <span class="hljs-number">6732</span>, <span class="hljs-number">3384</span>,  <span class="hljs-number">1106</span>,  <span class="hljs-number">1140</span>,  <span class="hljs-number">1112</span>,  <span class="hljs-number">1178</span>,   <span class="hljs-number">107</span>,  <span class="hljs-number">1103</span>,  <span class="hljs-number">7737</span>,   <span class="hljs-number">107</span>, <span class="hljs-number">117</span>,  <span class="hljs-number">7277</span>,  <span class="hljs-number">2180</span>,  <span class="hljs-number">5303</span>,  <span class="hljs-number">4806</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">1711</span>,  <span class="hljs-number">1104</span>,  <span class="hljs-number">9938</span>, <span class="hljs-number">4267</span>, <span class="hljs-number">12223</span>, <span class="hljs-number">21811</span>,  <span class="hljs-number">1117</span>,  <span class="hljs-number">2554</span>,   <span class="hljs-number">119</span>,   <span class="hljs-number">102</span>]),
<span class="hljs-string">&#x27;token_type_ids&#x27;</span>: array([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]),
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: array([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])}`,wrap:!1}}),Se=new W({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKGxhbWJkYSUyMGV4YW1wbGVzJTNBJTIwJTdCJTIybGFiZWxzJTIyJTNBJTIwZXhhbXBsZXMlNUIlMjJsYWJlbCUyMiU1RCU3RCUyQyUyMGJhdGNoZWQlM0RUcnVlKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> examples: {<span class="hljs-string">&quot;labels&quot;</span>: examples[<span class="hljs-string">&quot;label&quot;</span>]}, batched=<span class="hljs-literal">True</span>)',wrap:!1}}),se=new ht({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Bl],pytorch:[Fl]},$$scope:{ctx:o}}}),Ke=new us({props:{title:"What’s next?",local:"whats-next",headingTag:"h2"}}),ss=new Wa({props:{source:"https://github.com/huggingface/datasets/blob/main/docs/source/quickstart.mdx"}}),{c(){e=_("meta"),l=d(),t=_("p"),s=d(),k(r.$$.fragment),n=d(),k(c.$$.fragment),u=d(),w=_("p"),w.innerHTML=G,v=d(),C=_("p"),C.innerHTML=U,b=d(),j=_("div"),j.innerHTML=N,X=d(),k(V.$$.fragment),R=d(),Z=_("p"),Z.textContent=B,F=d(),k(E.$$.fragment),fs=d(),ae=_("p"),ae.textContent=Tt,ms=d(),P=_("ul"),le=_("li"),ns=_("p"),ns.innerHTML=Jt,jt=d(),k(ne.$$.fragment),_t=d(),re=_("li"),rs=_("p"),rs.innerHTML=$t,Mt=d(),k(oe.$$.fragment),hs=d(),ie=_("p"),ie.textContent=vt,ds=d(),k(K.$$.fragment),gs=d(),k(ce.$$.fragment),bs=d(),pe=_("p"),pe.innerHTML=Ut,ws=d(),ue=_("p"),ue.innerHTML=Ct,js=d(),k(fe.$$.fragment),_s=d(),me=_("p"),me.innerHTML=It,Ms=d(),k(he.$$.fragment),ys=d(),de=_("p"),de.innerHTML=Gt,ks=d(),k(ge.$$.fragment),Ts=d(),be=_("p"),be.innerHTML=Rt,Js=d(),we=_("p"),we.innerHTML=Zt,$s=d(),k(je.$$.fragment),vs=d(),_e=_("p"),_e.innerHTML=Nt,Us=d(),k(Me.$$.fragment),Cs=d(),ye=_("p"),ye.innerHTML=Ft,Is=d(),k(O.$$.fragment),Gs=d(),ke=_("p"),ke.innerHTML=Wt,Rs=d(),k(Te.$$.fragment),Zs=d(),Je=_("p"),Je.innerHTML=Bt,Ns=d(),$e=_("p"),$e.innerHTML=Vt,Fs=d(),k(ve.$$.fragment),Ws=d(),Ue=_("p"),Ue.innerHTML=Xt,Bs=d(),k(Ce.$$.fragment),Vs=d(),Ie=_("p"),Ie.textContent=Yt,Xs=d(),Ge=_("p"),Ge.innerHTML=Ht,Ys=d(),k(Re.$$.fragment),Hs=d(),Ze=_("p"),Ze.innerHTML=zt,zs=d(),k(Ne.$$.fragment),Es=d(),Fe=_("p"),Fe.innerHTML=Et,As=d(),k(We.$$.fragment),xs=d(),Be=_("p"),Be.innerHTML=At,Ls=d(),k(ee.$$.fragment),qs=d(),Ve=_("p"),Ve.innerHTML=xt,Qs=d(),k(Xe.$$.fragment),Ss=d(),Ye=_("p"),Ye.innerHTML=Lt,Ds=d(),He=_("p"),He.innerHTML=qt,Ps=d(),k(ze.$$.fragment),Ks=d(),Ee=_("p"),Ee.innerHTML=Qt,Os=d(),k(Ae.$$.fragment),et=d(),xe=_("p"),xe.innerHTML=St,st=d(),Le=_("p"),Le.innerHTML=Dt,tt=d(),k(qe.$$.fragment),at=d(),Qe=_("p"),Qe.innerHTML=Pt,lt=d(),k(Se.$$.fragment),nt=d(),De=_("p"),De.innerHTML=Kt,rt=d(),k(se.$$.fragment),ot=d(),Pe=_("p"),Pe.innerHTML=Ot,it=d(),k(Ke.$$.fragment),ct=d(),Oe=_("p"),Oe.textContent=ea,pt=d(),es=_("p"),es.innerHTML=sa,ut=d(),k(ss.$$.fragment),ft=d(),ps=_("p"),this.h()},l(a){const p=Ra("svelte-u9bgzb",document.head);e=M(p,"META",{name:!0,content:!0}),p.forEach(i),l=g(a),t=M(a,"P",{}),z(t).forEach(i),s=g(a),$(r.$$.fragment,a),n=g(a),$(c.$$.fragment,a),u=g(a),w=M(a,"P",{"data-svelte-h":!0}),I(w)!=="svelte-1gql5oj"&&(w.innerHTML=G),v=g(a),C=M(a,"P",{"data-svelte-h":!0}),I(C)!=="svelte-1gca5uw"&&(C.innerHTML=U),b=g(a),j=M(a,"DIV",{class:!0,"data-svelte-h":!0}),I(j)!=="svelte-1o5x2pv"&&(j.innerHTML=N),X=g(a),$(V.$$.fragment,a),R=g(a),Z=M(a,"P",{"data-svelte-h":!0}),I(Z)!=="svelte-hoqk88"&&(Z.textContent=B),F=g(a),$(E.$$.fragment,a),fs=g(a),ae=M(a,"P",{"data-svelte-h":!0}),I(ae)!=="svelte-mhvkco"&&(ae.textContent=Tt),ms=g(a),P=M(a,"UL",{});var ts=z(P);le=M(ts,"LI",{});var as=z(le);ns=M(as,"P",{"data-svelte-h":!0}),I(ns)!=="svelte-1t6a7b8"&&(ns.innerHTML=Jt),jt=g(as),$(ne.$$.fragment,as),as.forEach(i),_t=g(ts),re=M(ts,"LI",{});var ls=z(re);rs=M(ls,"P",{"data-svelte-h":!0}),I(rs)!=="svelte-1ez1o9h"&&(rs.innerHTML=$t),Mt=g(ls),$(oe.$$.fragment,ls),ls.forEach(i),ts.forEach(i),hs=g(a),ie=M(a,"P",{"data-svelte-h":!0}),I(ie)!=="svelte-1ixvldz"&&(ie.textContent=vt),ds=g(a),$(K.$$.fragment,a),gs=g(a),$(ce.$$.fragment,a),bs=g(a),pe=M(a,"P",{"data-svelte-h":!0}),I(pe)!=="svelte-amoo34"&&(pe.innerHTML=Ut),ws=g(a),ue=M(a,"P",{"data-svelte-h":!0}),I(ue)!=="svelte-e5og20"&&(ue.innerHTML=Ct),js=g(a),$(fe.$$.fragment,a),_s=g(a),me=M(a,"P",{"data-svelte-h":!0}),I(me)!=="svelte-2lbv45"&&(me.innerHTML=It),Ms=g(a),$(he.$$.fragment,a),ys=g(a),de=M(a,"P",{"data-svelte-h":!0}),I(de)!=="svelte-nrn9g9"&&(de.innerHTML=Gt),ks=g(a),$(ge.$$.fragment,a),Ts=g(a),be=M(a,"P",{"data-svelte-h":!0}),I(be)!=="svelte-15ly327"&&(be.innerHTML=Rt),Js=g(a),we=M(a,"P",{"data-svelte-h":!0}),I(we)!=="svelte-b7r0be"&&(we.innerHTML=Zt),$s=g(a),$(je.$$.fragment,a),vs=g(a),_e=M(a,"P",{"data-svelte-h":!0}),I(_e)!=="svelte-11c1w2v"&&(_e.innerHTML=Nt),Us=g(a),$(Me.$$.fragment,a),Cs=g(a),ye=M(a,"P",{"data-svelte-h":!0}),I(ye)!=="svelte-1yhgs5r"&&(ye.innerHTML=Ft),Is=g(a),$(O.$$.fragment,a),Gs=g(a),ke=M(a,"P",{"data-svelte-h":!0}),I(ke)!=="svelte-e7a4ym"&&(ke.innerHTML=Wt),Rs=g(a),$(Te.$$.fragment,a),Zs=g(a),Je=M(a,"P",{"data-svelte-h":!0}),I(Je)!=="svelte-zqcdgz"&&(Je.innerHTML=Bt),Ns=g(a),$e=M(a,"P",{"data-svelte-h":!0}),I($e)!=="svelte-1un4iat"&&($e.innerHTML=Vt),Fs=g(a),$(ve.$$.fragment,a),Ws=g(a),Ue=M(a,"P",{"data-svelte-h":!0}),I(Ue)!=="svelte-svx4j9"&&(Ue.innerHTML=Xt),Bs=g(a),$(Ce.$$.fragment,a),Vs=g(a),Ie=M(a,"P",{"data-svelte-h":!0}),I(Ie)!=="svelte-1skemuq"&&(Ie.textContent=Yt),Xs=g(a),Ge=M(a,"P",{"data-svelte-h":!0}),I(Ge)!=="svelte-qj39jy"&&(Ge.innerHTML=Ht),Ys=g(a),$(Re.$$.fragment,a),Hs=g(a),Ze=M(a,"P",{"data-svelte-h":!0}),I(Ze)!=="svelte-1u5korr"&&(Ze.innerHTML=zt),zs=g(a),$(Ne.$$.fragment,a),Es=g(a),Fe=M(a,"P",{"data-svelte-h":!0}),I(Fe)!=="svelte-ss0lor"&&(Fe.innerHTML=Et),As=g(a),$(We.$$.fragment,a),xs=g(a),Be=M(a,"P",{"data-svelte-h":!0}),I(Be)!=="svelte-1f1vpgi"&&(Be.innerHTML=At),Ls=g(a),$(ee.$$.fragment,a),qs=g(a),Ve=M(a,"P",{"data-svelte-h":!0}),I(Ve)!=="svelte-1m7qjra"&&(Ve.innerHTML=xt),Qs=g(a),$(Xe.$$.fragment,a),Ss=g(a),Ye=M(a,"P",{"data-svelte-h":!0}),I(Ye)!=="svelte-1rpgba6"&&(Ye.innerHTML=Lt),Ds=g(a),He=M(a,"P",{"data-svelte-h":!0}),I(He)!=="svelte-hn87b8"&&(He.innerHTML=qt),Ps=g(a),$(ze.$$.fragment,a),Ks=g(a),Ee=M(a,"P",{"data-svelte-h":!0}),I(Ee)!=="svelte-9lbdnp"&&(Ee.innerHTML=Qt),Os=g(a),$(Ae.$$.fragment,a),et=g(a),xe=M(a,"P",{"data-svelte-h":!0}),I(xe)!=="svelte-ryi2zh"&&(xe.innerHTML=St),st=g(a),Le=M(a,"P",{"data-svelte-h":!0}),I(Le)!=="svelte-13qg5o2"&&(Le.innerHTML=Dt),tt=g(a),$(qe.$$.fragment,a),at=g(a),Qe=M(a,"P",{"data-svelte-h":!0}),I(Qe)!=="svelte-1jz0ya3"&&(Qe.innerHTML=Pt),lt=g(a),$(Se.$$.fragment,a),nt=g(a),De=M(a,"P",{"data-svelte-h":!0}),I(De)!=="svelte-1f1vpgi"&&(De.innerHTML=Kt),rt=g(a),$(se.$$.fragment,a),ot=g(a),Pe=M(a,"P",{"data-svelte-h":!0}),I(Pe)!=="svelte-11yp24k"&&(Pe.innerHTML=Ot),it=g(a),$(Ke.$$.fragment,a),ct=g(a),Oe=M(a,"P",{"data-svelte-h":!0}),I(Oe)!=="svelte-zs1nfs"&&(Oe.textContent=ea),pt=g(a),es=M(a,"P",{"data-svelte-h":!0}),I(es)!=="svelte-1jspkk5"&&(es.innerHTML=sa),ut=g(a),$(ss.$$.fragment,a),ft=g(a),ps=M(a,"P",{}),z(ps).forEach(i),this.h()},h(){y(e,"name","hf:doc:metadata"),y(e,"content",Xl),y(j,"class","mt-4")},m(a,p){H(document.head,e),f(a,l,p),f(a,t,p),f(a,s,p),T(r,a,p),f(a,n,p),T(c,a,p),f(a,u,p),f(a,w,p),f(a,v,p),f(a,C,p),f(a,b,p),f(a,j,p),f(a,X,p),T(V,a,p),f(a,R,p),f(a,Z,p),f(a,F,p),T(E,a,p),f(a,fs,p),f(a,ae,p),f(a,ms,p),f(a,P,p),H(P,le),H(le,ns),H(le,jt),T(ne,le,null),H(P,_t),H(P,re),H(re,rs),H(re,Mt),T(oe,re,null),f(a,hs,p),f(a,ie,p),f(a,ds,p),T(K,a,p),f(a,gs,p),T(ce,a,p),f(a,bs,p),f(a,pe,p),f(a,ws,p),f(a,ue,p),f(a,js,p),T(fe,a,p),f(a,_s,p),f(a,me,p),f(a,Ms,p),T(he,a,p),f(a,ys,p),f(a,de,p),f(a,ks,p),T(ge,a,p),f(a,Ts,p),f(a,be,p),f(a,Js,p),f(a,we,p),f(a,$s,p),T(je,a,p),f(a,vs,p),f(a,_e,p),f(a,Us,p),T(Me,a,p),f(a,Cs,p),f(a,ye,p),f(a,Is,p),T(O,a,p),f(a,Gs,p),f(a,ke,p),f(a,Rs,p),T(Te,a,p),f(a,Zs,p),f(a,Je,p),f(a,Ns,p),f(a,$e,p),f(a,Fs,p),T(ve,a,p),f(a,Ws,p),f(a,Ue,p),f(a,Bs,p),T(Ce,a,p),f(a,Vs,p),f(a,Ie,p),f(a,Xs,p),f(a,Ge,p),f(a,Ys,p),T(Re,a,p),f(a,Hs,p),f(a,Ze,p),f(a,zs,p),T(Ne,a,p),f(a,Es,p),f(a,Fe,p),f(a,As,p),T(We,a,p),f(a,xs,p),f(a,Be,p),f(a,Ls,p),T(ee,a,p),f(a,qs,p),f(a,Ve,p),f(a,Qs,p),T(Xe,a,p),f(a,Ss,p),f(a,Ye,p),f(a,Ds,p),f(a,He,p),f(a,Ps,p),T(ze,a,p),f(a,Ks,p),f(a,Ee,p),f(a,Os,p),T(Ae,a,p),f(a,et,p),f(a,xe,p),f(a,st,p),f(a,Le,p),f(a,tt,p),T(qe,a,p),f(a,at,p),f(a,Qe,p),f(a,lt,p),T(Se,a,p),f(a,nt,p),f(a,De,p),f(a,rt,p),T(se,a,p),f(a,ot,p),f(a,Pe,p),f(a,it,p),T(Ke,a,p),f(a,ct,p),f(a,Oe,p),f(a,pt,p),f(a,es,p),f(a,ut,p),T(ss,a,p),f(a,ft,p),f(a,ps,p),mt=!0},p(a,[p]){const ts={};p&2&&(ts.$$scope={dirty:p,ctx:a}),V.$set(ts);const as={};p&2&&(as.$$scope={dirty:p,ctx:a}),K.$set(as);const ls={};p&2&&(ls.$$scope={dirty:p,ctx:a}),O.$set(ls);const ta={};p&2&&(ta.$$scope={dirty:p,ctx:a}),ee.$set(ta);const aa={};p&2&&(aa.$$scope={dirty:p,ctx:a}),se.$set(aa)},i(a){mt||(m(r.$$.fragment,a),m(c.$$.fragment,a),m(V.$$.fragment,a),m(E.$$.fragment,a),m(ne.$$.fragment,a),m(oe.$$.fragment,a),m(K.$$.fragment,a),m(ce.$$.fragment,a),m(fe.$$.fragment,a),m(he.$$.fragment,a),m(ge.$$.fragment,a),m(je.$$.fragment,a),m(Me.$$.fragment,a),m(O.$$.fragment,a),m(Te.$$.fragment,a),m(ve.$$.fragment,a),m(Ce.$$.fragment,a),m(Re.$$.fragment,a),m(Ne.$$.fragment,a),m(We.$$.fragment,a),m(ee.$$.fragment,a),m(Xe.$$.fragment,a),m(ze.$$.fragment,a),m(Ae.$$.fragment,a),m(qe.$$.fragment,a),m(Se.$$.fragment,a),m(se.$$.fragment,a),m(Ke.$$.fragment,a),m(ss.$$.fragment,a),mt=!0)},o(a){h(r.$$.fragment,a),h(c.$$.fragment,a),h(V.$$.fragment,a),h(E.$$.fragment,a),h(ne.$$.fragment,a),h(oe.$$.fragment,a),h(K.$$.fragment,a),h(ce.$$.fragment,a),h(fe.$$.fragment,a),h(he.$$.fragment,a),h(ge.$$.fragment,a),h(je.$$.fragment,a),h(Me.$$.fragment,a),h(O.$$.fragment,a),h(Te.$$.fragment,a),h(ve.$$.fragment,a),h(Ce.$$.fragment,a),h(Re.$$.fragment,a),h(Ne.$$.fragment,a),h(We.$$.fragment,a),h(ee.$$.fragment,a),h(Xe.$$.fragment,a),h(ze.$$.fragment,a),h(Ae.$$.fragment,a),h(qe.$$.fragment,a),h(Se.$$.fragment,a),h(se.$$.fragment,a),h(Ke.$$.fragment,a),h(ss.$$.fragment,a),mt=!1},d(a){a&&(i(l),i(t),i(s),i(n),i(u),i(w),i(v),i(C),i(b),i(j),i(X),i(R),i(Z),i(F),i(fs),i(ae),i(ms),i(P),i(hs),i(ie),i(ds),i(gs),i(bs),i(pe),i(ws),i(ue),i(js),i(_s),i(me),i(Ms),i(ys),i(de),i(ks),i(Ts),i(be),i(Js),i(we),i($s),i(vs),i(_e),i(Us),i(Cs),i(ye),i(Is),i(Gs),i(ke),i(Rs),i(Zs),i(Je),i(Ns),i($e),i(Fs),i(Ws),i(Ue),i(Bs),i(Vs),i(Ie),i(Xs),i(Ge),i(Ys),i(Hs),i(Ze),i(zs),i(Es),i(Fe),i(As),i(xs),i(Be),i(Ls),i(qs),i(Ve),i(Qs),i(Ss),i(Ye),i(Ds),i(He),i(Ps),i(Ks),i(Ee),i(Os),i(et),i(xe),i(st),i(Le),i(tt),i(at),i(Qe),i(lt),i(nt),i(De),i(rt),i(ot),i(Pe),i(it),i(ct),i(Oe),i(pt),i(es),i(ut),i(ft),i(ps)),i(e),J(r,a),J(c,a),J(V,a),J(E,a),J(ne),J(oe),J(K,a),J(ce,a),J(fe,a),J(he,a),J(ge,a),J(je,a),J(Me,a),J(O,a),J(Te,a),J(ve,a),J(Ce,a),J(Re,a),J(Ne,a),J(We,a),J(ee,a),J(Xe,a),J(ze,a),J(Ae,a),J(qe,a),J(Se,a),J(se,a),J(Ke,a),J(ss,a)}}}const Xl='{"title":"Quickstart","local":"quickstart","sections":[{"title":"Audio","local":"audio","sections":[],"depth":2},{"title":"Vision","local":"vision","sections":[],"depth":2},{"title":"NLP","local":"nlp","sections":[],"depth":2},{"title":"What’s next?","local":"whats-next","sections":[],"depth":2}],"depth":1}';function Yl(o){return yt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Dl extends is{constructor(e){super(),cs(this,e,Yl,Vl,os,{})}}export{Dl as component};
