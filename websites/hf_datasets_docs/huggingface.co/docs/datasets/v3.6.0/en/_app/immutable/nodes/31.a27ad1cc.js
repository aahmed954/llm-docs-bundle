import{s as et,n as lt,o as nt}from"../chunks/scheduler.bdbef820.js";import{S as pt,i as ot,g as o,s as l,r as x,A as it,h as i,f as a,c as n,j as st,u as q,x as R,k as at,y as mt,a as e,v as _,d as w,t as b,w as U}from"../chunks/index.c0aea24a.js";import{C as Z}from"../chunks/CodeBlock.e814ab8d.js";import{H as dt,E as ht}from"../chunks/index.89e522f3.js";function rt(S){let p,X,I,C,m,G,d,A='This guide shows you how to load text datasets. To learn how to load any type of dataset, take a look at the <a class="underline decoration-sky-400 decoration-2 font-semibold" href="./loading">general loading guide</a>.',k,h,P="Text files are one of the most common file types for storing a dataset. By default, ü§ó Datasets samples a text file line by line to build the dataset.",Y,r,F,u,D="To sample a text file by paragraph or even an entire document, use the <code>sample_by</code> parameter:",V,c,z,M,K="You can also use grep patterns to load specific files:",N,y,W,J,O="To load remote text files via HTTP, pass the URLs instead:",v,f,Q,g,tt="To load XML data you can use the ‚Äúxml‚Äù loader, which is equivalent to ‚Äútext‚Äù with sample_by=‚Äúdocument‚Äù:",E,j,H,T,B,$,L;return m=new dt({props:{title:"Load text data",local:"load-text-data",headingTag:"h1"}}),r=new Z({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ0ZXh0JTIyJTJDJTIwZGF0YV9maWxlcyUzRCU3QiUyMnRyYWluJTIyJTNBJTIwJTVCJTIybXlfdGV4dF8xLnR4dCUyMiUyQyUyMCUyMm15X3RleHRfMi50eHQlMjIlNUQlMkMlMjAlMjJ0ZXN0JTIyJTNBJTIwJTIybXlfdGVzdF9maWxlLnR4dCUyMiU3RCklMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMnRleHQlMjIlMkMlMjBkYXRhX2RpciUzRCUyMnBhdGglMkZ0byUyRnRleHQlMkZkYXRhc2V0JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: [<span class="hljs-string">&quot;my_text_1.txt&quot;</span>, <span class="hljs-string">&quot;my_text_2.txt&quot;</span>], <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;my_test_file.txt&quot;</span>})

<span class="hljs-comment"># Load from a directory</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_dir=<span class="hljs-string">&quot;path/to/text/dataset&quot;</span>)`,wrap:!1}}),c=new Z({props:{code:"ZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ0ZXh0JTIyJTJDJTIwZGF0YV9maWxlcyUzRCU3QiUyMnRyYWluJTIyJTNBJTIwJTIybXlfdHJhaW5fZmlsZS50eHQlMjIlMkMlMjAlMjJ0ZXN0JTIyJTNBJTIwJTIybXlfdGVzdF9maWxlLnR4dCUyMiU3RCUyQyUyMHNhbXBsZV9ieSUzRCUyMnBhcmFncmFwaCUyMiklMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMnRleHQlMjIlMkMlMjBkYXRhX2ZpbGVzJTNEJTdCJTIydHJhaW4lMjIlM0ElMjAlMjJteV90cmFpbl9maWxlLnR4dCUyMiUyQyUyMCUyMnRlc3QlMjIlM0ElMjAlMjJteV90ZXN0X2ZpbGUudHh0JTIyJTdEJTJDJTIwc2FtcGxlX2J5JTNEJTIyZG9jdW1lbnQlMjIp",highlighted:`<span class="hljs-comment"># Sample by paragraph</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;my_train_file.txt&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;my_test_file.txt&quot;</span>}, sample_by=<span class="hljs-string">&quot;paragraph&quot;</span>)

<span class="hljs-comment"># Sample by document</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;my_train_file.txt&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;my_test_file.txt&quot;</span>}, sample_by=<span class="hljs-string">&quot;document&quot;</span>)`,wrap:!1}}),y=new Z({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBYzRfc3Vic2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMmFsbGVuYWklMkZjNCUyMiUyQyUyMGRhdGFfZmlsZXMlM0QlMjJlbiUyRmM0LXRyYWluLjAwMDAqLW9mLTAxMDI0Lmpzb24uZ3olMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>c4_subset = load_dataset(<span class="hljs-string">&quot;allenai/c4&quot;</span>, data_files=<span class="hljs-string">&quot;en/c4-train.0000*-of-01024.json.gz&quot;</span>)`,wrap:!1}}),f=new Z({props:{code:"ZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ0ZXh0JTIyJTJDJTIwZGF0YV9maWxlcyUzRCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmxob2VzdHElMkZ0ZXN0JTJGcmVzb2x2ZSUyRm1haW4lMkZzb21lX3RleHQudHh0JTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;text&quot;</span>, data_files=<span class="hljs-string">&quot;https://huggingface.co/datasets/lhoestq/test/resolve/main/some_text.txt&quot;</span>)',wrap:!1}}),j=new Z({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ4bWwlMjIlMkMlMjBkYXRhX2ZpbGVzJTNEJTdCJTIydHJhaW4lMjIlM0ElMjAlNUIlMjJteV94bWxfMS54bWwlMjIlMkMlMjAlMjJteV94bWxfMi54bWwlMjIlNUQlMkMlMjAlMjJ0ZXN0JTIyJTNBJTIwJTIybXlfeG1sX2ZpbGUueG1sJTIyJTdEKSUwQSUwQWRhdGFzZXQlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyeG1sJTIyJTJDJTIwZGF0YV9kaXIlM0QlMjJwYXRoJTJGdG8lMkZ4bWwlMkZkYXRhc2V0JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;xml&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: [<span class="hljs-string">&quot;my_xml_1.xml&quot;</span>, <span class="hljs-string">&quot;my_xml_2.xml&quot;</span>], <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;my_xml_file.xml&quot;</span>})

<span class="hljs-comment"># Load from a directory</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;xml&quot;</span>, data_dir=<span class="hljs-string">&quot;path/to/xml/dataset&quot;</span>)`,wrap:!1}}),T=new ht({props:{source:"https://github.com/huggingface/datasets/blob/main/docs/source/nlp_load.mdx"}}),{c(){p=o("meta"),X=l(),I=o("p"),C=l(),x(m.$$.fragment),G=l(),d=o("p"),d.innerHTML=A,k=l(),h=o("p"),h.textContent=P,Y=l(),x(r.$$.fragment),F=l(),u=o("p"),u.innerHTML=D,V=l(),x(c.$$.fragment),z=l(),M=o("p"),M.textContent=K,N=l(),x(y.$$.fragment),W=l(),J=o("p"),J.textContent=O,v=l(),x(f.$$.fragment),Q=l(),g=o("p"),g.textContent=tt,E=l(),x(j.$$.fragment),H=l(),x(T.$$.fragment),B=l(),$=o("p"),this.h()},l(t){const s=it("svelte-u9bgzb",document.head);p=i(s,"META",{name:!0,content:!0}),s.forEach(a),X=n(t),I=i(t,"P",{}),st(I).forEach(a),C=n(t),q(m.$$.fragment,t),G=n(t),d=i(t,"P",{"data-svelte-h":!0}),R(d)!=="svelte-w06s16"&&(d.innerHTML=A),k=n(t),h=i(t,"P",{"data-svelte-h":!0}),R(h)!=="svelte-1nologr"&&(h.textContent=P),Y=n(t),q(r.$$.fragment,t),F=n(t),u=i(t,"P",{"data-svelte-h":!0}),R(u)!=="svelte-7z7mls"&&(u.innerHTML=D),V=n(t),q(c.$$.fragment,t),z=n(t),M=i(t,"P",{"data-svelte-h":!0}),R(M)!=="svelte-19wmves"&&(M.textContent=K),N=n(t),q(y.$$.fragment,t),W=n(t),J=i(t,"P",{"data-svelte-h":!0}),R(J)!=="svelte-129tbg5"&&(J.textContent=O),v=n(t),q(f.$$.fragment,t),Q=n(t),g=i(t,"P",{"data-svelte-h":!0}),R(g)!=="svelte-q2d66r"&&(g.textContent=tt),E=n(t),q(j.$$.fragment,t),H=n(t),q(T.$$.fragment,t),B=n(t),$=i(t,"P",{}),st($).forEach(a),this.h()},h(){at(p,"name","hf:doc:metadata"),at(p,"content",ut)},m(t,s){mt(document.head,p),e(t,X,s),e(t,I,s),e(t,C,s),_(m,t,s),e(t,G,s),e(t,d,s),e(t,k,s),e(t,h,s),e(t,Y,s),_(r,t,s),e(t,F,s),e(t,u,s),e(t,V,s),_(c,t,s),e(t,z,s),e(t,M,s),e(t,N,s),_(y,t,s),e(t,W,s),e(t,J,s),e(t,v,s),_(f,t,s),e(t,Q,s),e(t,g,s),e(t,E,s),_(j,t,s),e(t,H,s),_(T,t,s),e(t,B,s),e(t,$,s),L=!0},p:lt,i(t){L||(w(m.$$.fragment,t),w(r.$$.fragment,t),w(c.$$.fragment,t),w(y.$$.fragment,t),w(f.$$.fragment,t),w(j.$$.fragment,t),w(T.$$.fragment,t),L=!0)},o(t){b(m.$$.fragment,t),b(r.$$.fragment,t),b(c.$$.fragment,t),b(y.$$.fragment,t),b(f.$$.fragment,t),b(j.$$.fragment,t),b(T.$$.fragment,t),L=!1},d(t){t&&(a(X),a(I),a(C),a(G),a(d),a(k),a(h),a(Y),a(F),a(u),a(V),a(z),a(M),a(N),a(W),a(J),a(v),a(Q),a(g),a(E),a(H),a(B),a($)),a(p),U(m,t),U(r,t),U(c,t),U(y,t),U(f,t),U(j,t),U(T,t)}}}const ut='{"title":"Load text data","local":"load-text-data","sections":[],"depth":1}';function ct(S){return nt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class gt extends pt{constructor(p){super(),ot(this,p,ct,rt,et,{})}}export{gt as component};
