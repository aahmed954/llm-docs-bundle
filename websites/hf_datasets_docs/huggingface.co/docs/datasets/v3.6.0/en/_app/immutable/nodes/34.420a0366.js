import{s as Mo,o as To,n as C}from"../chunks/scheduler.bdbef820.js";import{S as Jo,i as jo,g as c,s as r,r as f,A as ko,h as p,f as i,c as o,j as M,u as h,x as v,k as T,y as n,a as u,v as _,d as b,t as $,w as x}from"../chunks/index.c0aea24a.js";import{D as J}from"../chunks/Docstring.a4266085.js";import{C as U}from"../chunks/CodeBlock.e814ab8d.js";import{E as k}from"../chunks/ExampleCodeBlock.8633afcb.js";import{H as es,E as Co}from"../chunks/index.89e522f3.js";function Uo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIlMEFidWlsZGVyJTIwJTNEJTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIoJ2Nvcm5lbGwtbW92aWUtcmV2aWV3LWRhdGElMkZyb3R0ZW5fdG9tYXRvZXMnKSUwQWJ1aWxkZXIuZG93bmxvYWRfYW5kX3ByZXBhcmUoKSUwQWRzJTIwJTNEJTIwYnVpbGRlci5hc19kYXRhc2V0KHNwbGl0JTNEJ3RyYWluJyklMEFkcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>builder = load_dataset_builder(<span class="hljs-string">&#x27;cornell-movie-review-data/rotten_tomatoes&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>builder.download_and_prepare()
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = builder.as_dataset(split=<span class="hljs-string">&#x27;train&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds
Dataset({
    features: [<span class="hljs-string">&#x27;text&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>],
    num_rows: <span class="hljs-number">8530</span>
})`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Ro(y){let a,w="Download and prepare the dataset as Arrow files that can be loaded as a Dataset using <code>builder.as_dataset()</code>:",d,s,l;return s=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIlMEFidWlsZGVyJTIwJTNEJTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIoJTIyY29ybmVsbC1tb3ZpZS1yZXZpZXctZGF0YSUyRnJvdHRlbl90b21hdG9lcyUyMiklMEFidWlsZGVyLmRvd25sb2FkX2FuZF9wcmVwYXJlKCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>builder = load_dataset_builder(<span class="hljs-string">&quot;cornell-movie-review-data/rotten_tomatoes&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>builder.download_and_prepare()`,wrap:!1}}),{c(){a=c("p"),a.innerHTML=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-i6fpq7"&&(a.innerHTML=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function No(y){let a,w="Download and prepare the dataset as sharded Parquet files locally:",d,s,l;return s=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIlMEFidWlsZGVyJTIwJTNEJTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIoJTIyY29ybmVsbC1tb3ZpZS1yZXZpZXctZGF0YSUyRnJvdHRlbl90b21hdG9lcyUyMiklMEFidWlsZGVyLmRvd25sb2FkX2FuZF9wcmVwYXJlKCUyMi4lMkZvdXRwdXRfZGlyJTIyJTJDJTIwZmlsZV9mb3JtYXQlM0QlMjJwYXJxdWV0JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>builder = load_dataset_builder(<span class="hljs-string">&quot;cornell-movie-review-data/rotten_tomatoes&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>builder.download_and_prepare(<span class="hljs-string">&quot;./output_dir&quot;</span>, file_format=<span class="hljs-string">&quot;parquet&quot;</span>)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-1035kd7"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Go(y){let a,w="Download and prepare the dataset as sharded Parquet files in a cloud storage:",d,s,l;return s=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIlMEFzdG9yYWdlX29wdGlvbnMlMjAlM0QlMjAlN0IlMjJrZXklMjIlM0ElMjBhd3NfYWNjZXNzX2tleV9pZCUyQyUyMCUyMnNlY3JldCUyMiUzQSUyMGF3c19zZWNyZXRfYWNjZXNzX2tleSU3RCUwQWJ1aWxkZXIlMjAlM0QlMjBsb2FkX2RhdGFzZXRfYnVpbGRlciglMjJjb3JuZWxsLW1vdmllLXJldmlldy1kYXRhJTJGcm90dGVuX3RvbWF0b2VzJTIyKSUwQWJ1aWxkZXIuZG93bmxvYWRfYW5kX3ByZXBhcmUoJTIyczMlM0ElMkYlMkZteS1idWNrZXQlMkZteV9yb3R0ZW5fdG9tYXRvZXMlMjIlMkMlMjBzdG9yYWdlX29wdGlvbnMlM0RzdG9yYWdlX29wdGlvbnMlMkMlMjBmaWxlX2Zvcm1hdCUzRCUyMnBhcnF1ZXQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>storage_options = {<span class="hljs-string">&quot;key&quot;</span>: aws_access_key_id, <span class="hljs-string">&quot;secret&quot;</span>: aws_secret_access_key}
<span class="hljs-meta">&gt;&gt;&gt; </span>builder = load_dataset_builder(<span class="hljs-string">&quot;cornell-movie-review-data/rotten_tomatoes&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>builder.download_and_prepare(<span class="hljs-string">&quot;s3://my-bucket/my_rotten_tomatoes&quot;</span>, storage_options=storage_options, file_format=<span class="hljs-string">&quot;parquet&quot;</span>)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-y7m7rz"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Xo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIlMEFkc19idWlsZGVyJTIwJTNEJTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIoJ3Zpdm9zJyklMEFkc19idWlsZGVyLmdldF9hbGxfZXhwb3J0ZWRfZGF0YXNldF9pbmZvcygp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder = load_dataset_builder(<span class="hljs-string">&#x27;vivos&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder.get_all_exported_dataset_infos()
{<span class="hljs-string">&#x27;default&#x27;</span>: DatasetInfo(description=<span class="hljs-string">&#x27;&#x27;</span>, citation=<span class="hljs-string">&#x27;&#x27;</span>, homepage=<span class="hljs-string">&#x27;&#x27;</span>, license=<span class="hljs-string">&#x27;&#x27;</span>, features={<span class="hljs-string">&#x27;speaker_id&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;path&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">16000</span>, mono=<span class="hljs-literal">True</span>, decode=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;sentence&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}, post_processed=<span class="hljs-literal">None</span>, supervised_keys=<span class="hljs-literal">None</span>, builder_name=<span class="hljs-literal">None</span>, dataset_name=<span class="hljs-literal">None</span>, config_name=<span class="hljs-string">&#x27;default&#x27;</span>, version=<span class="hljs-literal">None</span>, splits={<span class="hljs-string">&#x27;train&#x27;</span>: SplitInfo(name=<span class="hljs-string">&#x27;train&#x27;</span>, num_bytes=<span class="hljs-number">1722002133</span>, num_examples=<span class="hljs-number">11660</span>, shard_lengths=<span class="hljs-literal">None</span>, dataset_name=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;test&#x27;</span>: SplitInfo(name=<span class="hljs-string">&#x27;test&#x27;</span>, num_bytes=<span class="hljs-number">86120227</span>, num_examples=<span class="hljs-number">760</span>, shard_lengths=<span class="hljs-literal">None</span>, dataset_name=<span class="hljs-literal">None</span>)}, download_checksums=<span class="hljs-literal">None</span>, download_size=<span class="hljs-number">1475540500</span>, post_processing_size=<span class="hljs-literal">None</span>, dataset_size=<span class="hljs-number">1808122360</span>, size_in_bytes=<span class="hljs-literal">None</span>)}`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Zo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIlMEFkc19idWlsZGVyJTIwJTNEJTIwbG9hZF9kYXRhc2V0X2J1aWxkZXIoJ2Nvcm5lbGwtbW92aWUtcmV2aWV3LWRhdGElMkZyb3R0ZW5fdG9tYXRvZXMnKSUwQWRzX2J1aWxkZXIuZ2V0X2V4cG9ydGVkX2RhdGFzZXRfaW5mbygp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset_builder
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder = load_dataset_builder(<span class="hljs-string">&#x27;cornell-movie-review-data/rotten_tomatoes&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds_builder.get_exported_dataset_info()
DatasetInfo(description=<span class="hljs-string">&#x27;&#x27;</span>, citation=<span class="hljs-string">&#x27;&#x27;</span>, homepage=<span class="hljs-string">&#x27;&#x27;</span>, license=<span class="hljs-string">&#x27;&#x27;</span>, features={<span class="hljs-string">&#x27;speaker_id&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;path&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;audio&#x27;</span>: Audio(sampling_rate=<span class="hljs-number">16000</span>, mono=<span class="hljs-literal">True</span>, decode=<span class="hljs-literal">True</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;sentence&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}, post_processed=<span class="hljs-literal">None</span>, supervised_keys=<span class="hljs-literal">None</span>, builder_name=<span class="hljs-literal">None</span>, dataset_name=<span class="hljs-literal">None</span>, config_name=<span class="hljs-string">&#x27;default&#x27;</span>, version=<span class="hljs-literal">None</span>, splits={<span class="hljs-string">&#x27;train&#x27;</span>: SplitInfo(name=<span class="hljs-string">&#x27;train&#x27;</span>, num_bytes=<span class="hljs-number">1722002133</span>, num_examples=<span class="hljs-number">11660</span>, shard_lengths=<span class="hljs-literal">None</span>, dataset_name=<span class="hljs-literal">None</span>), <span class="hljs-string">&#x27;test&#x27;</span>: SplitInfo(name=<span class="hljs-string">&#x27;test&#x27;</span>, num_bytes=<span class="hljs-number">86120227</span>, num_examples=<span class="hljs-number">760</span>, shard_lengths=<span class="hljs-literal">None</span>, dataset_name=<span class="hljs-literal">None</span>)}, download_checksums=<span class="hljs-literal">None</span>, download_size=<span class="hljs-number">1475540500</span>, post_processing_size=<span class="hljs-literal">None</span>, dataset_size=<span class="hljs-number">1808122360</span>, size_in_bytes=<span class="hljs-literal">None</span>)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Io(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZG93bmxvYWRlZF9maWxlcyUyMCUzRCUyMGRsX21hbmFnZXIuZG93bmxvYWQoJ2h0dHBzJTNBJTJGJTJGc3RvcmFnZS5nb29nbGVhcGlzLmNvbSUyRnNlbGRvbi1kYXRhc2V0cyUyRnNlbnRlbmNlX3BvbGFyaXR5X3YxJTJGcnQtcG9sYXJpdHlkYXRhLnRhci5neicp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>downloaded_files = dl_manager.download(<span class="hljs-string">&#x27;https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz&#x27;</span>)',wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Do(y){let a,w="Is roughly equivalent to:",d,s,l;return s=new U({props:{code:"ZXh0cmFjdGVkX3BhdGhzJTIwJTNEJTIwZGxfbWFuYWdlci5leHRyYWN0KGRsX21hbmFnZXIuZG93bmxvYWQodXJsX29yX3VybHMpKQ==",highlighted:'<span class="hljs-attr">extracted_paths</span> = dl_manager.extract(dl_manager.download(url_or_urls))',wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-yva38v"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Bo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZG93bmxvYWRlZF9maWxlcyUyMCUzRCUyMGRsX21hbmFnZXIuZG93bmxvYWQoJ2h0dHBzJTNBJTJGJTJGc3RvcmFnZS5nb29nbGVhcGlzLmNvbSUyRnNlbGRvbi1kYXRhc2V0cyUyRnNlbnRlbmNlX3BvbGFyaXR5X3YxJTJGcnQtcG9sYXJpdHlkYXRhLnRhci5neicpJTBBZXh0cmFjdGVkX2ZpbGVzJTIwJTNEJTIwZGxfbWFuYWdlci5leHRyYWN0KGRvd25sb2FkZWRfZmlsZXMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>downloaded_files = dl_manager.download(<span class="hljs-string">&#x27;https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>extracted_files = dl_manager.extract(downloaded_files)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Fo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"YXJjaGl2ZSUyMCUzRCUyMGRsX21hbmFnZXIuZG93bmxvYWQoJ2h0dHBzJTNBJTJGJTJGc3RvcmFnZS5nb29nbGVhcGlzLmNvbSUyRnNlbGRvbi1kYXRhc2V0cyUyRnNlbnRlbmNlX3BvbGFyaXR5X3YxJTJGcnQtcG9sYXJpdHlkYXRhLnRhci5neicpJTBBZmlsZXMlMjAlM0QlMjBkbF9tYW5hZ2VyLml0ZXJfYXJjaGl2ZShhcmNoaXZlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>archive = dl_manager.download(<span class="hljs-string">&#x27;https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>files = dl_manager.iter_archive(archive)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Vo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZmlsZXMlMjAlM0QlMjBkbF9tYW5hZ2VyLmRvd25sb2FkX2FuZF9leHRyYWN0KCdodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZiZWFucyUyRnJlc29sdmUlMkZtYWluJTJGZGF0YSUyRnRyYWluLnppcCcpJTBBZmlsZXMlMjAlM0QlMjBkbF9tYW5hZ2VyLml0ZXJfZmlsZXMoZmlsZXMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>files = dl_manager.download_and_extract(<span class="hljs-string">&#x27;https://huggingface.co/datasets/beans/resolve/main/data/train.zip&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>files = dl_manager.iter_files(files)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function zo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZG93bmxvYWRlZF9maWxlcyUyMCUzRCUyMGRsX21hbmFnZXIuZG93bmxvYWQoJ2h0dHBzJTNBJTJGJTJGc3RvcmFnZS5nb29nbGVhcGlzLmNvbSUyRnNlbGRvbi1kYXRhc2V0cyUyRnNlbnRlbmNlX3BvbGFyaXR5X3YxJTJGcnQtcG9sYXJpdHlkYXRhLnRhci5neicp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>downloaded_files = dl_manager.download(<span class="hljs-string">&#x27;https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz&#x27;</span>)',wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function So(y){let a,w="Is equivalent to:",d,s,l;return s=new U({props:{code:"dXJscyUyMCUzRCUyMGRsX21hbmFnZXIuZXh0cmFjdChkbF9tYW5hZ2VyLmRvd25sb2FkKHVybF9vcl91cmxzKSk=",highlighted:'<span class="hljs-attribute">urls</span> <span class="hljs-operator">=</span> dl_manager.extract(dl_manager.download(url_or_urls))',wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-b0lbw9"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Eo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZG93bmxvYWRlZF9maWxlcyUyMCUzRCUyMGRsX21hbmFnZXIuZG93bmxvYWQoJ2h0dHBzJTNBJTJGJTJGc3RvcmFnZS5nb29nbGVhcGlzLmNvbSUyRnNlbGRvbi1kYXRhc2V0cyUyRnNlbnRlbmNlX3BvbGFyaXR5X3YxJTJGcnQtcG9sYXJpdHlkYXRhLnRhci5neicpJTBBZXh0cmFjdGVkX2ZpbGVzJTIwJTNEJTIwZGxfbWFuYWdlci5leHRyYWN0KGRvd25sb2FkZWRfZmlsZXMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>downloaded_files = dl_manager.download(<span class="hljs-string">&#x27;https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>extracted_files = dl_manager.extract(downloaded_files)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Yo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"YXJjaGl2ZSUyMCUzRCUyMGRsX21hbmFnZXIuZG93bmxvYWQoJ2h0dHBzJTNBJTJGJTJGc3RvcmFnZS5nb29nbGVhcGlzLmNvbSUyRnNlbGRvbi1kYXRhc2V0cyUyRnNlbnRlbmNlX3BvbGFyaXR5X3YxJTJGcnQtcG9sYXJpdHlkYXRhLnRhci5neicpJTBBZmlsZXMlMjAlM0QlMjBkbF9tYW5hZ2VyLml0ZXJfYXJjaGl2ZShhcmNoaXZlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>archive = dl_manager.download(<span class="hljs-string">&#x27;https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>files = dl_manager.iter_archive(archive)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Qo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZmlsZXMlMjAlM0QlMjBkbF9tYW5hZ2VyLmRvd25sb2FkX2FuZF9leHRyYWN0KCdodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZiZWFucyUyRnJlc29sdmUlMkZtYWluJTJGZGF0YSUyRnRyYWluLnppcCcpJTBBZmlsZXMlMjAlM0QlMjBkbF9tYW5hZ2VyLml0ZXJfZmlsZXMoZmlsZXMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>files = dl_manager.download_and_extract(<span class="hljs-string">&#x27;https://huggingface.co/datasets/beans/resolve/main/data/train.zip&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>files = dl_manager.iter_files(files)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Wo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZGF0YXNldHMuU3BsaXRHZW5lcmF0b3IoJTBBJTIwJTIwJTIwJTIwbmFtZSUzRGRhdGFzZXRzLlNwbGl0LlRSQUlOJTJDJTBBJTIwJTIwJTIwJTIwZ2VuX2t3YXJncyUzRCU3QiUyMnNwbGl0X2tleSUyMiUzQSUyMCUyMnRyYWluJTIyJTJDJTIwJTIyZmlsZXMlMjIlM0ElMjBkbF9tYW5hZ2VyLmRvd25sb2FkX2FuZF9leHRyYWN0KHVybCklN0QlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>datasets.SplitGenerator(
<span class="hljs-meta">... </span>    name=datasets.Split.TRAIN,
<span class="hljs-meta">... </span>    gen_kwargs={<span class="hljs-string">&quot;split_key&quot;</span>: <span class="hljs-string">&quot;train&quot;</span>, <span class="hljs-string">&quot;files&quot;</span>: dl_manager.download_and_extract(url)},
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Lo(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"ZGF0YXNldHMuU3BsaXRHZW5lcmF0b3IoJTBBJTIwJTIwJTIwJTIwbmFtZSUzRGRhdGFzZXRzLlNwbGl0LlRSQUlOJTJDJTBBJTIwJTIwJTIwJTIwZ2VuX2t3YXJncyUzRCU3QiUyMnNwbGl0X2tleSUyMiUzQSUyMCUyMnRyYWluJTIyJTJDJTIwJTIyZmlsZXMlMjIlM0ElMjBkbF9tYW5hZ2VyLmRvd25sb2FkX2FuZCUyMGV4dHJhY3QodXJsKSU3RCUyQyUwQSklMkMlMEFkYXRhc2V0cy5TcGxpdEdlbmVyYXRvciglMEElMjAlMjAlMjAlMjBuYW1lJTNEZGF0YXNldHMuU3BsaXQuVkFMSURBVElPTiUyQyUwQSUyMCUyMCUyMCUyMGdlbl9rd2FyZ3MlM0QlN0IlMjJzcGxpdF9rZXklMjIlM0ElMjAlMjJ2YWxpZGF0aW9uJTIyJTJDJTIwJTIyZmlsZXMlMjIlM0ElMjBkbF9tYW5hZ2VyLmRvd25sb2FkX2FuZCUyMGV4dHJhY3QodXJsKSU3RCUyQyUwQSklMkMlMEFkYXRhc2V0cy5TcGxpdEdlbmVyYXRvciglMEElMjAlMjAlMjAlMjBuYW1lJTNEZGF0YXNldHMuU3BsaXQuVEVTVCUyQyUwQSUyMCUyMCUyMCUyMGdlbl9rd2FyZ3MlM0QlN0IlMjJzcGxpdF9rZXklMjIlM0ElMjAlMjJ0ZXN0JTIyJTJDJTIwJTIyZmlsZXMlMjIlM0ElMjBkbF9tYW5hZ2VyLmRvd25sb2FkX2FuZCUyMGV4dHJhY3QodXJsKSU3RCUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>datasets.SplitGenerator(
<span class="hljs-meta">... </span>    name=datasets.Split.TRAIN,
<span class="hljs-meta">... </span>    gen_kwargs={<span class="hljs-string">&quot;split_key&quot;</span>: <span class="hljs-string">&quot;train&quot;</span>, <span class="hljs-string">&quot;files&quot;</span>: dl_manager.download_and extract(url)},
<span class="hljs-meta">... </span>),
<span class="hljs-meta">... </span>datasets.SplitGenerator(
<span class="hljs-meta">... </span>    name=datasets.Split.VALIDATION,
<span class="hljs-meta">... </span>    gen_kwargs={<span class="hljs-string">&quot;split_key&quot;</span>: <span class="hljs-string">&quot;validation&quot;</span>, <span class="hljs-string">&quot;files&quot;</span>: dl_manager.download_and extract(url)},
<span class="hljs-meta">... </span>),
<span class="hljs-meta">... </span>datasets.SplitGenerator(
<span class="hljs-meta">... </span>    name=datasets.Split.TEST,
<span class="hljs-meta">... </span>    gen_kwargs={<span class="hljs-string">&quot;split_key&quot;</span>: <span class="hljs-string">&quot;test&quot;</span>, <span class="hljs-string">&quot;files&quot;</span>: dl_manager.download_and extract(url)},
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Ho(y){let a,w="Each descriptor can be composed with other using addition or slice:",d,s,l;return s=new U({props:{code:"c3BsaXQlMjAlM0QlMjBkYXRhc2V0cy5TcGxpdC5UUkFJTi5zdWJzcGxpdChkYXRhc2V0cy5wZXJjZW50JTVCMCUzQTI1JTVEKSUyMCUyQiUyMGRhdGFzZXRzLlNwbGl0LlRFU1Q=",highlighted:'split = datasets.Split.TRAIN.subsplit(datasets.percent[<span class="hljs-number">0</span>:<span class="hljs-number">25</span>]) + datasets.Split.TEST',wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-in376m"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Ao(y){let a,w="A split cannot be added twice, so the following will fail:",d,s,l;return s=new U({props:{code:"c3BsaXQlMjAlM0QlMjAoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwZGF0YXNldHMuU3BsaXQuVFJBSU4uc3Vic3BsaXQoZGF0YXNldHMucGVyY2VudCU1QiUzQTI1JTVEKSUyMCUyQiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGRhdGFzZXRzLlNwbGl0LlRSQUlOLnN1YnNwbGl0KGRhdGFzZXRzLnBlcmNlbnQlNUI3NSUzQSU1RCklMEEpJTIwJTIwJTIzJTIwRXJyb3IlMEFzcGxpdCUyMCUzRCUyMGRhdGFzZXRzLlNwbGl0LlRFU1QlMjAlMkIlMjBkYXRhc2V0cy5TcGxpdC5BTEwlMjAlMjAlMjMlMjBFcnJvcg==",highlighted:`split = (
        datasets.Split.TRAIN.subsplit(datasets.percent[:<span class="hljs-number">25</span>]) +
        datasets.Split.TRAIN.subsplit(datasets.percent[<span class="hljs-number">75</span>:])
)  <span class="hljs-comment"># Error</span>
split = datasets.Split.TEST + datasets.Split.ALL  <span class="hljs-comment"># Error</span>`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-1dn84z5"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Po(y){let a,w="The slices can be applied only one time. So the following are valid:",d,s,l;return s=new U({props:{code:"c3BsaXQlMjAlM0QlMjAoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwZGF0YXNldHMuU3BsaXQuVFJBSU4uc3Vic3BsaXQoZGF0YXNldHMucGVyY2VudCU1QiUzQTI1JTVEKSUyMCUyQiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGRhdGFzZXRzLlNwbGl0LlRFU1Quc3Vic3BsaXQoZGF0YXNldHMucGVyY2VudCU1QiUzQTUwJTVEKSUwQSklMEFzcGxpdCUyMCUzRCUyMChkYXRhc2V0cy5TcGxpdC5UUkFJTiUyMCUyQiUyMGRhdGFzZXRzLlNwbGl0LlRFU1QpLnN1YnNwbGl0KGRhdGFzZXRzLnBlcmNlbnQlNUIlM0E1MCU1RCk=",highlighted:`split = (
        datasets.Split.TRAIN.subsplit(datasets.percent[:<span class="hljs-number">25</span>]) +
        datasets.Split.TEST.subsplit(datasets.percent[:<span class="hljs-number">50</span>])
)
split = (datasets.Split.TRAIN + datasets.Split.TEST).subsplit(datasets.percent[:<span class="hljs-number">50</span>])`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-f377rx"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function qo(y){let a,w="But this is not valid:",d,s,l;return s=new U({props:{code:"dHJhaW4lMjAlM0QlMjBkYXRhc2V0cy5TcGxpdC5UUkFJTiUwQXRlc3QlMjAlM0QlMjBkYXRhc2V0cy5TcGxpdC5URVNUJTBBc3BsaXQlMjAlM0QlMjB0cmFpbi5zdWJzcGxpdChkYXRhc2V0cy5wZXJjZW50JTVCJTNBMjUlNUQpLnN1YnNwbGl0KGRhdGFzZXRzLnBlcmNlbnQlNUIlM0EyNSU1RCklMEFzcGxpdCUyMCUzRCUyMCh0cmFpbi5zdWJzcGxpdChkYXRhc2V0cy5wZXJjZW50JTVCJTNBMjUlNUQpJTIwJTJCJTIwdGVzdCkuc3Vic3BsaXQoZGF0YXNldHMucGVyY2VudCU1QiUzQTUwJTVEKQ==",highlighted:`train = datasets.Split.TRAIN
test = datasets.Split.TEST
split = train.subsplit(datasets.percent[:<span class="hljs-number">25</span>]).subsplit(datasets.percent[:<span class="hljs-number">25</span>])
split = (train.subsplit(datasets.percent[:<span class="hljs-number">25</span>]) + test).subsplit(datasets.percent[:<span class="hljs-number">50</span>])`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-1jf0xuu"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Oo(y){let a,w="Examples:",d,s,l;return s=new U({props:{code:"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",highlighted:`<span class="hljs-comment"># The following lines are equivalent:</span>
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=<span class="hljs-string">&#x27;test[:33%]&#x27;</span>)
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=datasets.ReadInstruction.from_spec(<span class="hljs-string">&#x27;test[:33%]&#x27;</span>))
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=datasets.ReadInstruction(<span class="hljs-string">&#x27;test&#x27;</span>, to=<span class="hljs-number">33</span>, unit=<span class="hljs-string">&#x27;%&#x27;</span>))
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=datasets.ReadInstruction(
<span class="hljs-string">&#x27;test&#x27;</span>, from_=<span class="hljs-number">0</span>, to=<span class="hljs-number">33</span>, unit=<span class="hljs-string">&#x27;%&#x27;</span>))

<span class="hljs-comment"># The following lines are equivalent:</span>
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=<span class="hljs-string">&#x27;test[:33%]+train[1:-1]&#x27;</span>)
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=datasets.ReadInstruction.from_spec(
<span class="hljs-string">&#x27;test[:33%]+train[1:-1]&#x27;</span>))
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=(
datasets.ReadInstruction(<span class="hljs-string">&#x27;test&#x27;</span>, to=<span class="hljs-number">33</span>, unit=<span class="hljs-string">&#x27;%&#x27;</span>) +
datasets.ReadInstruction(<span class="hljs-string">&#x27;train&#x27;</span>, from_=<span class="hljs-number">1</span>, to=-<span class="hljs-number">1</span>, unit=<span class="hljs-string">&#x27;abs&#x27;</span>)))

<span class="hljs-comment"># The following lines are equivalent:</span>
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=<span class="hljs-string">&#x27;test[:33%](pct1_dropremainder)&#x27;</span>)
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=datasets.ReadInstruction.from_spec(
<span class="hljs-string">&#x27;test[:33%](pct1_dropremainder)&#x27;</span>))
ds = datasets.load_dataset(<span class="hljs-string">&#x27;mnist&#x27;</span>, split=datasets.ReadInstruction(
<span class="hljs-string">&#x27;test&#x27;</span>, from_=<span class="hljs-number">0</span>, to=<span class="hljs-number">33</span>, unit=<span class="hljs-string">&#x27;%&#x27;</span>, rounding=<span class="hljs-string">&quot;pct1_dropremainder&quot;</span>))

<span class="hljs-comment"># 10-fold validation:</span>
tests = datasets.load_dataset(
<span class="hljs-string">&#x27;mnist&#x27;</span>,
[datasets.ReadInstruction(<span class="hljs-string">&#x27;train&#x27;</span>, from_=k, to=k+<span class="hljs-number">10</span>, unit=<span class="hljs-string">&#x27;%&#x27;</span>)
<span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">100</span>, <span class="hljs-number">10</span>)])
trains = datasets.load_dataset(
<span class="hljs-string">&#x27;mnist&#x27;</span>,
[datasets.ReadInstruction(<span class="hljs-string">&#x27;train&#x27;</span>, to=k, unit=<span class="hljs-string">&#x27;%&#x27;</span>) + datasets.ReadInstruction(<span class="hljs-string">&#x27;train&#x27;</span>, from_=k+<span class="hljs-number">10</span>, unit=<span class="hljs-string">&#x27;%&#x27;</span>)
<span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">100</span>, <span class="hljs-number">10</span>)])`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-kvfsh7"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function Ko(y){let a,w="Examples:",d,s,l;return s=new U({props:{code:"dGVzdCUzQSUyMHRlc3QlMjBzcGxpdC4lMEF0ZXN0JTIwJTJCJTIwdmFsaWRhdGlvbiUzQSUyMHRlc3QlMjBzcGxpdCUyMCUyQiUyMHZhbGlkYXRpb24lMjBzcGxpdC4lMEF0ZXN0JTVCMTAlM0ElNUQlM0ElMjB0ZXN0JTIwc3BsaXQlMkMlMjBtaW51cyUyMGl0cyUyMGZpcnN0JTIwMTAlMjByZWNvcmRzLiUwQXRlc3QlNUIlM0ExMCUyNSU1RCUzQSUyMGZpcnN0JTIwMTAlMjUlMjByZWNvcmRzJTIwb2YlMjB0ZXN0JTIwc3BsaXQuJTBBdGVzdCU1QiUzQTIwJTI1JTVEKHBjdDFfZHJvcHJlbWFpbmRlciklM0ElMjBmaXJzdCUyMDEwJTI1JTIwcmVjb3JkcyUyQyUyMHJvdW5kZWQlMjB3aXRoJTIwdGhlJTIwcGN0MV9kcm9wcmVtYWluZGVyJTIwcm91bmRpbmcuJTBBdGVzdCU1QiUzQS01JTI1JTVEJTJCdHJhaW4lNUI0MCUyNSUzQTYwJTI1JTVEJTNBJTIwZmlyc3QlMjA5NSUyNSUyMG9mJTIwdGVzdCUyMCUyQiUyMG1pZGRsZSUyMDIwJTI1JTIwb2YlMjB0cmFpbi4=",highlighted:`<span class="hljs-keyword">test: test</span> split.
<span class="hljs-keyword">test </span>+ validation: test split + validation split.
test[10:]: test split, minus its first 10 records.
test[:10%]: first 10% records of test split.
test[:20%](pct1_dropremainder): first 10% records, rounded with the pct1_dropremainder rounding.
test[:<span class="hljs-string">-5</span>%]+train[40%:60%]: first 95% of test + middle 20% of train.`,wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-kvfsh7"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function el(y){let a,w="Example:",d,s,l;return s=new U({props:{code:"VkVSU0lPTiUyMCUzRCUyMGRhdGFzZXRzLlZlcnNpb24oJTIyMS4wLjAlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>VERSION = datasets.Version(<span class="hljs-string">&quot;1.0.0&quot;</span>)',wrap:!1}}),{c(){a=c("p"),a.textContent=w,d=r(),f(s.$$.fragment)},l(e){a=p(e,"P",{"data-svelte-h":!0}),v(a)!=="svelte-11lpom8"&&(a.textContent=w),d=o(e),h(s.$$.fragment,e)},m(e,m){u(e,a,m),u(e,d,m),_(s,e,m),l=!0},p:C,i(e){l||(b(s.$$.fragment,e),l=!0)},o(e){$(s.$$.fragment,e),l=!1},d(e){e&&(i(a),i(d)),x(s,e)}}}function tl(y){let a,w,d,s,l,e,m,as,ot,$r='🤗 Datasets relies on two main classes during the dataset building process: <a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.DatasetBuilder">DatasetBuilder</a> and <a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.BuilderConfig">BuilderConfig</a>.',ss,j,lt,Js,Ht,xr="Abstract base class for all datasets.",js,At,vr="<code>DatasetBuilder</code> has 3 key methods:",ks,Pt,wr=`<li><code>DatasetBuilder.info</code>: Documents the dataset, including feature
names, types, shapes, version, splits, citation, etc.</li> <li><a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.DatasetBuilder.download_and_prepare">DatasetBuilder.download_and_prepare()</a>: Downloads the source data
and writes it to disk.</li> <li><a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.DatasetBuilder.as_dataset">DatasetBuilder.as_dataset()</a>: Generates a <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a>.</li>`,Cs,qt,yr=`Some <code>DatasetBuilder</code>s expose multiple variants of the
dataset by defining a <a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.BuilderConfig">BuilderConfig</a> subclass and accepting a
config object (or name) on construction. Configurable datasets expose a
pre-defined set of configurations in <code>DatasetBuilder.builder_configs()</code>.`,Us,oe,dt,Rs,Ot,Mr="Return a Dataset for the specified split.",Ns,Ge,Gs,D,it,Xs,Kt,Tr="Downloads and prepares dataset for reading.",Zs,ea,Jr="Example:",Is,Xe,Ds,Ze,Bs,Ie,Fs,le,ct,Vs,ta,jr="Empty dict if doesn’t exist",zs,De,Ss,de,pt,Es,aa,kr="Empty <code>DatasetInfo</code> if doesn’t exist",Ys,Be,Qs,Fe,mt,Ws,sa,Cr="Return the path of the module of this class or subclass.",ns,K,gt,Ls,na,Ur="Base class for datasets with data generation based on dict generators.",Hs,ra,Rr=`<code>GeneratorBasedBuilder</code> is a convenience class that abstracts away much
of the data writing and reading of <code>DatasetBuilder</code>. It expects subclasses to
implement generators of feature dictionaries across the dataset splits
(<code>_split_generators</code>). See the method docstrings for details.`,rs,$e,ut,As,oa,Nr="Base class for datasets with data generation based on Arrow loading functions (CSV/JSON/Parquet).",os,Q,ft,Ps,la,Gr="Base class for <code>DatasetBuilder</code> data configuration.",qs,da,Xr=`<code>DatasetBuilder</code> subclasses with data configuration options should subclass
<code>BuilderConfig</code> and add their own properties.`,Os,A,ht,Ks,ia,Zr=`The config id is used to build the cache directory.
By default it is equal to the config name.
However the name of a config is not sufficient to have a unique identifier for the dataset being generated
since it doesn’t take into account:`,en,ca,Ir="<li>the config kwargs that can be used to overwrite attributes</li> <li>the custom features used to write the dataset</li> <li>the data_files for json/text/csv/pandas datasets</li>",tn,pa,Dr="Therefore the config id is just the config name with an optional suffix based on these.",ls,_t,ds,Z,bt,an,P,$t,sn,ma,Br="Download given URL(s).",nn,ga,Fr="By default, only one process is used for download. Pass customized <code>download_config.num_proc</code> to change this behavior.",rn,Ve,on,ie,xt,ln,ua,Vr="Download and extract given <code>url_or_urls</code>.",dn,ze,cn,ce,vt,pn,fa,zr="Extract given path(s).",mn,Se,gn,pe,wt,un,ha,Sr="Iterate over files within an archive.",fn,Ee,hn,me,yt,_n,_a,Er="Iterate over file paths.",bn,Ye,is,G,Mt,$n,ba,Yr=`Download manager that uses the ”::” separator to navigate through (possibly remote) compressed archives.
Contrary to the regular <code>DownloadManager</code>, the <code>download</code> and <code>extract</code> methods don’t actually download nor extract
data, but they rather return the path or url that could be opened using the <code>xopen</code> function which extends the
built-in <code>open</code> function to stream data from remote files.`,xn,ge,Tt,vn,$a,Qr=`Normalize URL(s) of files to stream data from.
This is the lazy version of <code>DownloadManager.download</code> for streaming.`,wn,Qe,yn,q,Jt,Mn,xa,Wr="Prepare given <code>url_or_urls</code> for streaming (add extraction protocol).",Tn,va,Lr="This is the lazy version of <code>DownloadManager.download_and_extract</code> for streaming.",Jn,We,jn,O,jt,kn,wa,Hr="Add extraction protocol for given url(s) for streaming.",Cn,ya,Ar="This is the lazy version of <code>DownloadManager.extract</code> for streaming.",Un,Le,Rn,ue,kt,Nn,Ma,Pr="Iterate over files within an archive.",Gn,He,Xn,fe,Ct,Zn,Ta,qr="Iterate over files.",In,Ae,cs,xe,Ut,Dn,Ja,Or="Configuration for our cached path manager.",ps,F,Rt,Bn,ja,Kr="<code>Enum</code> for how to treat pre-existing downloads and data.",Fn,ka,eo=`The default mode is <code>REUSE_DATASET_IF_EXISTS</code>, which will reuse both
raw downloads and the prepared dataset if they exist.`,Vn,Ca,to="The generations modes:",zn,Ua,ao="<thead><tr><th></th> <th>Downloads</th> <th>Dataset</th></tr></thead> <tbody><tr><td><code>REUSE_DATASET_IF_EXISTS</code> (default)</td> <td>Reuse</td> <td>Reuse</td></tr> <tr><td><code>REUSE_CACHE_IF_EXISTS</code></td> <td>Reuse</td> <td>Fresh</td></tr> <tr><td><code>FORCE_REDOWNLOAD</code></td> <td>Fresh</td> <td>Fresh</td></tr></tbody>",ms,Nt,gs,V,Gt,Sn,Ra,so="<code>Enum</code> that specifies which verification checks to run.",En,Na,no=`The default mode is <code>BASIC_CHECKS</code>, which will perform only rudimentary checks to avoid slowdowns
when generating/downloading a dataset for the first time.`,Yn,Ga,ro="The verification modes:",Qn,Xa,oo="<thead><tr><th></th> <th>Verification checks</th></tr></thead> <tbody><tr><td><code>ALL_CHECKS</code></td> <td>Split checks, uniqueness of the keys yielded in case of the GeneratorBuilder</td></tr> <tr><td></td> <td>and the validity (number of files, checksums, etc.) of downloaded files</td></tr> <tr><td><code>BASIC_CHECKS</code> (default)</td> <td>Same as <code>ALL_CHECKS</code> but without checking downloaded files</td></tr> <tr><td><code>NO_CHECKS</code></td> <td>None</td></tr></tbody>",us,Xt,fs,W,Zt,Wn,Za,lo="Defines the split information for the generator.",Ln,Ia,io=`This should be used as returned value of
<code>GeneratorBasedBuilder._split_generators</code>.
See <code>GeneratorBasedBuilder._split_generators</code> for more info and example
of usage.`,Hn,Pe,hs,X,It,An,Da,co="<code>Enum</code> for dataset splits.",Pn,Ba,po=`Datasets are typically split into different subsets to be used at various
stages of training and evaluation.`,qn,Fa,mo=`<li><code>TRAIN</code>: the training data.</li> <li><code>VALIDATION</code>: the validation data. If present, this is typically used as
evaluation data while iterating on a model (e.g. changing hyperparameters,
model architecture, etc.).</li> <li><code>TEST</code>: the testing data. This is the data to report metrics on. Typically
you do not want to use this during model iteration as you may overfit to it.</li> <li><code>ALL</code>: the union of all defined dataset splits.</li>`,On,Va,go="All splits, including compositions inherit from <code>datasets.SplitBase</code>.",Kn,za,uo='See the <a href="../load_hub#splits">guide</a> on splits for more information.',er,qe,_s,N,Dt,tr,Sa,fo="Descriptor corresponding to a named split (train, test, …).",ar,Ea,ho="Example:",sr,Oe,nr,Ya,_o=`The resulting split will correspond to 25% of the train split merged with
100% of the test split.`,rr,Ke,or,et,lr,tt,bs,ve,Bt,dr,Qa,bo="Split corresponding to the union of all defined dataset splits.",$s,z,Ft,ir,Wa,$o="Reading instruction for a dataset.",cr,at,pr,he,Vt,mr,La,xo="Creates a <code>ReadInstruction</code> instance out of a string spec.",gr,st,ur,_e,zt,fr,Ha,vo="Translate instruction into a list of absolute instructions.",hr,Aa,wo="Those absolute instructions are then to be added together.",xs,St,vs,ee,Et,_r,Pa,yo="Dataset version <code>MAJOR.MINOR.PATCH</code>.",br,nt,ws,Yt,ys,ts,Ms;return l=new es({props:{title:"Builder classes",local:"builder-classes",headingTag:"h1"}}),m=new es({props:{title:"Builders",local:"datasets.DatasetBuilder",headingTag:"h2"}}),lt=new J({props:{name:"class datasets.DatasetBuilder",anchor:"datasets.DatasetBuilder",parameters:[{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"dataset_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"hash",val:": typing.Optional[str] = None"},{name:"base_path",val:": typing.Optional[str] = None"},{name:"info",val:": typing.Optional[datasets.info.DatasetInfo] = None"},{name:"features",val:": typing.Optional[datasets.features.features.Features] = None"},{name:"token",val:": typing.Union[bool, str, NoneType] = None"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"data_files",val:": typing.Union[str, list, dict, datasets.data_files.DataFilesDict, NoneType] = None"},{name:"data_dir",val:": typing.Optional[str] = None"},{name:"storage_options",val:": typing.Optional[dict] = None"},{name:"writer_batch_size",val:": typing.Optional[int] = None"},{name:"**config_kwargs",val:""}],parametersDescription:[{anchor:"datasets.DatasetBuilder.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Directory to cache data. Defaults to <code>&quot;~/.cache/huggingface/datasets&quot;</code>.`,name:"cache_dir"},{anchor:"datasets.DatasetBuilder.dataset_name",description:`<strong>dataset_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the dataset, if different from the builder name. Useful for packaged builders
like csv, imagefolder, audiofolder, etc. to reflect the difference between datasets
that use the same packaged builder.`,name:"dataset_name"},{anchor:"datasets.DatasetBuilder.config_name",description:`<strong>config_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Name of the dataset configuration.
It affects the data generated on disk. Different configurations will have their own subdirectories and
versions.
If not provided, the default configuration is used (if it exists).</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.3.0</p>
						
<p>Parameter <code>name</code> was renamed to <code>config_name</code>.</p>

					</div>`,name:"config_name"},{anchor:"datasets.DatasetBuilder.hash",description:`<strong>hash</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Hash specific to the dataset code. Used to update the caching directory when the
dataset loading script code is updated (to avoid reusing old data).
The typical caching directory (defined in <code>self._relative_data_dir</code>) is <code>name/version/hash/</code>.`,name:"hash"},{anchor:"datasets.DatasetBuilder.base_path",description:`<strong>base_path</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Base path for relative paths that are used to download files.
This can be a remote URL.`,name:"base_path"},{anchor:"datasets.DatasetBuilder.features",description:`<strong>features</strong> (<a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Features">Features</a>, <em>optional</em>) &#x2014;
Features types to use with this dataset.
It can be used to change the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Features">Features</a> types of a dataset, for example.`,name:"features"},{anchor:"datasets.DatasetBuilder.token",description:`<strong>token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
String or boolean to use as Bearer token for remote files on the
Datasets Hub. If <code>True</code>, will get token from <code>&quot;~/.huggingface&quot;</code>.`,name:"token"},{anchor:"datasets.DatasetBuilder.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
ID of the dataset repository.
Used to distinguish builders with the same name but not coming from the same namespace, for example &#x201C;rajpurkar/squad&#x201D;
and &#x201C;lhoestq/squad&#x201D; repo IDs. In the latter, the builder name would be &#x201C;lhoestq___squad&#x201D;.`,name:"repo_id"},{anchor:"datasets.DatasetBuilder.data_files",description:`<strong>data_files</strong> (<code>str</code> or <code>Sequence</code> or <code>Mapping</code>, <em>optional</em>) &#x2014;
Path(s) to source data file(s).
For builders like &#x201C;csv&#x201D; or &#x201C;json&#x201D; that need the user to specify data files. They can be either
local or remote files. For convenience, you can use a <code>DataFilesDict</code>.`,name:"data_files"},{anchor:"datasets.DatasetBuilder.data_dir",description:`<strong>data_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Path to directory containing source data file(s).
Use only if <code>data_files</code> is not passed, in which case it is equivalent to passing
<code>os.path.join(data_dir, &quot;**&quot;)</code> as <code>data_files</code>.
For builders that require manual download, it must be the path to the local directory containing the
manually downloaded data.`,name:"data_dir"},{anchor:"datasets.DatasetBuilder.storage_options",description:`<strong>storage_options</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Key/value pairs to be passed on to the dataset file-system backend, if any.`,name:"storage_options"},{anchor:"datasets.DatasetBuilder.writer_batch_size",description:`<strong>writer_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Batch size used by the ArrowWriter.
It defines the number of samples that are kept in memory before writing them
and also the length of the arrow chunks.
None means that the ArrowWriter will use its default value.`,name:"writer_batch_size"},{anchor:"datasets.DatasetBuilder.*config_kwargs",description:`*<strong>*config_kwargs</strong> (additional keyword arguments) &#x2014; Keyword arguments to be passed to the corresponding builder
configuration class, set on the class attribute <a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.BuilderConfig">DatasetBuilder.BUILDER_CONFIG_CLASS</a>. The builder
configuration class is <a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.BuilderConfig">BuilderConfig</a> or a subclass of it.`,name:"*config_kwargs"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L210"}}),dt=new J({props:{name:"as_dataset",anchor:"datasets.DatasetBuilder.as_dataset",parameters:[{name:"split",val:": typing.Optional[datasets.splits.Split] = None"},{name:"run_post_process",val:" = True"},{name:"verification_mode",val:": typing.Union[datasets.utils.info_utils.VerificationMode, str, NoneType] = None"},{name:"in_memory",val:" = False"}],parametersDescription:[{anchor:"datasets.DatasetBuilder.as_dataset.split",description:`<strong>split</strong> (<code>datasets.Split</code>) &#x2014;
Which subset of the data to return.`,name:"split"},{anchor:"datasets.DatasetBuilder.as_dataset.run_post_process",description:`<strong>run_post_process</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether to run post-processing dataset transforms and/or add
indexes.`,name:"run_post_process"},{anchor:"datasets.DatasetBuilder.as_dataset.verification_mode",description:`<strong>verification_mode</strong> (<a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.VerificationMode">VerificationMode</a> or <code>str</code>, defaults to <code>BASIC_CHECKS</code>) &#x2014;
Verification mode determining the checks to run on the
downloaded/processed dataset information (checksums/size/splits/&#x2026;).</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.9.1</p>
						
					</div>`,name:"verification_mode"},{anchor:"datasets.DatasetBuilder.as_dataset.in_memory",description:`<strong>in_memory</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to copy the data in-memory.`,name:"in_memory"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L1067",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>datasets.Dataset</p>
`}}),Ge=new k({props:{anchor:"datasets.DatasetBuilder.as_dataset.example",$$slots:{default:[Uo]},$$scope:{ctx:y}}}),it=new J({props:{name:"download_and_prepare",anchor:"datasets.DatasetBuilder.download_and_prepare",parameters:[{name:"output_dir",val:": typing.Optional[str] = None"},{name:"download_config",val:": typing.Optional[datasets.download.download_config.DownloadConfig] = None"},{name:"download_mode",val:": typing.Union[datasets.download.download_manager.DownloadMode, str, NoneType] = None"},{name:"verification_mode",val:": typing.Union[datasets.utils.info_utils.VerificationMode, str, NoneType] = None"},{name:"dl_manager",val:": typing.Optional[datasets.download.download_manager.DownloadManager] = None"},{name:"base_path",val:": typing.Optional[str] = None"},{name:"file_format",val:": str = 'arrow'"},{name:"max_shard_size",val:": typing.Union[str, int, NoneType] = None"},{name:"num_proc",val:": typing.Optional[int] = None"},{name:"storage_options",val:": typing.Optional[dict] = None"},{name:"**download_and_prepare_kwargs",val:""}],parametersDescription:[{anchor:"datasets.DatasetBuilder.download_and_prepare.output_dir",description:`<strong>output_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Output directory for the dataset.
Default to this builder&#x2019;s <code>cache_dir</code>, which is inside <code>~/.cache/huggingface/datasets</code> by default.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.5.0</p>
						
					</div>`,name:"output_dir"},{anchor:"datasets.DatasetBuilder.download_and_prepare.download_config",description:`<strong>download_config</strong> (<code>DownloadConfig</code>, <em>optional</em>) &#x2014;
Specific download configuration parameters.`,name:"download_config"},{anchor:"datasets.DatasetBuilder.download_and_prepare.download_mode",description:`<strong>download_mode</strong> (<a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.DownloadMode">DownloadMode</a> or <code>str</code>, <em>optional</em>) &#x2014;
Select the download/generate mode, default to <code>REUSE_DATASET_IF_EXISTS</code>.`,name:"download_mode"},{anchor:"datasets.DatasetBuilder.download_and_prepare.verification_mode",description:`<strong>verification_mode</strong> (<a href="/docs/datasets/v3.6.0/en/package_reference/builder_classes#datasets.VerificationMode">VerificationMode</a> or <code>str</code>, defaults to <code>BASIC_CHECKS</code>) &#x2014;
Verification mode determining the checks to run on the downloaded/processed dataset information (checksums/size/splits/&#x2026;).</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.9.1</p>
						
					</div>`,name:"verification_mode"},{anchor:"datasets.DatasetBuilder.download_and_prepare.dl_manager",description:`<strong>dl_manager</strong> (<code>DownloadManager</code>, <em>optional</em>) &#x2014;
Specific <code>DownloadManger</code> to use.`,name:"dl_manager"},{anchor:"datasets.DatasetBuilder.download_and_prepare.base_path",description:`<strong>base_path</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Base path for relative paths that are used to download files. This can be a remote url.
If not specified, the value of the <code>base_path</code> attribute (<code>self.base_path</code>) will be used instead.`,name:"base_path"},{anchor:"datasets.DatasetBuilder.download_and_prepare.file_format",description:`<strong>file_format</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Format of the data files in which the dataset will be written.
Supported formats: &#x201C;arrow&#x201D;, &#x201C;parquet&#x201D;. Default to &#x201C;arrow&#x201D; format.
If the format is &#x201C;parquet&#x201D;, then image and audio data are embedded into the Parquet files instead of pointing to local files.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.5.0</p>
						
					</div>`,name:"file_format"},{anchor:"datasets.DatasetBuilder.download_and_prepare.max_shard_size",description:`<strong>max_shard_size</strong> (<code>Union[str, int]</code>, <em>optional</em>) &#x2014;
Maximum number of bytes written per shard, default is &#x201C;500MB&#x201D;.
The size is based on uncompressed data size, so in practice your shard files may be smaller than
<code>max_shard_size</code> thanks to Parquet compression for example.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.5.0</p>
						
					</div>`,name:"max_shard_size"},{anchor:"datasets.DatasetBuilder.download_and_prepare.num_proc",description:`<strong>num_proc</strong> (<code>int</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
Number of processes when downloading and generating the dataset locally.
Multiprocessing is disabled by default.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.7.0</p>
						
					</div>`,name:"num_proc"},{anchor:"datasets.DatasetBuilder.download_and_prepare.storage_options",description:`<strong>storage_options</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Key/value pairs to be passed on to the caching file-system backend, if any.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						<p class="font-medium">Added in 2.5.0</p>
						
					</div>`,name:"storage_options"},{anchor:"datasets.DatasetBuilder.download_and_prepare.*download_and_prepare_kwargs",description:"*<strong>*download_and_prepare_kwargs</strong> (additional keyword arguments) &#x2014; Keyword arguments.",name:"*download_and_prepare_kwargs"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L722"}}),Xe=new k({props:{anchor:"datasets.DatasetBuilder.download_and_prepare.example",$$slots:{default:[Ro]},$$scope:{ctx:y}}}),Ze=new k({props:{anchor:"datasets.DatasetBuilder.download_and_prepare.example-2",$$slots:{default:[No]},$$scope:{ctx:y}}}),Ie=new k({props:{anchor:"datasets.DatasetBuilder.download_and_prepare.example-3",$$slots:{default:[Go]},$$scope:{ctx:y}}}),ct=new J({props:{name:"get_all_exported_dataset_infos",anchor:"datasets.DatasetBuilder.get_all_exported_dataset_infos",parameters:[],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L506"}}),De=new k({props:{anchor:"datasets.DatasetBuilder.get_all_exported_dataset_infos.example",$$slots:{default:[Xo]},$$scope:{ctx:y}}}),pt=new J({props:{name:"get_exported_dataset_info",anchor:"datasets.DatasetBuilder.get_exported_dataset_info",parameters:[],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L521"}}),Be=new k({props:{anchor:"datasets.DatasetBuilder.get_exported_dataset_info.example",$$slots:{default:[Zo]},$$scope:{ctx:y}}}),mt=new J({props:{name:"get_imported_module_dir",anchor:"datasets.DatasetBuilder.get_imported_module_dir",parameters:[],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L714"}}),gt=new J({props:{name:"class datasets.GeneratorBasedBuilder",anchor:"datasets.GeneratorBasedBuilder",parameters:[{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"dataset_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"hash",val:": typing.Optional[str] = None"},{name:"base_path",val:": typing.Optional[str] = None"},{name:"info",val:": typing.Optional[datasets.info.DatasetInfo] = None"},{name:"features",val:": typing.Optional[datasets.features.features.Features] = None"},{name:"token",val:": typing.Union[bool, str, NoneType] = None"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"data_files",val:": typing.Union[str, list, dict, datasets.data_files.DataFilesDict, NoneType] = None"},{name:"data_dir",val:": typing.Optional[str] = None"},{name:"storage_options",val:": typing.Optional[dict] = None"},{name:"writer_batch_size",val:": typing.Optional[int] = None"},{name:"**config_kwargs",val:""}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L1396"}}),ut=new J({props:{name:"class datasets.ArrowBasedBuilder",anchor:"datasets.ArrowBasedBuilder",parameters:[{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"dataset_name",val:": typing.Optional[str] = None"},{name:"config_name",val:": typing.Optional[str] = None"},{name:"hash",val:": typing.Optional[str] = None"},{name:"base_path",val:": typing.Optional[str] = None"},{name:"info",val:": typing.Optional[datasets.info.DatasetInfo] = None"},{name:"features",val:": typing.Optional[datasets.features.features.Features] = None"},{name:"token",val:": typing.Union[bool, str, NoneType] = None"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"data_files",val:": typing.Union[str, list, dict, datasets.data_files.DataFilesDict, NoneType] = None"},{name:"data_dir",val:": typing.Optional[str] = None"},{name:"storage_options",val:": typing.Optional[dict] = None"},{name:"writer_batch_size",val:": typing.Optional[int] = None"},{name:"**config_kwargs",val:""}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L1661"}}),ft=new J({props:{name:"class datasets.BuilderConfig",anchor:"datasets.BuilderConfig",parameters:[{name:"name",val:": str = 'default'"},{name:"version",val:": typing.Union[str, datasets.utils.version.Version, NoneType] = 0.0.0"},{name:"data_dir",val:": typing.Optional[str] = None"},{name:"data_files",val:": typing.Union[datasets.data_files.DataFilesDict, datasets.data_files.DataFilesPatternsDict, NoneType] = None"},{name:"description",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"datasets.BuilderConfig.name",description:`<strong>name</strong> (<code>str</code>, defaults to <code>default</code>) &#x2014;
The name of the configuration.`,name:"name"},{anchor:"datasets.BuilderConfig.version",description:`<strong>version</strong> (<code>Version</code> or <code>str</code>, defaults to <code>0.0.0</code>) &#x2014;
The version of the configuration.`,name:"version"},{anchor:"datasets.BuilderConfig.data_dir",description:`<strong>data_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Path to the directory containing the source data.`,name:"data_dir"},{anchor:"datasets.BuilderConfig.data_files",description:`<strong>data_files</strong> (<code>str</code> or <code>Sequence</code> or <code>Mapping</code>, <em>optional</em>) &#x2014;
Path(s) to source data file(s).`,name:"data_files"},{anchor:"datasets.BuilderConfig.description",description:`<strong>description</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A human description of the configuration.`,name:"description"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L96"}}),ht=new J({props:{name:"create_config_id",anchor:"datasets.BuilderConfig.create_config_id",parameters:[{name:"config_kwargs",val:": dict"},{name:"custom_features",val:": typing.Optional[datasets.features.features.Features] = None"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/builder.py#L140"}}),_t=new es({props:{title:"Download",local:"datasets.DownloadManager",headingTag:"h2"}}),bt=new J({props:{name:"class datasets.DownloadManager",anchor:"datasets.DownloadManager",parameters:[{name:"dataset_name",val:": typing.Optional[str] = None"},{name:"data_dir",val:": typing.Optional[str] = None"},{name:"download_config",val:": typing.Optional[datasets.download.download_config.DownloadConfig] = None"},{name:"base_path",val:": typing.Optional[str] = None"},{name:"record_checksums",val:" = True"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L71"}}),$t=new J({props:{name:"download",anchor:"datasets.DownloadManager.download",parameters:[{name:"url_or_urls",val:""}],parametersDescription:[{anchor:"datasets.DownloadManager.download.url_or_urls",description:`<strong>url_or_urls</strong> (<code>str</code> or <code>list</code> or <code>dict</code>) &#x2014;
URL or <code>list</code> or <code>dict</code> of URLs to download. Each URL is a <code>str</code>.`,name:"url_or_urls"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L131",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The downloaded paths matching the given input <code>url_or_urls</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>str</code> or <code>list</code> or <code>dict</code></p>
`}}),Ve=new k({props:{anchor:"datasets.DownloadManager.download.example",$$slots:{default:[Io]},$$scope:{ctx:y}}}),xt=new J({props:{name:"download_and_extract",anchor:"datasets.DownloadManager.download_and_extract",parameters:[{name:"url_or_urls",val:""}],parametersDescription:[{anchor:"datasets.DownloadManager.download_and_extract.url_or_urls",description:`<strong>url_or_urls</strong> (<code>str</code> or <code>list</code> or <code>dict</code>) &#x2014;
URL or <code>list</code> or <code>dict</code> of URLs to download and extract. Each URL is a <code>str</code>.`,name:"url_or_urls"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L310",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>str</code>, extracted paths of given URL(s).</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>extracted_path(s)</p>
`}}),ze=new k({props:{anchor:"datasets.DownloadManager.download_and_extract.example",$$slots:{default:[Do]},$$scope:{ctx:y}}}),vt=new J({props:{name:"extract",anchor:"datasets.DownloadManager.extract",parameters:[{name:"path_or_paths",val:""}],parametersDescription:[{anchor:"datasets.DownloadManager.extract.path_or_paths",description:`<strong>path_or_paths</strong> (path or <code>list</code> or <code>dict</code>) &#x2014;
Path of file to extract. Each path is a <code>str</code>.`,name:"path_or_paths"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L278",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>str</code>, The extracted paths matching the given input
path_or_paths.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>extracted_path(s)</p>
`}}),Se=new k({props:{anchor:"datasets.DownloadManager.extract.example",$$slots:{default:[Bo]},$$scope:{ctx:y}}}),wt=new J({props:{name:"iter_archive",anchor:"datasets.DownloadManager.iter_archive",parameters:[{name:"path_or_buf",val:": typing.Union[str, _io.BufferedReader]"}],parametersDescription:[{anchor:"datasets.DownloadManager.iter_archive.path_or_buf",description:`<strong>path_or_buf</strong> (<code>str</code> or <code>io.BufferedReader</code>) &#x2014;
Archive path or archive binary file object.`,name:"path_or_buf"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L234",returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>tuple[str, io.BufferedReader]</code></p>
`,isYield:!0}}),Ee=new k({props:{anchor:"datasets.DownloadManager.iter_archive.example",$$slots:{default:[Fo]},$$scope:{ctx:y}}}),yt=new J({props:{name:"iter_files",anchor:"datasets.DownloadManager.iter_files",parameters:[{name:"paths",val:": typing.Union[str, list[str]]"}],parametersDescription:[{anchor:"datasets.DownloadManager.iter_files.paths",description:`<strong>paths</strong> (<code>str</code> or <code>list</code> of <code>str</code>) &#x2014;
Root paths.`,name:"paths"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L259",returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>str</code></p>
`,isYield:!0}}),Ye=new k({props:{anchor:"datasets.DownloadManager.iter_files.example",$$slots:{default:[Vo]},$$scope:{ctx:y}}}),Mt=new J({props:{name:"class datasets.StreamingDownloadManager",anchor:"datasets.StreamingDownloadManager",parameters:[{name:"dataset_name",val:": typing.Optional[str] = None"},{name:"data_dir",val:": typing.Optional[str] = None"},{name:"download_config",val:": typing.Optional[datasets.download.download_config.DownloadConfig] = None"},{name:"base_path",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/streaming_download_manager.py#L47"}}),Tt=new J({props:{name:"download",anchor:"datasets.StreamingDownloadManager.download",parameters:[{name:"url_or_urls",val:""}],parametersDescription:[{anchor:"datasets.StreamingDownloadManager.download.url_or_urls",description:`<strong>url_or_urls</strong> (<code>str</code> or <code>list</code> or <code>dict</code>) &#x2014;
URL(s) of files to stream data from. Each url is a <code>str</code>.`,name:"url_or_urls"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/streaming_download_manager.py#L75",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(<code>str</code> or <code>list</code> or <code>dict</code>), URL(s) to stream data from matching the given input url_or_urls.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>url(s)</p>
`}}),Qe=new k({props:{anchor:"datasets.StreamingDownloadManager.download.example",$$slots:{default:[zo]},$$scope:{ctx:y}}}),Jt=new J({props:{name:"download_and_extract",anchor:"datasets.StreamingDownloadManager.download_and_extract",parameters:[{name:"url_or_urls",val:""}],parametersDescription:[{anchor:"datasets.StreamingDownloadManager.download_and_extract.url_or_urls",description:`<strong>url_or_urls</strong> (<code>str</code> or <code>list</code> or <code>dict</code>) &#x2014;
URL(s) to stream from data from. Each url is a <code>str</code>.`,name:"url_or_urls"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/streaming_download_manager.py#L151",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(<code>str</code> or <code>list</code> or <code>dict</code>), URL(s) to stream data from matching the given input <code>url_or_urls</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>url(s)</p>
`}}),We=new k({props:{anchor:"datasets.StreamingDownloadManager.download_and_extract.example",$$slots:{default:[So]},$$scope:{ctx:y}}}),jt=new J({props:{name:"extract",anchor:"datasets.StreamingDownloadManager.extract",parameters:[{name:"url_or_urls",val:""}],parametersDescription:[{anchor:"datasets.StreamingDownloadManager.extract.url_or_urls",description:`<strong>url_or_urls</strong> (<code>str</code> or <code>list</code> or <code>dict</code>) &#x2014;
URL(s) of files to stream data from. Each url is a <code>str</code>.`,name:"url_or_urls"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/streaming_download_manager.py#L102",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(<code>str</code> or <code>list</code> or <code>dict</code>), URL(s) to stream data from matching the given input <code>url_or_urls</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>url(s)</p>
`}}),Le=new k({props:{anchor:"datasets.StreamingDownloadManager.extract.example",$$slots:{default:[Eo]},$$scope:{ctx:y}}}),kt=new J({props:{name:"iter_archive",anchor:"datasets.StreamingDownloadManager.iter_archive",parameters:[{name:"urlpath_or_buf",val:": typing.Union[str, _io.BufferedReader]"}],parametersDescription:[{anchor:"datasets.StreamingDownloadManager.iter_archive.urlpath_or_buf",description:`<strong>urlpath_or_buf</strong> (<code>str</code> or <code>io.BufferedReader</code>) &#x2014;
Archive path or archive binary file object.`,name:"urlpath_or_buf"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/streaming_download_manager.py#L171",returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>tuple[str, io.BufferedReader]</code></p>
`,isYield:!0}}),He=new k({props:{anchor:"datasets.StreamingDownloadManager.iter_archive.example",$$slots:{default:[Yo]},$$scope:{ctx:y}}}),Ct=new J({props:{name:"iter_files",anchor:"datasets.StreamingDownloadManager.iter_files",parameters:[{name:"urlpaths",val:": typing.Union[str, list[str]]"}],parametersDescription:[{anchor:"datasets.StreamingDownloadManager.iter_files.urlpaths",description:`<strong>urlpaths</strong> (<code>str</code> or <code>list</code> of <code>str</code>) &#x2014;
Root paths.`,name:"urlpaths"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/streaming_download_manager.py#L196",returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>str</p>
`,isYield:!0}}),Ae=new k({props:{anchor:"datasets.StreamingDownloadManager.iter_files.example",$$slots:{default:[Qo]},$$scope:{ctx:y}}}),Ut=new J({props:{name:"class datasets.DownloadConfig",anchor:"datasets.DownloadConfig",parameters:[{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"local_files_only",val:": bool = False"},{name:"proxies",val:": typing.Optional[dict] = None"},{name:"user_agent",val:": typing.Optional[str] = None"},{name:"extract_compressed_file",val:": bool = False"},{name:"force_extract",val:": bool = False"},{name:"delete_extracted",val:": bool = False"},{name:"extract_on_the_fly",val:": bool = False"},{name:"use_etag",val:": bool = True"},{name:"num_proc",val:": typing.Optional[int] = None"},{name:"max_retries",val:": int = 1"},{name:"token",val:": typing.Union[str, bool, NoneType] = None"},{name:"storage_options",val:": dict = <factory>"},{name:"download_desc",val:": typing.Optional[str] = None"},{name:"disable_tqdm",val:": bool = False"}],parametersDescription:[{anchor:"datasets.DownloadConfig.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>Path</code>, <em>optional</em>) &#x2014;
Specify a cache directory to save the file to (overwrite the
default cache dir).`,name:"cache_dir"},{anchor:"datasets.DownloadConfig.force_download",description:`<strong>force_download</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, re-download the file even if it&#x2019;s already cached in
the cache dir.`,name:"force_download"},{anchor:"datasets.DownloadConfig.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, resume the download if an incompletely received file is
found.`,name:"resume_download"},{anchor:"datasets.DownloadConfig.proxies",description:"<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;",name:"proxies"},{anchor:"datasets.DownloadConfig.user_agent",description:`<strong>user_agent</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Optional string or dict that will be appended to the user-agent on remote
requests.`,name:"user_agent"},{anchor:"datasets.DownloadConfig.extract_compressed_file",description:`<strong>extract_compressed_file</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
If <code>True</code> and the path point to a zip or tar file,
extract the compressed file in a folder along the archive.`,name:"extract_compressed_file"},{anchor:"datasets.DownloadConfig.force_extract",description:`<strong>force_extract</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
If <code>True</code> when <code>extract_compressed_file</code> is <code>True</code> and the archive
was already extracted, re-extract the archive and override the folder where it was extracted.`,name:"force_extract"},{anchor:"datasets.DownloadConfig.delete_extracted",description:`<strong>delete_extracted</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to delete (or keep) the extracted files.`,name:"delete_extracted"},{anchor:"datasets.DownloadConfig.extract_on_the_fly",description:`<strong>extract_on_the_fly</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, extract compressed files while they are being read.`,name:"extract_on_the_fly"},{anchor:"datasets.DownloadConfig.use_etag",description:`<strong>use_etag</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether to use the ETag HTTP response header to validate the cached files.`,name:"use_etag"},{anchor:"datasets.DownloadConfig.num_proc",description:`<strong>num_proc</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The number of processes to launch to download the files in parallel.`,name:"num_proc"},{anchor:"datasets.DownloadConfig.max_retries",description:`<strong>max_retries</strong> (<code>int</code>, default to <code>1</code>) &#x2014;
The number of times to retry an HTTP request if it fails.`,name:"max_retries"},{anchor:"datasets.DownloadConfig.token",description:`<strong>token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
Optional string or boolean to use as Bearer token
for remote files on the Datasets Hub. If <code>True</code>, or not specified, will get token from <code>~/.huggingface</code>.`,name:"token"},{anchor:"datasets.DownloadConfig.storage_options",description:`<strong>storage_options</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Key/value pairs to be passed on to the dataset file-system backend, if any.`,name:"storage_options"},{anchor:"datasets.DownloadConfig.download_desc",description:`<strong>download_desc</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A description to be displayed alongside with the progress bar while downloading the files.`,name:"download_desc"},{anchor:"datasets.DownloadConfig.disable_tqdm",description:`<strong>disable_tqdm</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to disable the individual files download progress bar`,name:"disable_tqdm"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_config.py#L9"}}),Rt=new J({props:{name:"class datasets.DownloadMode",anchor:"datasets.DownloadMode",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/download/download_manager.py#L50"}}),Nt=new es({props:{title:"Verification",local:"datasets.VerificationMode",headingTag:"h2"}}),Gt=new J({props:{name:"class datasets.VerificationMode",anchor:"datasets.VerificationMode",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/utils/info_utils.py#L22"}}),Xt=new es({props:{title:"Splits",local:"datasets.SplitGenerator",headingTag:"h2"}}),Zt=new J({props:{name:"class datasets.SplitGenerator",anchor:"datasets.SplitGenerator",parameters:[{name:"name",val:": str"},{name:"gen_kwargs",val:": dict = <factory>"}],parametersDescription:[{anchor:"datasets.SplitGenerator.name",description:`<strong>name</strong> (<code>str</code>) &#x2014;
Name of the <code>Split</code> for which the generator will
create the examples.`,name:"name"},{anchor:"datasets.SplitGenerator.*gen_kwargs",description:`*<strong>*gen_kwargs</strong> (additional keyword arguments) &#x2014;
Keyword arguments to forward to the <code>DatasetBuilder._generate_examples</code> method
of the builder.`,name:"*gen_kwargs"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/splits.py#L601"}}),Pe=new k({props:{anchor:"datasets.SplitGenerator.example",$$slots:{default:[Wo]},$$scope:{ctx:y}}}),It=new J({props:{name:"class datasets.Split",anchor:"datasets.Split",parameters:[{name:"name",val:""}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/splits.py#L406"}}),qe=new k({props:{anchor:"datasets.Split.example",$$slots:{default:[Lo]},$$scope:{ctx:y}}}),Dt=new J({props:{name:"class datasets.NamedSplit",anchor:"datasets.NamedSplit",parameters:[{name:"name",val:""}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/splits.py#L314"}}),Oe=new k({props:{anchor:"datasets.NamedSplit.example",$$slots:{default:[Ho]},$$scope:{ctx:y}}}),Ke=new k({props:{anchor:"datasets.NamedSplit.example-2",$$slots:{default:[Ao]},$$scope:{ctx:y}}}),et=new k({props:{anchor:"datasets.NamedSplit.example-3",$$slots:{default:[Po]},$$scope:{ctx:y}}}),tt=new k({props:{anchor:"datasets.NamedSplit.example-4",$$slots:{default:[qo]},$$scope:{ctx:y}}}),Bt=new J({props:{name:"class datasets.NamedSplitAll",anchor:"datasets.NamedSplitAll",parameters:[],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/splits.py#L391"}}),Ft=new J({props:{name:"class datasets.ReadInstruction",anchor:"datasets.ReadInstruction",parameters:[{name:"split_name",val:""},{name:"rounding",val:" = None"},{name:"from_",val:" = None"},{name:"to",val:" = None"},{name:"unit",val:" = None"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/arrow_reader.py#L456"}}),at=new k({props:{anchor:"datasets.ReadInstruction.example",$$slots:{default:[Oo]},$$scope:{ctx:y}}}),Vt=new J({props:{name:"from_spec",anchor:"datasets.ReadInstruction.from_spec",parameters:[{name:"spec",val:""}],parametersDescription:[{anchor:"datasets.ReadInstruction.from_spec.spec",description:`<strong>spec</strong> (<code>str</code>) &#x2014;
Split(s) + optional slice(s) to read + optional rounding
if percents are used as the slicing unit. A slice can be specified,
using absolute numbers (<code>int</code>) or percentages (<code>int</code>).`,name:"spec"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/arrow_reader.py#L536",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>ReadInstruction instance.</p>
`}}),st=new k({props:{anchor:"datasets.ReadInstruction.from_spec.example",$$slots:{default:[Ko]},$$scope:{ctx:y}}}),zt=new J({props:{name:"to_absolute",anchor:"datasets.ReadInstruction.to_absolute",parameters:[{name:"name2len",val:""}],parametersDescription:[{anchor:"datasets.ReadInstruction.to_absolute.name2len",description:`<strong>name2len</strong> (<code>dict</code>) &#x2014;
Associating split names to number of examples.`,name:"name2len"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/arrow_reader.py#L608",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>list of _AbsoluteInstruction instances (corresponds to the + in spec).</p>
`}}),St=new es({props:{title:"Version",local:"datasets.Version",headingTag:"h2"}}),Et=new J({props:{name:"class datasets.Version",anchor:"datasets.Version",parameters:[{name:"version_str",val:": str"},{name:"description",val:": typing.Optional[str] = None"},{name:"major",val:": typing.Union[str, int, NoneType] = None"},{name:"minor",val:": typing.Union[str, int, NoneType] = None"},{name:"patch",val:": typing.Union[str, int, NoneType] = None"}],parametersDescription:[{anchor:"datasets.Version.version_str",description:`<strong>version_str</strong> (<code>str</code>) &#x2014;
The dataset version.`,name:"version_str"},{anchor:"datasets.Version.description",description:`<strong>description</strong> (<code>str</code>) &#x2014;
A description of what is new in this version.`,name:"description"},{anchor:"datasets.Version.major",description:"<strong>major</strong> (<code>str</code>) &#x2014;",name:"major"},{anchor:"datasets.Version.minor",description:"<strong>minor</strong> (<code>str</code>) &#x2014;",name:"minor"},{anchor:"datasets.Version.patch",description:"<strong>patch</strong> (<code>str</code>) &#x2014;",name:"patch"}],source:"https://github.com/huggingface/datasets/blob/3.6.0/src/datasets/utils/version.py#L28"}}),nt=new k({props:{anchor:"datasets.Version.example",$$slots:{default:[el]},$$scope:{ctx:y}}}),Yt=new Co({props:{source:"https://github.com/huggingface/datasets/blob/main/docs/source/package_reference/builder_classes.mdx"}}),{c(){a=c("meta"),w=r(),d=c("p"),s=r(),f(l.$$.fragment),e=r(),f(m.$$.fragment),as=r(),ot=c("p"),ot.innerHTML=$r,ss=r(),j=c("div"),f(lt.$$.fragment),Js=r(),Ht=c("p"),Ht.textContent=xr,js=r(),At=c("p"),At.innerHTML=vr,ks=r(),Pt=c("ul"),Pt.innerHTML=wr,Cs=r(),qt=c("p"),qt.innerHTML=yr,Us=r(),oe=c("div"),f(dt.$$.fragment),Rs=r(),Ot=c("p"),Ot.textContent=Mr,Ns=r(),f(Ge.$$.fragment),Gs=r(),D=c("div"),f(it.$$.fragment),Xs=r(),Kt=c("p"),Kt.textContent=Tr,Zs=r(),ea=c("p"),ea.textContent=Jr,Is=r(),f(Xe.$$.fragment),Ds=r(),f(Ze.$$.fragment),Bs=r(),f(Ie.$$.fragment),Fs=r(),le=c("div"),f(ct.$$.fragment),Vs=r(),ta=c("p"),ta.textContent=jr,zs=r(),f(De.$$.fragment),Ss=r(),de=c("div"),f(pt.$$.fragment),Es=r(),aa=c("p"),aa.innerHTML=kr,Ys=r(),f(Be.$$.fragment),Qs=r(),Fe=c("div"),f(mt.$$.fragment),Ws=r(),sa=c("p"),sa.textContent=Cr,ns=r(),K=c("div"),f(gt.$$.fragment),Ls=r(),na=c("p"),na.textContent=Ur,Hs=r(),ra=c("p"),ra.innerHTML=Rr,rs=r(),$e=c("div"),f(ut.$$.fragment),As=r(),oa=c("p"),oa.textContent=Nr,os=r(),Q=c("div"),f(ft.$$.fragment),Ps=r(),la=c("p"),la.innerHTML=Gr,qs=r(),da=c("p"),da.innerHTML=Xr,Os=r(),A=c("div"),f(ht.$$.fragment),Ks=r(),ia=c("p"),ia.textContent=Zr,en=r(),ca=c("ul"),ca.innerHTML=Ir,tn=r(),pa=c("p"),pa.textContent=Dr,ls=r(),f(_t.$$.fragment),ds=r(),Z=c("div"),f(bt.$$.fragment),an=r(),P=c("div"),f($t.$$.fragment),sn=r(),ma=c("p"),ma.textContent=Br,nn=r(),ga=c("p"),ga.innerHTML=Fr,rn=r(),f(Ve.$$.fragment),on=r(),ie=c("div"),f(xt.$$.fragment),ln=r(),ua=c("p"),ua.innerHTML=Vr,dn=r(),f(ze.$$.fragment),cn=r(),ce=c("div"),f(vt.$$.fragment),pn=r(),fa=c("p"),fa.textContent=zr,mn=r(),f(Se.$$.fragment),gn=r(),pe=c("div"),f(wt.$$.fragment),un=r(),ha=c("p"),ha.textContent=Sr,fn=r(),f(Ee.$$.fragment),hn=r(),me=c("div"),f(yt.$$.fragment),_n=r(),_a=c("p"),_a.textContent=Er,bn=r(),f(Ye.$$.fragment),is=r(),G=c("div"),f(Mt.$$.fragment),$n=r(),ba=c("p"),ba.innerHTML=Yr,xn=r(),ge=c("div"),f(Tt.$$.fragment),vn=r(),$a=c("p"),$a.innerHTML=Qr,wn=r(),f(Qe.$$.fragment),yn=r(),q=c("div"),f(Jt.$$.fragment),Mn=r(),xa=c("p"),xa.innerHTML=Wr,Tn=r(),va=c("p"),va.innerHTML=Lr,Jn=r(),f(We.$$.fragment),jn=r(),O=c("div"),f(jt.$$.fragment),kn=r(),wa=c("p"),wa.textContent=Hr,Cn=r(),ya=c("p"),ya.innerHTML=Ar,Un=r(),f(Le.$$.fragment),Rn=r(),ue=c("div"),f(kt.$$.fragment),Nn=r(),Ma=c("p"),Ma.textContent=Pr,Gn=r(),f(He.$$.fragment),Xn=r(),fe=c("div"),f(Ct.$$.fragment),Zn=r(),Ta=c("p"),Ta.textContent=qr,In=r(),f(Ae.$$.fragment),cs=r(),xe=c("div"),f(Ut.$$.fragment),Dn=r(),Ja=c("p"),Ja.textContent=Or,ps=r(),F=c("div"),f(Rt.$$.fragment),Bn=r(),ja=c("p"),ja.innerHTML=Kr,Fn=r(),ka=c("p"),ka.innerHTML=eo,Vn=r(),Ca=c("p"),Ca.textContent=to,zn=r(),Ua=c("table"),Ua.innerHTML=ao,ms=r(),f(Nt.$$.fragment),gs=r(),V=c("div"),f(Gt.$$.fragment),Sn=r(),Ra=c("p"),Ra.innerHTML=so,En=r(),Na=c("p"),Na.innerHTML=no,Yn=r(),Ga=c("p"),Ga.textContent=ro,Qn=r(),Xa=c("table"),Xa.innerHTML=oo,us=r(),f(Xt.$$.fragment),fs=r(),W=c("div"),f(Zt.$$.fragment),Wn=r(),Za=c("p"),Za.textContent=lo,Ln=r(),Ia=c("p"),Ia.innerHTML=io,Hn=r(),f(Pe.$$.fragment),hs=r(),X=c("div"),f(It.$$.fragment),An=r(),Da=c("p"),Da.innerHTML=co,Pn=r(),Ba=c("p"),Ba.textContent=po,qn=r(),Fa=c("ul"),Fa.innerHTML=mo,On=r(),Va=c("p"),Va.innerHTML=go,Kn=r(),za=c("p"),za.innerHTML=uo,er=r(),f(qe.$$.fragment),_s=r(),N=c("div"),f(Dt.$$.fragment),tr=r(),Sa=c("p"),Sa.textContent=fo,ar=r(),Ea=c("p"),Ea.textContent=ho,sr=r(),f(Oe.$$.fragment),nr=r(),Ya=c("p"),Ya.textContent=_o,rr=r(),f(Ke.$$.fragment),or=r(),f(et.$$.fragment),lr=r(),f(tt.$$.fragment),bs=r(),ve=c("div"),f(Bt.$$.fragment),dr=r(),Qa=c("p"),Qa.textContent=bo,$s=r(),z=c("div"),f(Ft.$$.fragment),ir=r(),Wa=c("p"),Wa.textContent=$o,cr=r(),f(at.$$.fragment),pr=r(),he=c("div"),f(Vt.$$.fragment),mr=r(),La=c("p"),La.innerHTML=xo,gr=r(),f(st.$$.fragment),ur=r(),_e=c("div"),f(zt.$$.fragment),fr=r(),Ha=c("p"),Ha.textContent=vo,hr=r(),Aa=c("p"),Aa.textContent=wo,xs=r(),f(St.$$.fragment),vs=r(),ee=c("div"),f(Et.$$.fragment),_r=r(),Pa=c("p"),Pa.innerHTML=yo,br=r(),f(nt.$$.fragment),ws=r(),f(Yt.$$.fragment),ys=r(),ts=c("p"),this.h()},l(t){const g=ko("svelte-u9bgzb",document.head);a=p(g,"META",{name:!0,content:!0}),g.forEach(i),w=o(t),d=p(t,"P",{}),M(d).forEach(i),s=o(t),h(l.$$.fragment,t),e=o(t),h(m.$$.fragment,t),as=o(t),ot=p(t,"P",{"data-svelte-h":!0}),v(ot)!=="svelte-vybzsk"&&(ot.innerHTML=$r),ss=o(t),j=p(t,"DIV",{class:!0});var R=M(j);h(lt.$$.fragment,R),Js=o(R),Ht=p(R,"P",{"data-svelte-h":!0}),v(Ht)!=="svelte-krqj9a"&&(Ht.textContent=xr),js=o(R),At=p(R,"P",{"data-svelte-h":!0}),v(At)!=="svelte-apl31e"&&(At.innerHTML=vr),ks=o(R),Pt=p(R,"UL",{"data-svelte-h":!0}),v(Pt)!=="svelte-2skyxh"&&(Pt.innerHTML=wr),Cs=o(R),qt=p(R,"P",{"data-svelte-h":!0}),v(qt)!=="svelte-1o5om4x"&&(qt.innerHTML=yr),Us=o(R),oe=p(R,"DIV",{class:!0});var we=M(oe);h(dt.$$.fragment,we),Rs=o(we),Ot=p(we,"P",{"data-svelte-h":!0}),v(Ot)!=="svelte-1q1652n"&&(Ot.textContent=Mr),Ns=o(we),h(Ge.$$.fragment,we),we.forEach(i),Gs=o(R),D=p(R,"DIV",{class:!0});var S=M(D);h(it.$$.fragment,S),Xs=o(S),Kt=p(S,"P",{"data-svelte-h":!0}),v(Kt)!=="svelte-9mag6f"&&(Kt.textContent=Tr),Zs=o(S),ea=p(S,"P",{"data-svelte-h":!0}),v(ea)!=="svelte-11lpom8"&&(ea.textContent=Jr),Is=o(S),h(Xe.$$.fragment,S),Ds=o(S),h(Ze.$$.fragment,S),Bs=o(S),h(Ie.$$.fragment,S),S.forEach(i),Fs=o(R),le=p(R,"DIV",{class:!0});var ye=M(le);h(ct.$$.fragment,ye),Vs=o(ye),ta=p(ye,"P",{"data-svelte-h":!0}),v(ta)!=="svelte-1o5q38l"&&(ta.textContent=jr),zs=o(ye),h(De.$$.fragment,ye),ye.forEach(i),Ss=o(R),de=p(R,"DIV",{class:!0});var Me=M(de);h(pt.$$.fragment,Me),Es=o(Me),aa=p(Me,"P",{"data-svelte-h":!0}),v(aa)!=="svelte-168h2s0"&&(aa.innerHTML=kr),Ys=o(Me),h(Be.$$.fragment,Me),Me.forEach(i),Qs=o(R),Fe=p(R,"DIV",{class:!0});var Qt=M(Fe);h(mt.$$.fragment,Qt),Ws=o(Qt),sa=p(Qt,"P",{"data-svelte-h":!0}),v(sa)!=="svelte-1jq5ljq"&&(sa.textContent=Cr),Qt.forEach(i),R.forEach(i),ns=o(t),K=p(t,"DIV",{class:!0});var Te=M(K);h(gt.$$.fragment,Te),Ls=o(Te),na=p(Te,"P",{"data-svelte-h":!0}),v(na)!=="svelte-5e48ll"&&(na.textContent=Ur),Hs=o(Te),ra=p(Te,"P",{"data-svelte-h":!0}),v(ra)!=="svelte-1b18j1y"&&(ra.innerHTML=Rr),Te.forEach(i),rs=o(t),$e=p(t,"DIV",{class:!0});var Wt=M($e);h(ut.$$.fragment,Wt),As=o(Wt),oa=p(Wt,"P",{"data-svelte-h":!0}),v(oa)!=="svelte-17aolem"&&(oa.textContent=Nr),Wt.forEach(i),os=o(t),Q=p(t,"DIV",{class:!0});var te=M(Q);h(ft.$$.fragment,te),Ps=o(te),la=p(te,"P",{"data-svelte-h":!0}),v(la)!=="svelte-15gz2dy"&&(la.innerHTML=Gr),qs=o(te),da=p(te,"P",{"data-svelte-h":!0}),v(da)!=="svelte-1m2o9um"&&(da.innerHTML=Xr),Os=o(te),A=p(te,"DIV",{class:!0});var ae=M(A);h(ht.$$.fragment,ae),Ks=o(ae),ia=p(ae,"P",{"data-svelte-h":!0}),v(ia)!=="svelte-1h03lp6"&&(ia.textContent=Zr),en=o(ae),ca=p(ae,"UL",{"data-svelte-h":!0}),v(ca)!=="svelte-y69nf2"&&(ca.innerHTML=Ir),tn=o(ae),pa=p(ae,"P",{"data-svelte-h":!0}),v(pa)!=="svelte-d2y9u1"&&(pa.textContent=Dr),ae.forEach(i),te.forEach(i),ls=o(t),h(_t.$$.fragment,t),ds=o(t),Z=p(t,"DIV",{class:!0});var E=M(Z);h(bt.$$.fragment,E),an=o(E),P=p(E,"DIV",{class:!0});var se=M(P);h($t.$$.fragment,se),sn=o(se),ma=p(se,"P",{"data-svelte-h":!0}),v(ma)!=="svelte-19i8z0e"&&(ma.textContent=Br),nn=o(se),ga=p(se,"P",{"data-svelte-h":!0}),v(ga)!=="svelte-a30fyv"&&(ga.innerHTML=Fr),rn=o(se),h(Ve.$$.fragment,se),se.forEach(i),on=o(E),ie=p(E,"DIV",{class:!0});var Je=M(ie);h(xt.$$.fragment,Je),ln=o(Je),ua=p(Je,"P",{"data-svelte-h":!0}),v(ua)!=="svelte-xkawo0"&&(ua.innerHTML=Vr),dn=o(Je),h(ze.$$.fragment,Je),Je.forEach(i),cn=o(E),ce=p(E,"DIV",{class:!0});var je=M(ce);h(vt.$$.fragment,je),pn=o(je),fa=p(je,"P",{"data-svelte-h":!0}),v(fa)!=="svelte-1vlembv"&&(fa.textContent=zr),mn=o(je),h(Se.$$.fragment,je),je.forEach(i),gn=o(E),pe=p(E,"DIV",{class:!0});var ke=M(pe);h(wt.$$.fragment,ke),un=o(ke),ha=p(ke,"P",{"data-svelte-h":!0}),v(ha)!=="svelte-1ephcm7"&&(ha.textContent=Sr),fn=o(ke),h(Ee.$$.fragment,ke),ke.forEach(i),hn=o(E),me=p(E,"DIV",{class:!0});var Ce=M(me);h(yt.$$.fragment,Ce),_n=o(Ce),_a=p(Ce,"P",{"data-svelte-h":!0}),v(_a)!=="svelte-1sadrg0"&&(_a.textContent=Er),bn=o(Ce),h(Ye.$$.fragment,Ce),Ce.forEach(i),E.forEach(i),is=o(t),G=p(t,"DIV",{class:!0});var I=M(G);h(Mt.$$.fragment,I),$n=o(I),ba=p(I,"P",{"data-svelte-h":!0}),v(ba)!=="svelte-2x5qds"&&(ba.innerHTML=Yr),xn=o(I),ge=p(I,"DIV",{class:!0});var Ue=M(ge);h(Tt.$$.fragment,Ue),vn=o(Ue),$a=p(Ue,"P",{"data-svelte-h":!0}),v($a)!=="svelte-z89fig"&&($a.innerHTML=Qr),wn=o(Ue),h(Qe.$$.fragment,Ue),Ue.forEach(i),yn=o(I),q=p(I,"DIV",{class:!0});var ne=M(q);h(Jt.$$.fragment,ne),Mn=o(ne),xa=p(ne,"P",{"data-svelte-h":!0}),v(xa)!=="svelte-vb22br"&&(xa.innerHTML=Wr),Tn=o(ne),va=p(ne,"P",{"data-svelte-h":!0}),v(va)!=="svelte-1hkl2pt"&&(va.innerHTML=Lr),Jn=o(ne),h(We.$$.fragment,ne),ne.forEach(i),jn=o(I),O=p(I,"DIV",{class:!0});var re=M(O);h(jt.$$.fragment,re),kn=o(re),wa=p(re,"P",{"data-svelte-h":!0}),v(wa)!=="svelte-sgtbuc"&&(wa.textContent=Hr),Cn=o(re),ya=p(re,"P",{"data-svelte-h":!0}),v(ya)!=="svelte-5qr3om"&&(ya.innerHTML=Ar),Un=o(re),h(Le.$$.fragment,re),re.forEach(i),Rn=o(I),ue=p(I,"DIV",{class:!0});var Re=M(ue);h(kt.$$.fragment,Re),Nn=o(Re),Ma=p(Re,"P",{"data-svelte-h":!0}),v(Ma)!=="svelte-1ephcm7"&&(Ma.textContent=Pr),Gn=o(Re),h(He.$$.fragment,Re),Re.forEach(i),Xn=o(I),fe=p(I,"DIV",{class:!0});var Ne=M(fe);h(Ct.$$.fragment,Ne),Zn=o(Ne),Ta=p(Ne,"P",{"data-svelte-h":!0}),v(Ta)!=="svelte-1kdi5en"&&(Ta.textContent=qr),In=o(Ne),h(Ae.$$.fragment,Ne),Ne.forEach(i),I.forEach(i),cs=o(t),xe=p(t,"DIV",{class:!0});var Lt=M(xe);h(Ut.$$.fragment,Lt),Dn=o(Lt),Ja=p(Lt,"P",{"data-svelte-h":!0}),v(Ja)!=="svelte-1equdtb"&&(Ja.textContent=Or),Lt.forEach(i),ps=o(t),F=p(t,"DIV",{class:!0});var L=M(F);h(Rt.$$.fragment,L),Bn=o(L),ja=p(L,"P",{"data-svelte-h":!0}),v(ja)!=="svelte-nmj2uv"&&(ja.innerHTML=Kr),Fn=o(L),ka=p(L,"P",{"data-svelte-h":!0}),v(ka)!=="svelte-xtdw9q"&&(ka.innerHTML=eo),Vn=o(L),Ca=p(L,"P",{"data-svelte-h":!0}),v(Ca)!=="svelte-a4zsdi"&&(Ca.textContent=to),zn=o(L),Ua=p(L,"TABLE",{"data-svelte-h":!0}),v(Ua)!=="svelte-pv0x4r"&&(Ua.innerHTML=ao),L.forEach(i),ms=o(t),h(Nt.$$.fragment,t),gs=o(t),V=p(t,"DIV",{class:!0});var H=M(V);h(Gt.$$.fragment,H),Sn=o(H),Ra=p(H,"P",{"data-svelte-h":!0}),v(Ra)!=="svelte-1eqexd"&&(Ra.innerHTML=so),En=o(H),Na=p(H,"P",{"data-svelte-h":!0}),v(Na)!=="svelte-13iynk4"&&(Na.innerHTML=no),Yn=o(H),Ga=p(H,"P",{"data-svelte-h":!0}),v(Ga)!=="svelte-1luabaw"&&(Ga.textContent=ro),Qn=o(H),Xa=p(H,"TABLE",{"data-svelte-h":!0}),v(Xa)!=="svelte-6p84mg"&&(Xa.innerHTML=oo),H.forEach(i),us=o(t),h(Xt.$$.fragment,t),fs=o(t),W=p(t,"DIV",{class:!0});var rt=M(W);h(Zt.$$.fragment,rt),Wn=o(rt),Za=p(rt,"P",{"data-svelte-h":!0}),v(Za)!=="svelte-18qkgha"&&(Za.textContent=lo),Ln=o(rt),Ia=p(rt,"P",{"data-svelte-h":!0}),v(Ia)!=="svelte-fn7w0y"&&(Ia.innerHTML=io),Hn=o(rt),h(Pe.$$.fragment,rt),rt.forEach(i),hs=o(t),X=p(t,"DIV",{class:!0});var Y=M(X);h(It.$$.fragment,Y),An=o(Y),Da=p(Y,"P",{"data-svelte-h":!0}),v(Da)!=="svelte-ewaslg"&&(Da.innerHTML=co),Pn=o(Y),Ba=p(Y,"P",{"data-svelte-h":!0}),v(Ba)!=="svelte-l59ai2"&&(Ba.textContent=po),qn=o(Y),Fa=p(Y,"UL",{"data-svelte-h":!0}),v(Fa)!=="svelte-sbyekb"&&(Fa.innerHTML=mo),On=o(Y),Va=p(Y,"P",{"data-svelte-h":!0}),v(Va)!=="svelte-20xdby"&&(Va.innerHTML=go),Kn=o(Y),za=p(Y,"P",{"data-svelte-h":!0}),v(za)!=="svelte-1cn2wk0"&&(za.innerHTML=uo),er=o(Y),h(qe.$$.fragment,Y),Y.forEach(i),_s=o(t),N=p(t,"DIV",{class:!0});var B=M(N);h(Dt.$$.fragment,B),tr=o(B),Sa=p(B,"P",{"data-svelte-h":!0}),v(Sa)!=="svelte-124iux6"&&(Sa.textContent=fo),ar=o(B),Ea=p(B,"P",{"data-svelte-h":!0}),v(Ea)!=="svelte-11lpom8"&&(Ea.textContent=ho),sr=o(B),h(Oe.$$.fragment,B),nr=o(B),Ya=p(B,"P",{"data-svelte-h":!0}),v(Ya)!=="svelte-5jjbkq"&&(Ya.textContent=_o),rr=o(B),h(Ke.$$.fragment,B),or=o(B),h(et.$$.fragment,B),lr=o(B),h(tt.$$.fragment,B),B.forEach(i),bs=o(t),ve=p(t,"DIV",{class:!0});var Ts=M(ve);h(Bt.$$.fragment,Ts),dr=o(Ts),Qa=p(Ts,"P",{"data-svelte-h":!0}),v(Qa)!=="svelte-11ie63y"&&(Qa.textContent=bo),Ts.forEach(i),$s=o(t),z=p(t,"DIV",{class:!0});var be=M(z);h(Ft.$$.fragment,be),ir=o(be),Wa=p(be,"P",{"data-svelte-h":!0}),v(Wa)!=="svelte-3dhs2m"&&(Wa.textContent=$o),cr=o(be),h(at.$$.fragment,be),pr=o(be),he=p(be,"DIV",{class:!0});var qa=M(he);h(Vt.$$.fragment,qa),mr=o(qa),La=p(qa,"P",{"data-svelte-h":!0}),v(La)!=="svelte-1g1y80g"&&(La.innerHTML=xo),gr=o(qa),h(st.$$.fragment,qa),qa.forEach(i),ur=o(be),_e=p(be,"DIV",{class:!0});var Oa=M(_e);h(zt.$$.fragment,Oa),fr=o(Oa),Ha=p(Oa,"P",{"data-svelte-h":!0}),v(Ha)!=="svelte-14tg07e"&&(Ha.textContent=vo),hr=o(Oa),Aa=p(Oa,"P",{"data-svelte-h":!0}),v(Aa)!=="svelte-l773xk"&&(Aa.textContent=wo),Oa.forEach(i),be.forEach(i),xs=o(t),h(St.$$.fragment,t),vs=o(t),ee=p(t,"DIV",{class:!0});var Ka=M(ee);h(Et.$$.fragment,Ka),_r=o(Ka),Pa=p(Ka,"P",{"data-svelte-h":!0}),v(Pa)!=="svelte-14lq7j5"&&(Pa.innerHTML=yo),br=o(Ka),h(nt.$$.fragment,Ka),Ka.forEach(i),ws=o(t),h(Yt.$$.fragment,t),ys=o(t),ts=p(t,"P",{}),M(ts).forEach(i),this.h()},h(){T(a,"name","hf:doc:metadata"),T(a,"content",al),T(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(de,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(he,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),T(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,g){n(document.head,a),u(t,w,g),u(t,d,g),u(t,s,g),_(l,t,g),u(t,e,g),_(m,t,g),u(t,as,g),u(t,ot,g),u(t,ss,g),u(t,j,g),_(lt,j,null),n(j,Js),n(j,Ht),n(j,js),n(j,At),n(j,ks),n(j,Pt),n(j,Cs),n(j,qt),n(j,Us),n(j,oe),_(dt,oe,null),n(oe,Rs),n(oe,Ot),n(oe,Ns),_(Ge,oe,null),n(j,Gs),n(j,D),_(it,D,null),n(D,Xs),n(D,Kt),n(D,Zs),n(D,ea),n(D,Is),_(Xe,D,null),n(D,Ds),_(Ze,D,null),n(D,Bs),_(Ie,D,null),n(j,Fs),n(j,le),_(ct,le,null),n(le,Vs),n(le,ta),n(le,zs),_(De,le,null),n(j,Ss),n(j,de),_(pt,de,null),n(de,Es),n(de,aa),n(de,Ys),_(Be,de,null),n(j,Qs),n(j,Fe),_(mt,Fe,null),n(Fe,Ws),n(Fe,sa),u(t,ns,g),u(t,K,g),_(gt,K,null),n(K,Ls),n(K,na),n(K,Hs),n(K,ra),u(t,rs,g),u(t,$e,g),_(ut,$e,null),n($e,As),n($e,oa),u(t,os,g),u(t,Q,g),_(ft,Q,null),n(Q,Ps),n(Q,la),n(Q,qs),n(Q,da),n(Q,Os),n(Q,A),_(ht,A,null),n(A,Ks),n(A,ia),n(A,en),n(A,ca),n(A,tn),n(A,pa),u(t,ls,g),_(_t,t,g),u(t,ds,g),u(t,Z,g),_(bt,Z,null),n(Z,an),n(Z,P),_($t,P,null),n(P,sn),n(P,ma),n(P,nn),n(P,ga),n(P,rn),_(Ve,P,null),n(Z,on),n(Z,ie),_(xt,ie,null),n(ie,ln),n(ie,ua),n(ie,dn),_(ze,ie,null),n(Z,cn),n(Z,ce),_(vt,ce,null),n(ce,pn),n(ce,fa),n(ce,mn),_(Se,ce,null),n(Z,gn),n(Z,pe),_(wt,pe,null),n(pe,un),n(pe,ha),n(pe,fn),_(Ee,pe,null),n(Z,hn),n(Z,me),_(yt,me,null),n(me,_n),n(me,_a),n(me,bn),_(Ye,me,null),u(t,is,g),u(t,G,g),_(Mt,G,null),n(G,$n),n(G,ba),n(G,xn),n(G,ge),_(Tt,ge,null),n(ge,vn),n(ge,$a),n(ge,wn),_(Qe,ge,null),n(G,yn),n(G,q),_(Jt,q,null),n(q,Mn),n(q,xa),n(q,Tn),n(q,va),n(q,Jn),_(We,q,null),n(G,jn),n(G,O),_(jt,O,null),n(O,kn),n(O,wa),n(O,Cn),n(O,ya),n(O,Un),_(Le,O,null),n(G,Rn),n(G,ue),_(kt,ue,null),n(ue,Nn),n(ue,Ma),n(ue,Gn),_(He,ue,null),n(G,Xn),n(G,fe),_(Ct,fe,null),n(fe,Zn),n(fe,Ta),n(fe,In),_(Ae,fe,null),u(t,cs,g),u(t,xe,g),_(Ut,xe,null),n(xe,Dn),n(xe,Ja),u(t,ps,g),u(t,F,g),_(Rt,F,null),n(F,Bn),n(F,ja),n(F,Fn),n(F,ka),n(F,Vn),n(F,Ca),n(F,zn),n(F,Ua),u(t,ms,g),_(Nt,t,g),u(t,gs,g),u(t,V,g),_(Gt,V,null),n(V,Sn),n(V,Ra),n(V,En),n(V,Na),n(V,Yn),n(V,Ga),n(V,Qn),n(V,Xa),u(t,us,g),_(Xt,t,g),u(t,fs,g),u(t,W,g),_(Zt,W,null),n(W,Wn),n(W,Za),n(W,Ln),n(W,Ia),n(W,Hn),_(Pe,W,null),u(t,hs,g),u(t,X,g),_(It,X,null),n(X,An),n(X,Da),n(X,Pn),n(X,Ba),n(X,qn),n(X,Fa),n(X,On),n(X,Va),n(X,Kn),n(X,za),n(X,er),_(qe,X,null),u(t,_s,g),u(t,N,g),_(Dt,N,null),n(N,tr),n(N,Sa),n(N,ar),n(N,Ea),n(N,sr),_(Oe,N,null),n(N,nr),n(N,Ya),n(N,rr),_(Ke,N,null),n(N,or),_(et,N,null),n(N,lr),_(tt,N,null),u(t,bs,g),u(t,ve,g),_(Bt,ve,null),n(ve,dr),n(ve,Qa),u(t,$s,g),u(t,z,g),_(Ft,z,null),n(z,ir),n(z,Wa),n(z,cr),_(at,z,null),n(z,pr),n(z,he),_(Vt,he,null),n(he,mr),n(he,La),n(he,gr),_(st,he,null),n(z,ur),n(z,_e),_(zt,_e,null),n(_e,fr),n(_e,Ha),n(_e,hr),n(_e,Aa),u(t,xs,g),_(St,t,g),u(t,vs,g),u(t,ee,g),_(Et,ee,null),n(ee,_r),n(ee,Pa),n(ee,br),_(nt,ee,null),u(t,ws,g),_(Yt,t,g),u(t,ys,g),u(t,ts,g),Ms=!0},p(t,[g]){const R={};g&2&&(R.$$scope={dirty:g,ctx:t}),Ge.$set(R);const we={};g&2&&(we.$$scope={dirty:g,ctx:t}),Xe.$set(we);const S={};g&2&&(S.$$scope={dirty:g,ctx:t}),Ze.$set(S);const ye={};g&2&&(ye.$$scope={dirty:g,ctx:t}),Ie.$set(ye);const Me={};g&2&&(Me.$$scope={dirty:g,ctx:t}),De.$set(Me);const Qt={};g&2&&(Qt.$$scope={dirty:g,ctx:t}),Be.$set(Qt);const Te={};g&2&&(Te.$$scope={dirty:g,ctx:t}),Ve.$set(Te);const Wt={};g&2&&(Wt.$$scope={dirty:g,ctx:t}),ze.$set(Wt);const te={};g&2&&(te.$$scope={dirty:g,ctx:t}),Se.$set(te);const ae={};g&2&&(ae.$$scope={dirty:g,ctx:t}),Ee.$set(ae);const E={};g&2&&(E.$$scope={dirty:g,ctx:t}),Ye.$set(E);const se={};g&2&&(se.$$scope={dirty:g,ctx:t}),Qe.$set(se);const Je={};g&2&&(Je.$$scope={dirty:g,ctx:t}),We.$set(Je);const je={};g&2&&(je.$$scope={dirty:g,ctx:t}),Le.$set(je);const ke={};g&2&&(ke.$$scope={dirty:g,ctx:t}),He.$set(ke);const Ce={};g&2&&(Ce.$$scope={dirty:g,ctx:t}),Ae.$set(Ce);const I={};g&2&&(I.$$scope={dirty:g,ctx:t}),Pe.$set(I);const Ue={};g&2&&(Ue.$$scope={dirty:g,ctx:t}),qe.$set(Ue);const ne={};g&2&&(ne.$$scope={dirty:g,ctx:t}),Oe.$set(ne);const re={};g&2&&(re.$$scope={dirty:g,ctx:t}),Ke.$set(re);const Re={};g&2&&(Re.$$scope={dirty:g,ctx:t}),et.$set(Re);const Ne={};g&2&&(Ne.$$scope={dirty:g,ctx:t}),tt.$set(Ne);const Lt={};g&2&&(Lt.$$scope={dirty:g,ctx:t}),at.$set(Lt);const L={};g&2&&(L.$$scope={dirty:g,ctx:t}),st.$set(L);const H={};g&2&&(H.$$scope={dirty:g,ctx:t}),nt.$set(H)},i(t){Ms||(b(l.$$.fragment,t),b(m.$$.fragment,t),b(lt.$$.fragment,t),b(dt.$$.fragment,t),b(Ge.$$.fragment,t),b(it.$$.fragment,t),b(Xe.$$.fragment,t),b(Ze.$$.fragment,t),b(Ie.$$.fragment,t),b(ct.$$.fragment,t),b(De.$$.fragment,t),b(pt.$$.fragment,t),b(Be.$$.fragment,t),b(mt.$$.fragment,t),b(gt.$$.fragment,t),b(ut.$$.fragment,t),b(ft.$$.fragment,t),b(ht.$$.fragment,t),b(_t.$$.fragment,t),b(bt.$$.fragment,t),b($t.$$.fragment,t),b(Ve.$$.fragment,t),b(xt.$$.fragment,t),b(ze.$$.fragment,t),b(vt.$$.fragment,t),b(Se.$$.fragment,t),b(wt.$$.fragment,t),b(Ee.$$.fragment,t),b(yt.$$.fragment,t),b(Ye.$$.fragment,t),b(Mt.$$.fragment,t),b(Tt.$$.fragment,t),b(Qe.$$.fragment,t),b(Jt.$$.fragment,t),b(We.$$.fragment,t),b(jt.$$.fragment,t),b(Le.$$.fragment,t),b(kt.$$.fragment,t),b(He.$$.fragment,t),b(Ct.$$.fragment,t),b(Ae.$$.fragment,t),b(Ut.$$.fragment,t),b(Rt.$$.fragment,t),b(Nt.$$.fragment,t),b(Gt.$$.fragment,t),b(Xt.$$.fragment,t),b(Zt.$$.fragment,t),b(Pe.$$.fragment,t),b(It.$$.fragment,t),b(qe.$$.fragment,t),b(Dt.$$.fragment,t),b(Oe.$$.fragment,t),b(Ke.$$.fragment,t),b(et.$$.fragment,t),b(tt.$$.fragment,t),b(Bt.$$.fragment,t),b(Ft.$$.fragment,t),b(at.$$.fragment,t),b(Vt.$$.fragment,t),b(st.$$.fragment,t),b(zt.$$.fragment,t),b(St.$$.fragment,t),b(Et.$$.fragment,t),b(nt.$$.fragment,t),b(Yt.$$.fragment,t),Ms=!0)},o(t){$(l.$$.fragment,t),$(m.$$.fragment,t),$(lt.$$.fragment,t),$(dt.$$.fragment,t),$(Ge.$$.fragment,t),$(it.$$.fragment,t),$(Xe.$$.fragment,t),$(Ze.$$.fragment,t),$(Ie.$$.fragment,t),$(ct.$$.fragment,t),$(De.$$.fragment,t),$(pt.$$.fragment,t),$(Be.$$.fragment,t),$(mt.$$.fragment,t),$(gt.$$.fragment,t),$(ut.$$.fragment,t),$(ft.$$.fragment,t),$(ht.$$.fragment,t),$(_t.$$.fragment,t),$(bt.$$.fragment,t),$($t.$$.fragment,t),$(Ve.$$.fragment,t),$(xt.$$.fragment,t),$(ze.$$.fragment,t),$(vt.$$.fragment,t),$(Se.$$.fragment,t),$(wt.$$.fragment,t),$(Ee.$$.fragment,t),$(yt.$$.fragment,t),$(Ye.$$.fragment,t),$(Mt.$$.fragment,t),$(Tt.$$.fragment,t),$(Qe.$$.fragment,t),$(Jt.$$.fragment,t),$(We.$$.fragment,t),$(jt.$$.fragment,t),$(Le.$$.fragment,t),$(kt.$$.fragment,t),$(He.$$.fragment,t),$(Ct.$$.fragment,t),$(Ae.$$.fragment,t),$(Ut.$$.fragment,t),$(Rt.$$.fragment,t),$(Nt.$$.fragment,t),$(Gt.$$.fragment,t),$(Xt.$$.fragment,t),$(Zt.$$.fragment,t),$(Pe.$$.fragment,t),$(It.$$.fragment,t),$(qe.$$.fragment,t),$(Dt.$$.fragment,t),$(Oe.$$.fragment,t),$(Ke.$$.fragment,t),$(et.$$.fragment,t),$(tt.$$.fragment,t),$(Bt.$$.fragment,t),$(Ft.$$.fragment,t),$(at.$$.fragment,t),$(Vt.$$.fragment,t),$(st.$$.fragment,t),$(zt.$$.fragment,t),$(St.$$.fragment,t),$(Et.$$.fragment,t),$(nt.$$.fragment,t),$(Yt.$$.fragment,t),Ms=!1},d(t){t&&(i(w),i(d),i(s),i(e),i(as),i(ot),i(ss),i(j),i(ns),i(K),i(rs),i($e),i(os),i(Q),i(ls),i(ds),i(Z),i(is),i(G),i(cs),i(xe),i(ps),i(F),i(ms),i(gs),i(V),i(us),i(fs),i(W),i(hs),i(X),i(_s),i(N),i(bs),i(ve),i($s),i(z),i(xs),i(vs),i(ee),i(ws),i(ys),i(ts)),i(a),x(l,t),x(m,t),x(lt),x(dt),x(Ge),x(it),x(Xe),x(Ze),x(Ie),x(ct),x(De),x(pt),x(Be),x(mt),x(gt),x(ut),x(ft),x(ht),x(_t,t),x(bt),x($t),x(Ve),x(xt),x(ze),x(vt),x(Se),x(wt),x(Ee),x(yt),x(Ye),x(Mt),x(Tt),x(Qe),x(Jt),x(We),x(jt),x(Le),x(kt),x(He),x(Ct),x(Ae),x(Ut),x(Rt),x(Nt,t),x(Gt),x(Xt,t),x(Zt),x(Pe),x(It),x(qe),x(Dt),x(Oe),x(Ke),x(et),x(tt),x(Bt),x(Ft),x(at),x(Vt),x(st),x(zt),x(St,t),x(Et),x(nt),x(Yt,t)}}}const al='{"title":"Builder classes","local":"builder-classes","sections":[{"title":"Builders","local":"datasets.DatasetBuilder","sections":[],"depth":2},{"title":"Download","local":"datasets.DownloadManager","sections":[],"depth":2},{"title":"Verification","local":"datasets.VerificationMode","sections":[],"depth":2},{"title":"Splits","local":"datasets.SplitGenerator","sections":[],"depth":2},{"title":"Version","local":"datasets.Version","sections":[],"depth":2}],"depth":1}';function sl(y){return To(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class cl extends Jo{constructor(a){super(),jo(this,a,sl,tl,Mo,{})}}export{cl as component};
