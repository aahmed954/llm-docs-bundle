import{s as $s,n as ks,o as Is}from"../chunks/scheduler.bdbef820.js";import{S as Rs,i as Vs,g as o,s as l,r as i,A as Xs,h as p,f as a,c as n,j as G,u as d,x as r,k as hs,y as M,a as t,v as m,d as u,t as h,w as f}from"../chunks/index.c0aea24a.js";import{C as z}from"../chunks/CodeBlock.e814ab8d.js";import{H as fs,E as Ys}from"../chunks/index.89e522f3.js";function Zs(gs){let c,F,W,q,j,B,b,ys="This guide shows specific methods for processing audio datasets. Learn how to:",Q,J,Ms='<li>Resample the sampling rate.</li> <li>Use <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> with audio datasets.</li>',A,T,js='For a guide on how to process any type of dataset, take a look at the <a class="underline decoration-sky-400 decoration-2 font-semibold" href="./process">general process guide</a>.',L,U,P,w,bs='The <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.cast_column">cast_column()</a> function is used to cast a column to another feature to be decoded. When you use this function with the <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Audio">Audio</a> feature, you can resample the sampling rate:',S,_,K,v,Js="Audio files are decoded and resampled on-the-fly, so the next time you access an example, the audio file is resampled to 16kHz:",D,$,O,g,Ts='<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/resample.gif"/> <img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/resample-dark.gif"/>',ss,k,es,I,Us='The <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> function helps preprocess your entire dataset at once. Depending on the type of model you’re working with, you’ll need to either load a <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoFeatureExtractor" rel="nofollow">feature extractor</a> or a <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoProcessor" rel="nofollow">processor</a>.',as,y,R,N,ws="For pretrained speech recognition models, load a feature extractor and tokenizer and combine them in a <code>processor</code>:",ds,V,ms,X,H,_s="For fine-tuned speech recognition models, you only need to load a <code>processor</code>:",us,Y,ts,Z,vs='When you use <a href="/docs/datasets/v3.6.0/en/package_reference/main_classes#datasets.Dataset.map">map()</a> with your preprocessing function, include the <code>audio</code> column to ensure you’re actually resampling the audio data:',ls,C,ns,x,os,E,ps;return j=new fs({props:{title:"Process audio data",local:"process-audio-data",headingTag:"h1"}}),U=new fs({props:{title:"Cast",local:"cast",headingTag:"h2"}}),_=new z({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjAlMjJlbi1VUyUyMiUyQyUyMHNwbGl0JTNEJTIydHJhaW4lMjIpJTBBZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEMTYwMDApKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, <span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))`,wrap:!1}}),$=new z({props:{code:"ZGF0YXNldCU1QjAlNUQlNUIlMjJhdWRpbyUyMiU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">2.3443763e-05</span>,  <span class="hljs-number">2.1729663e-04</span>,  <span class="hljs-number">2.2145823e-04</span>, ...,
         <span class="hljs-number">3.8356509e-05</span>, -<span class="hljs-number">7.3497440e-06</span>, -<span class="hljs-number">2.1754686e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`,wrap:!1}}),k=new fs({props:{title:"Map",local:"map",headingTag:"h2"}}),V=new z({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvRmVhdHVyZUV4dHJhY3RvciUyQyUyMEF1dG9Qcm9jZXNzb3IlMEElMEFtb2RlbF9jaGVja3BvaW50JTIwJTNEJTIwJTIyZmFjZWJvb2slMkZ3YXYydmVjMi1sYXJnZS14bHNyLTUzJTIyJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplciglMjIuJTJGdm9jYWIuanNvbiUyMiUyQyUyMHVua190b2tlbiUzRCUyMiU1QlVOSyU1RCUyMiUyQyUyMHBhZF90b2tlbiUzRCUyMiU1QlBBRCU1RCUyMiUyQyUyMHdvcmRfZGVsaW1pdGVyX3Rva2VuJTNEJTIyJTdDJTIyKSUwQWZlYXR1cmVfZXh0cmFjdG9yJTIwJTNEJTIwQXV0b0ZlYXR1cmVFeHRyYWN0b3IuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2NoZWNrcG9pbnQpJTBBcHJvY2Vzc29yJTIwJTNEJTIwQXV0b1Byb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoZmVhdHVyZV9leHRyYWN0b3IlM0RmZWF0dXJlX2V4dHJhY3RvciUyQyUyMHRva2VuaXplciUzRHRva2VuaXplcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoFeatureExtractor, AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>model_checkpoint = <span class="hljs-string">&quot;facebook/wav2vec2-large-xlsr-53&quot;</span>
<span class="hljs-comment"># after defining a vocab.json file you can instantiate a tokenizer object:</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer(<span class="hljs-string">&quot;./vocab.json&quot;</span>, unk_token=<span class="hljs-string">&quot;[UNK]&quot;</span>, pad_token=<span class="hljs-string">&quot;[PAD]&quot;</span>, word_delimiter_token=<span class="hljs-string">&quot;|&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(feature_extractor=feature_extractor, tokenizer=tokenizer)`,wrap:!1}}),Y=new z({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJmYWNlYm9vayUyRndhdjJ2ZWMyLWJhc2UtOTYwaCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`,wrap:!1}}),C=new z({props:{code:"ZGVmJTIwcHJlcGFyZV9kYXRhc2V0KGJhdGNoKSUzQSUwQSUyMCUyMCUyMCUyMGF1ZGlvJTIwJTNEJTIwYmF0Y2glNUIlMjJhdWRpbyUyMiU1RCUwQSUyMCUyMCUyMCUyMGJhdGNoJTVCJTIyaW5wdXRfdmFsdWVzJTIyJTVEJTIwJTNEJTIwcHJvY2Vzc29yKGF1ZGlvJTVCJTIyYXJyYXklMjIlNUQlMkMlMjBzYW1wbGluZ19yYXRlJTNEYXVkaW8lNUIlMjJzYW1wbGluZ19yYXRlJTIyJTVEKS5pbnB1dF92YWx1ZXMlNUIwJTVEJTBBJTIwJTIwJTIwJTIwYmF0Y2glNUIlMjJpbnB1dF9sZW5ndGglMjIlNUQlMjAlM0QlMjBsZW4oYmF0Y2glNUIlMjJpbnB1dF92YWx1ZXMlMjIlNUQpJTBBJTIwJTIwJTIwJTIwd2l0aCUyMHByb2Nlc3Nvci5hc190YXJnZXRfcHJvY2Vzc29yKCklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBiYXRjaCU1QiUyMmxhYmVscyUyMiU1RCUyMCUzRCUyMHByb2Nlc3NvcihiYXRjaCU1QiUyMnNlbnRlbmNlJTIyJTVEKS5pbnB1dF9pZHMlMEElMjAlMjAlMjAlMjByZXR1cm4lMjBiYXRjaCUwQWRhdGFzZXQlMjAlM0QlMjBkYXRhc2V0Lm1hcChwcmVwYXJlX2RhdGFzZXQlMkMlMjByZW1vdmVfY29sdW1ucyUzRGRhdGFzZXQuY29sdW1uX25hbWVzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataset</span>(<span class="hljs-params">batch</span>):
<span class="hljs-meta">... </span>    audio = batch[<span class="hljs-string">&quot;audio&quot;</span>]
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;input_values&quot;</span>] = processor(audio[<span class="hljs-string">&quot;array&quot;</span>], sampling_rate=audio[<span class="hljs-string">&quot;sampling_rate&quot;</span>]).input_values[<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;input_length&quot;</span>] = <span class="hljs-built_in">len</span>(batch[<span class="hljs-string">&quot;input_values&quot;</span>])
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> processor.as_target_processor():
<span class="hljs-meta">... </span>        batch[<span class="hljs-string">&quot;labels&quot;</span>] = processor(batch[<span class="hljs-string">&quot;sentence&quot;</span>]).input_ids
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> batch
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(prepare_dataset, remove_columns=dataset.column_names)`,wrap:!1}}),x=new Ys({props:{source:"https://github.com/huggingface/datasets/blob/main/docs/source/audio_process.mdx"}}),{c(){c=o("meta"),F=l(),W=o("p"),q=l(),i(j.$$.fragment),B=l(),b=o("p"),b.textContent=ys,Q=l(),J=o("ul"),J.innerHTML=Ms,A=l(),T=o("p"),T.innerHTML=js,L=l(),i(U.$$.fragment),P=l(),w=o("p"),w.innerHTML=bs,S=l(),i(_.$$.fragment),K=l(),v=o("p"),v.textContent=Js,D=l(),i($.$$.fragment),O=l(),g=o("div"),g.innerHTML=Ts,ss=l(),i(k.$$.fragment),es=l(),I=o("p"),I.innerHTML=Us,as=l(),y=o("ul"),R=o("li"),N=o("p"),N.innerHTML=ws,ds=l(),i(V.$$.fragment),ms=l(),X=o("li"),H=o("p"),H.innerHTML=_s,us=l(),i(Y.$$.fragment),ts=l(),Z=o("p"),Z.innerHTML=vs,ls=l(),i(C.$$.fragment),ns=l(),i(x.$$.fragment),os=l(),E=o("p"),this.h()},l(s){const e=Xs("svelte-u9bgzb",document.head);c=p(e,"META",{name:!0,content:!0}),e.forEach(a),F=n(s),W=p(s,"P",{}),G(W).forEach(a),q=n(s),d(j.$$.fragment,s),B=n(s),b=p(s,"P",{"data-svelte-h":!0}),r(b)!=="svelte-12xza0g"&&(b.textContent=ys),Q=n(s),J=p(s,"UL",{"data-svelte-h":!0}),r(J)!=="svelte-1yfg4b5"&&(J.innerHTML=Ms),A=n(s),T=p(s,"P",{"data-svelte-h":!0}),r(T)!=="svelte-3s2bzp"&&(T.innerHTML=js),L=n(s),d(U.$$.fragment,s),P=n(s),w=p(s,"P",{"data-svelte-h":!0}),r(w)!=="svelte-hh0k95"&&(w.innerHTML=bs),S=n(s),d(_.$$.fragment,s),K=n(s),v=p(s,"P",{"data-svelte-h":!0}),r(v)!=="svelte-cxxpks"&&(v.textContent=Js),D=n(s),d($.$$.fragment,s),O=n(s),g=p(s,"DIV",{class:!0,"data-svelte-h":!0}),r(g)!=="svelte-1e533u5"&&(g.innerHTML=Ts),ss=n(s),d(k.$$.fragment,s),es=n(s),I=p(s,"P",{"data-svelte-h":!0}),r(I)!=="svelte-97ieyo"&&(I.innerHTML=Us),as=n(s),y=p(s,"UL",{});var rs=G(y);R=p(rs,"LI",{});var cs=G(R);N=p(cs,"P",{"data-svelte-h":!0}),r(N)!=="svelte-eqcmp0"&&(N.innerHTML=ws),ds=n(cs),d(V.$$.fragment,cs),cs.forEach(a),ms=n(rs),X=p(rs,"LI",{});var is=G(X);H=p(is,"P",{"data-svelte-h":!0}),r(H)!=="svelte-1p2th5z"&&(H.innerHTML=_s),us=n(is),d(Y.$$.fragment,is),is.forEach(a),rs.forEach(a),ts=n(s),Z=p(s,"P",{"data-svelte-h":!0}),r(Z)!=="svelte-eal307"&&(Z.innerHTML=vs),ls=n(s),d(C.$$.fragment,s),ns=n(s),d(x.$$.fragment,s),os=n(s),E=p(s,"P",{}),G(E).forEach(a),this.h()},h(){hs(c,"name","hf:doc:metadata"),hs(c,"content",Cs),hs(g,"class","flex justify-center")},m(s,e){M(document.head,c),t(s,F,e),t(s,W,e),t(s,q,e),m(j,s,e),t(s,B,e),t(s,b,e),t(s,Q,e),t(s,J,e),t(s,A,e),t(s,T,e),t(s,L,e),m(U,s,e),t(s,P,e),t(s,w,e),t(s,S,e),m(_,s,e),t(s,K,e),t(s,v,e),t(s,D,e),m($,s,e),t(s,O,e),t(s,g,e),t(s,ss,e),m(k,s,e),t(s,es,e),t(s,I,e),t(s,as,e),t(s,y,e),M(y,R),M(R,N),M(R,ds),m(V,R,null),M(y,ms),M(y,X),M(X,H),M(X,us),m(Y,X,null),t(s,ts,e),t(s,Z,e),t(s,ls,e),m(C,s,e),t(s,ns,e),m(x,s,e),t(s,os,e),t(s,E,e),ps=!0},p:ks,i(s){ps||(u(j.$$.fragment,s),u(U.$$.fragment,s),u(_.$$.fragment,s),u($.$$.fragment,s),u(k.$$.fragment,s),u(V.$$.fragment,s),u(Y.$$.fragment,s),u(C.$$.fragment,s),u(x.$$.fragment,s),ps=!0)},o(s){h(j.$$.fragment,s),h(U.$$.fragment,s),h(_.$$.fragment,s),h($.$$.fragment,s),h(k.$$.fragment,s),h(V.$$.fragment,s),h(Y.$$.fragment,s),h(C.$$.fragment,s),h(x.$$.fragment,s),ps=!1},d(s){s&&(a(F),a(W),a(q),a(B),a(b),a(Q),a(J),a(A),a(T),a(L),a(P),a(w),a(S),a(K),a(v),a(D),a(O),a(g),a(ss),a(es),a(I),a(as),a(y),a(ts),a(Z),a(ls),a(ns),a(os),a(E)),a(c),f(j,s),f(U,s),f(_,s),f($,s),f(k,s),f(V),f(Y),f(C,s),f(x,s)}}}const Cs='{"title":"Process audio data","local":"process-audio-data","sections":[{"title":"Cast","local":"cast","sections":[],"depth":2},{"title":"Map","local":"map","sections":[],"depth":2}],"depth":1}';function xs(gs){return Is(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gs extends Rs{constructor(c){super(),Vs(this,c,xs,Zs,$s,{})}}export{Gs as component};
