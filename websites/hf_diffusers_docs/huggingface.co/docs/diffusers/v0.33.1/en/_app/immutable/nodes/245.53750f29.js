import{s as mt,n as pt,o as ct}from"../chunks/scheduler.8c3d61f6.js";import{S as gt,i as ht,g as o,s as a,r as k,A as bt,h as l,f as i,c as s,j as rt,u as L,x as r,k as dt,y as xt,a as n,v as H,d as B,t as I,w as P}from"../chunks/index.da70eac4.js";import{C as ft}from"../chunks/CodeBlock.a9c4becf.js";import{H as ut,E as wt}from"../chunks/index.5d4ab994.js";function yt(N){let d,R,C,U,f,j,u,Q='ü§ó Diffusers provides a collection of training scripts for you to train your own diffusion models. You can find all of our training scripts in <a href="https://github.com/huggingface/diffusers/tree/main/examples" rel="nofollow">diffusers/examples</a>.',J,m,K="Each training script is:",Z,p,tt="<li><strong>Self-contained</strong>: the training script does not depend on any local files, and all packages required to run the script are installed from the <code>requirements.txt</code> file.</li> <li><strong>Easy-to-tweak</strong>: the training scripts are an example of how to train a diffusion model for a specific task and won‚Äôt work out-of-the-box for every training scenario. You‚Äôll likely need to adapt the training script for your specific use-case. To help you with that, we‚Äôve fully exposed the data preprocessing code and the training loop so you can modify it for your own use.</li> <li><strong>Beginner-friendly</strong>: the training scripts are designed to be beginner-friendly and easy to understand, rather than including the latest state-of-the-art methods to get the best and most competitive results. Any training methods we consider too complex are purposefully left out.</li> <li><strong>Single-purpose</strong>: each training script is expressly designed for only one task to keep it readable and understandable.</li>",E,c,et="Our current collection of training scripts include:",F,g,it='<thead><tr><th>Training</th> <th>SDXL-support</th> <th>LoRA-support</th> <th>Flax-support</th></tr></thead> <tbody><tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/unconditional_image_generation" rel="nofollow">unconditional image generation</a> <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td> <td></td> <td></td> <td></td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/text_to_image" rel="nofollow">text-to-image</a></td> <td>üëç</td> <td>üëç</td> <td>üëç</td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion" rel="nofollow">textual inversion</a> <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_textual_inversion_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td> <td></td> <td></td> <td>üëç</td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/dreambooth" rel="nofollow">DreamBooth</a> <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td> <td>üëç</td> <td>üëç</td> <td>üëç</td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/controlnet" rel="nofollow">ControlNet</a></td> <td>üëç</td> <td></td> <td>üëç</td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/instruct_pix2pix" rel="nofollow">InstructPix2Pix</a></td> <td>üëç</td> <td></td> <td></td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/custom_diffusion" rel="nofollow">Custom Diffusion</a></td> <td></td> <td></td> <td></td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/t2i_adapter" rel="nofollow">T2I-Adapters</a></td> <td>üëç</td> <td></td> <td></td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/kandinsky2_2/text_to_image" rel="nofollow">Kandinsky 2.2</a></td> <td></td> <td>üëç</td> <td></td></tr> <tr><td><a href="https://github.com/huggingface/diffusers/tree/main/examples/wuerstchen/text_to_image" rel="nofollow">Wuerstchen</a></td> <td></td> <td>üëç</td> <td></td></tr></tbody>',q,h,nt='These examples are <strong>actively</strong> maintained, so please feel free to open an issue if they aren‚Äôt working as expected. If you feel like another training example should be included, you‚Äôre more than welcome to start a <a href="https://github.com/huggingface/diffusers/issues/new?assignees=&amp;labels=&amp;template=feature_request.md&amp;title=" rel="nofollow">Feature Request</a> to discuss your feature idea with us and whether it meets our criteria of being self-contained, easy-to-tweak, beginner-friendly, and single-purpose.',G,b,S,x,at="Make sure you can successfully run the latest versions of the example scripts by installing the library from source in a new virtual environment:",W,w,X,y,st='Then navigate to the folder of the training script (for example, <a href="https://github.com/huggingface/diffusers/tree/main/examples/dreambooth" rel="nofollow">DreamBooth</a>) and install the <code>requirements.txt</code> file. Some training scripts have a specific requirement file for SDXL, LoRA or Flax. If you‚Äôre using one of these scripts, make sure you install its corresponding requirements file.',z,v,A,_,ot="To speedup training and reduce memory-usage, we recommend:",D,$,lt='<li>using PyTorch 2.0 or higher to automatically use <a href="../optimization/torch2.0#scaled-dot-product-attention">scaled dot product attention</a> during training (you don‚Äôt need to make any changes to the training code)</li> <li>installing <a href="../optimization/xformers">xFormers</a> to enable memory-efficient attention</li>',Y,T,O,M,V;return f=new ut({props:{title:"Overview",local:"overview",headingTag:"h1"}}),b=new ut({props:{title:"Install",local:"install",headingTag:"h2"}}),w=new ft({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZodWdnaW5nZmFjZSUyRmRpZmZ1c2VycyUwQWNkJTIwZGlmZnVzZXJzJTBBcGlwJTIwaW5zdGFsbCUyMC4=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/diffusers
<span class="hljs-built_in">cd</span> diffusers
pip install .`,wrap:!1}}),v=new ft({props:{code:"Y2QlMjBleGFtcGxlcyUyRmRyZWFtYm9vdGglMEFwaXAlMjBpbnN0YWxsJTIwLXIlMjByZXF1aXJlbWVudHMudHh0JTBBJTIzJTIwdG8lMjB0cmFpbiUyMFNEWEwlMjB3aXRoJTIwRHJlYW1Cb290aCUwQXBpcCUyMGluc3RhbGwlMjAtciUyMHJlcXVpcmVtZW50c19zZHhsLnR4dA==",highlighted:`<span class="hljs-built_in">cd</span> examples/dreambooth
pip install -r requirements.txt
<span class="hljs-comment"># to train SDXL with DreamBooth</span>
pip install -r requirements_sdxl.txt`,wrap:!1}}),T=new wt({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/training/overview.md"}}),{c(){d=o("meta"),R=a(),C=o("p"),U=a(),k(f.$$.fragment),j=a(),u=o("p"),u.innerHTML=Q,J=a(),m=o("p"),m.textContent=K,Z=a(),p=o("ul"),p.innerHTML=tt,E=a(),c=o("p"),c.textContent=et,F=a(),g=o("table"),g.innerHTML=it,q=a(),h=o("p"),h.innerHTML=nt,G=a(),k(b.$$.fragment),S=a(),x=o("p"),x.textContent=at,W=a(),k(w.$$.fragment),X=a(),y=o("p"),y.innerHTML=st,z=a(),k(v.$$.fragment),A=a(),_=o("p"),_.textContent=ot,D=a(),$=o("ul"),$.innerHTML=lt,Y=a(),k(T.$$.fragment),O=a(),M=o("p"),this.h()},l(t){const e=bt("svelte-u9bgzb",document.head);d=l(e,"META",{name:!0,content:!0}),e.forEach(i),R=s(t),C=l(t,"P",{}),rt(C).forEach(i),U=s(t),L(f.$$.fragment,t),j=s(t),u=l(t,"P",{"data-svelte-h":!0}),r(u)!=="svelte-odg5wz"&&(u.innerHTML=Q),J=s(t),m=l(t,"P",{"data-svelte-h":!0}),r(m)!=="svelte-1l5xx5e"&&(m.textContent=K),Z=s(t),p=l(t,"UL",{"data-svelte-h":!0}),r(p)!=="svelte-17s4x4c"&&(p.innerHTML=tt),E=s(t),c=l(t,"P",{"data-svelte-h":!0}),r(c)!=="svelte-1yvg5e"&&(c.textContent=et),F=s(t),g=l(t,"TABLE",{"data-svelte-h":!0}),r(g)!=="svelte-cok55p"&&(g.innerHTML=it),q=s(t),h=l(t,"P",{"data-svelte-h":!0}),r(h)!=="svelte-n03e9a"&&(h.innerHTML=nt),G=s(t),L(b.$$.fragment,t),S=s(t),x=l(t,"P",{"data-svelte-h":!0}),r(x)!=="svelte-1uukpq2"&&(x.textContent=at),W=s(t),L(w.$$.fragment,t),X=s(t),y=l(t,"P",{"data-svelte-h":!0}),r(y)!=="svelte-gld5li"&&(y.innerHTML=st),z=s(t),L(v.$$.fragment,t),A=s(t),_=l(t,"P",{"data-svelte-h":!0}),r(_)!=="svelte-1fce6dt"&&(_.textContent=ot),D=s(t),$=l(t,"UL",{"data-svelte-h":!0}),r($)!=="svelte-aa6btk"&&($.innerHTML=lt),Y=s(t),L(T.$$.fragment,t),O=s(t),M=l(t,"P",{}),rt(M).forEach(i),this.h()},h(){dt(d,"name","hf:doc:metadata"),dt(d,"content",vt)},m(t,e){xt(document.head,d),n(t,R,e),n(t,C,e),n(t,U,e),H(f,t,e),n(t,j,e),n(t,u,e),n(t,J,e),n(t,m,e),n(t,Z,e),n(t,p,e),n(t,E,e),n(t,c,e),n(t,F,e),n(t,g,e),n(t,q,e),n(t,h,e),n(t,G,e),H(b,t,e),n(t,S,e),n(t,x,e),n(t,W,e),H(w,t,e),n(t,X,e),n(t,y,e),n(t,z,e),H(v,t,e),n(t,A,e),n(t,_,e),n(t,D,e),n(t,$,e),n(t,Y,e),H(T,t,e),n(t,O,e),n(t,M,e),V=!0},p:pt,i(t){V||(B(f.$$.fragment,t),B(b.$$.fragment,t),B(w.$$.fragment,t),B(v.$$.fragment,t),B(T.$$.fragment,t),V=!0)},o(t){I(f.$$.fragment,t),I(b.$$.fragment,t),I(w.$$.fragment,t),I(v.$$.fragment,t),I(T.$$.fragment,t),V=!1},d(t){t&&(i(R),i(C),i(U),i(j),i(u),i(J),i(m),i(Z),i(p),i(E),i(c),i(F),i(g),i(q),i(h),i(G),i(S),i(x),i(W),i(X),i(y),i(z),i(A),i(_),i(D),i($),i(Y),i(O),i(M)),i(d),P(f,t),P(b,t),P(w,t),P(v,t),P(T,t)}}}const vt='{"title":"Overview","local":"overview","sections":[{"title":"Install","local":"install","sections":[],"depth":2}],"depth":1}';function _t(N){return ct(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kt extends gt{constructor(d){super(),ht(this,d,_t,yt,mt,{})}}export{kt as component};
