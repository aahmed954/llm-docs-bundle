import{s as Zs,o as Us,n as vl}from"../chunks/scheduler.8c3d61f6.js";import{S as js,i as Ws,g as n,s as a,r as m,A as Gs,h as o,f as l,c as i,j as ws,u as f,x as p,k as Z,y as vs,a as s,v as d,d as c,t as u,w as M}from"../chunks/index.da70eac4.js";import{T as Gl}from"../chunks/Tip.1d9b8c37.js";import{C as b}from"../chunks/CodeBlock.a9c4becf.js";import{D as Is}from"../chunks/DocNotebookDropdown.48852948.js";import{H as T,E as _s}from"../chunks/index.5d4ab994.js";function $s(j){let r,J='We recommend installing the <a href="https://pypi.org/project/invisible-watermark/" rel="nofollow">invisible-watermark</a> library to help identify images that are generated. If the invisible-watermark library is installed, it is used by default. To disable the watermarker:',y,h,w;return h=new b({props:{code:"cGlwZWxpbmUlMjAlM0QlMjBTdGFibGVEaWZmdXNpb25YTFBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCguLi4lMkMlMjBhZGRfd2F0ZXJtYXJrZXIlM0RGYWxzZSk=",highlighted:'pipeline = StableDiffusionXLPipeline.from_pretrained(..., add_watermarker=<span class="hljs-literal">False</span>)',wrap:!1}}),{c(){r=n("p"),r.innerHTML=J,y=a(),m(h.$$.fragment)},l(g){r=o(g,"P",{"data-svelte-h":!0}),p(r)!=="svelte-1pmihy9"&&(r.innerHTML=J),y=i(g),f(h.$$.fragment,g)},m(g,U){s(g,r,U),s(g,y,U),d(h,g,U),w=!0},p:vl,i(g){w||(c(h.$$.fragment,g),w=!0)},o(g){u(h.$$.fragment,g),w=!1},d(g){g&&(l(r),l(y)),M(h,g)}}}function Bs(j){let r,J="The <code>denoising_end</code> and <code>denoising_start</code> parameters should be a float between 0 and 1. These parameters are represented as a proportion of discrete timesteps as defined by the scheduler. If youâ€™re also using the <code>strength</code> parameter, itâ€™ll be ignored because the number of denoising steps is determined by the discrete timesteps the model is trained on and the declared fractional cutoff.";return{c(){r=n("p"),r.innerHTML=J},l(y){r=o(y,"P",{"data-svelte-h":!0}),p(r)!=="svelte-1m9evqf"&&(r.innerHTML=J)},m(y,h){s(y,r,h)},p:vl,d(y){y&&l(r)}}}function ks(j){let r,J='You can use SDXL refiner with a different base model. For example, you can use the <a href="../../api/pipelines/hunyuandit">Hunyuan-DiT</a> or <a href="../../api/pipelines/pixart_sigma">PixArt-Sigma</a> pipelines to generate images with better prompt adherence. Once you have generated an image, you can pass it to the SDXL refiner model to enhance final generation quality.';return{c(){r=n("p"),r.innerHTML=J},l(y){r=o(y,"P",{"data-svelte-h":!0}),p(r)!=="svelte-kvhztt"&&(r.innerHTML=J)},m(y,h){s(y,r,h)},p:vl,d(y){y&&l(r)}}}function Xs(j){let r,J='You can use both micro-conditioning and negative micro-conditioning parameters thanks to classifier-free guidance. They are available in the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline">StableDiffusionXLPipeline</a>, <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline">StableDiffusionXLImg2ImgPipeline</a>, <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline">StableDiffusionXLInpaintPipeline</a>, and <a href="/docs/diffusers/v0.33.1/en/api/pipelines/controlnet_sdxl#diffusers.StableDiffusionXLControlNetPipeline">StableDiffusionXLControlNetPipeline</a>.';return{c(){r=n("p"),r.innerHTML=J},l(y){r=o(y,"P",{"data-svelte-h":!0}),p(r)!=="svelte-gna5yh"&&(r.innerHTML=J)},m(y,h){s(y,r,h)},p:vl,d(y){y&&l(r)}}}function xs(j){let r,J,y,h,w,g,U,Oe,S,Il='<a href="https://huggingface.co/papers/2307.01952" rel="nofollow">Stable Diffusion XL</a> (SDXL) is a powerful text-to-image generation model that iterates on the previous Stable Diffusion models in three key ways:',et,E,_l="<li>the UNet is 3x larger and SDXL combines a second text encoder (OpenCLIP ViT-bigG/14) with the original text encoder to significantly increase the number of parameters</li> <li>introduces size and crop-conditioning to preserve training data from being discarded and gain more control over how a generated image should be cropped</li> <li>introduces a two-stage model process; the <em>base</em> model (can also be run as a standalone model) generates an image as an input to the <em>refiner</em> model which adds additional high-quality details</li>",tt,N,$l="This guide will show you how to use SDXL for text-to-image, image-to-image, and inpainting.",lt,Q,Bl="Before you begin, make sure you have the following libraries installed:",st,F,at,W,it,L,nt,H,kl='Model weights may be stored in separate subfolders on the Hub or locally, in which case, you should use the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained">from_pretrained()</a> method:',ot,z,pt,q,Xl='You can also use the <a href="/docs/diffusers/v0.33.1/en/api/loaders/single_file#diffusers.loaders.FromSingleFileMixin.from_single_file">from_single_file()</a> method to load a model checkpoint stored in a single file format (<code>.ckpt</code> or <code>.safetensors</code>) from the Hub or locally:',rt,D,mt,A,ft,P,xl="For text-to-image, pass a text prompt. By default, SDXL generates a 1024x1024 image for the best results. You can try setting the <code>height</code> and <code>width</code> parameters to 768x768 or 512x512, but anything below 512x512 is not likely to work.",dt,K,ct,G,Cl='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png" alt="generated image of an astronaut in a jungle"/>',ut,O,Mt,ee,Rl="For image-to-image, SDXL works especially well with image sizes between 768x768 and 1024x1024. Pass an initial image, and a text prompt to condition the image with:",yt,te,bt,v,Vl='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-img2img.png" alt="generated image of a dog catching a frisbee in a jungle"/>',gt,le,ht,se,Yl="For inpainting, youâ€™ll need the original image and a mask of what you want to replace in the original image. Create a prompt to describe what you want to replace the masked area with.",Jt,ae,Tt,I,Sl='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint.png" alt="generated image of a deep sea diver in a jungle"/>',wt,ie,Zt,ne,El='SDXL includes a <a href="https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0" rel="nofollow">refiner model</a> specialized in denoising low-noise stage images to generate higher-quality images from the base model. There are two ways to use the refiner:',Ut,oe,Nl="<li>use the base and refiner models together to produce a refined image</li> <li>use the base model to produce an image, and subsequently use the refiner model to add more details to the image (this is how SDXL was originally trained)</li>",jt,pe,Wt,re,Ql='When you use the base and refiner model together to generate an image, this is known as an <a href="https://research.nvidia.com/labs/dir/eDiff-I/" rel="nofollow"><em>ensemble of expert denoisers</em></a>. The ensemble of expert denoisers approach requires fewer overall denoising steps versus passing the base modelâ€™s output to the refiner model, so it should be significantly faster to run. However, you wonâ€™t be able to inspect the base modelâ€™s output because it still contains a large amount of noise.',Gt,me,Fl="As an ensemble of expert denoisers, the base model serves as the expert during the high-noise diffusion stage and the refiner model serves as the expert during the low-noise diffusion stage. Load the base and refiner model:",vt,fe,It,de,Ll='To use this approach, you need to define the number of timesteps for each model to run through their respective stages. For the base model, this is controlled by the <a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.denoising_end" rel="nofollow"><code>denoising_end</code></a> parameter and for the refiner model, it is controlled by the <a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLImg2ImgPipeline.__call__.denoising_start" rel="nofollow"><code>denoising_start</code></a> parameter.',_t,_,$t,ce,Hl="Letâ€™s set <code>denoising_end=0.8</code> so the base model performs the first 80% of denoising the <strong>high-noise</strong> timesteps and set <code>denoising_start=0.8</code> so the refiner model performs the last 20% of denoising the <strong>low-noise</strong> timesteps. The base model output should be in <strong>latent</strong> space instead of a PIL image.",Bt,ue,kt,$,zl='<div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lion_base.png" alt="generated image of a lion on a rock at night"/> <figcaption class="mt-2 text-center text-sm text-gray-500">default base model</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lion_refined.png" alt="generated image of a lion on a rock at night in higher quality"/> <figcaption class="mt-2 text-center text-sm text-gray-500">ensemble of expert denoisers</figcaption></div>',Xt,Me,ql='The refiner model can also be used for inpainting in the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline">StableDiffusionXLInpaintPipeline</a>:',xt,ye,Ct,be,Dl="This ensemble of expert denoisers method works well for all available schedulers!",Rt,ge,Vt,he,Al="SDXL gets a boost in image quality by using the refiner model to add additional high-quality details to the fully-denoised image from the base model, in an image-to-image setting.",Yt,Je,Pl="Load the base and refiner models:",St,Te,Et,B,Nt,we,Kl="Generate an image from the base model, and set the model output to <strong>latent</strong> space:",Qt,Ze,Ft,Ue,Ol="Pass the generated image to the refiner model:",Lt,je,Ht,k,es='<div><img class="rounded-xl" src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/sd_xl/init_image.png" alt="generated image of an astronaut riding a green horse on Mars"/> <figcaption class="mt-2 text-center text-sm text-gray-500">base model</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/sd_xl/refined_image.png" alt="higher quality generated image of an astronaut riding a green horse on Mars"/> <figcaption class="mt-2 text-center text-sm text-gray-500">base model + refiner model</figcaption></div>',zt,We,ts='For inpainting, load the base and the refiner model in the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline">StableDiffusionXLInpaintPipeline</a>, remove the <code>denoising_end</code> and <code>denoising_start</code> parameters, and choose a smaller number of inference steps for the refiner.',qt,Ge,Dt,ve,ls="SDXL training involves several additional conditioning techniques, which are referred to as <em>micro-conditioning</em>. These include original image size, target image size, and cropping parameters. The micro-conditionings can be used at inference time to create high-quality, centered images.",At,X,Pt,Ie,Kt,_e,ss="There are two types of size conditioning:",Ot,$e,as='<li><p><a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.original_size" rel="nofollow"><code>original_size</code></a> conditioning comes from upscaled images in the training batch (because it would be wasteful to discard the smaller images which make up almost 40% of the total training data). This way, SDXL learns that upscaling artifacts are not supposed to be present in high-resolution images. During inference, you can use <code>original_size</code> to indicate the original image resolution. Using the default value of <code>(1024, 1024)</code> produces higher-quality images that resemble the 1024x1024 images in the dataset. If you choose to use a lower resolution, such as <code>(256, 256)</code>, the model still generates 1024x1024 images, but theyâ€™ll look like the low resolution images (simpler patterns, blurring) in the dataset.</p></li> <li><p><a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLPipeline.__call__.target_size" rel="nofollow"><code>target_size</code></a> conditioning comes from finetuning SDXL to support different image aspect ratios. During inference, if you use the default value of <code>(1024, 1024)</code>, youâ€™ll get an image that resembles the composition of square images in the dataset. We recommend using the same value for <code>target_size</code> and <code>original_size</code>, but feel free to experiment with other options!</p></li>',el,Be,is="ðŸ¤— Diffusers also lets you specify negative conditions about an imageâ€™s size to steer generation away from certain image resolutions:",tl,ke,ll,x,ns='<img src="https://huggingface.co/datasets/diffusers/docs-images/resolve/main/sd_xl/negative_conditions.png"/> <figcaption class="text-center">Images negatively conditioned on image resolutions of (128, 128), (256, 256), and (512, 512).</figcaption>',sl,Xe,al,xe,os="Images generated by previous Stable Diffusion models may sometimes appear to be cropped. This is because images are actually cropped during training so that all the images in a batch have the same size. By conditioning on crop coordinates, SDXL <em>learns</em> that no cropping - coordinates <code>(0, 0)</code> - usually correlates with centered subjects and complete faces (this is the default value in ðŸ¤— Diffusers). You can experiment with different coordinates if you want to generate off-centered compositions!",il,Ce,nl,C,ps='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-cropped.png" alt="generated image of an astronaut in a jungle, slightly cropped"/>',ol,Re,rs="You can also specify negative cropping coordinates to steer generation away from certain cropping parameters:",pl,Ve,rl,Ye,ml,Se,ms='SDXL uses two text-encoders, so it is possible to pass a different prompt to each text-encoder, which can <a href="https://github.com/huggingface/diffusers/issues/4004#issuecomment-1627764201" rel="nofollow">improve quality</a>. Pass your original prompt to <code>prompt</code> and the second prompt to <code>prompt_2</code> (use <code>negative_prompt</code> and <code>negative_prompt_2</code> if youâ€™re using negative prompts):',fl,Ee,dl,R,fs='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-double-prompt.png" alt="generated image of an astronaut in a jungle in the style of a van gogh painting"/>',cl,Ne,ds='The dual text-encoders also support textual inversion embeddings that need to be loaded separately as explained in the <a href="textual_inversion_inference#stable-diffusion-xl">SDXL textual inversion</a> section.',ul,Qe,Ml,Fe,cs="SDXL is a large model, and you may need to optimize memory to get it to run on your hardware. Here are some tips to save memory and speed up inference.",yl,Le,us='<li>Offload the model to the CPU with <a href="/docs/diffusers/v0.33.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.enable_model_cpu_offload">enable_model_cpu_offload()</a> for out-of-memory errors:</li>',bl,He,gl,V,Ms="<li>Use <code>torch.compile</code> for ~20% speed-up (you need <code>torch&gt;=2.0</code>):</li>",hl,ze,Jl,Y,ys='<li>Enable <a href="../optimization/xformers">xFormers</a> to run SDXL if <code>torch&lt;2.0</code>:</li>',Tl,qe,wl,De,Zl,Ae,bs='If youâ€™re interested in experimenting with a minimal version of the <a href="/docs/diffusers/v0.33.1/en/api/models/unet2d-cond#diffusers.UNet2DConditionModel">UNet2DConditionModel</a> used in SDXL, take a look at the <a href="https://github.com/cloneofsimo/minSDXL" rel="nofollow">minSDXL</a> implementation which is written in PyTorch and directly compatible with ðŸ¤— Diffusers.',Ul,Pe,jl,Ke,Wl;return w=new T({props:{title:"Stable Diffusion XL",local:"stable-diffusion-xl",headingTag:"h1"}}),U=new Is({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/sdxl.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/sdxl.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/tensorflow/sdxl.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/sdxl.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/sdxl.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/tensorflow/sdxl.ipynb"}]}}),F=new b({props:{code:"JTIzJTIwdW5jb21tZW50JTIwdG8lMjBpbnN0YWxsJTIwdGhlJTIwbmVjZXNzYXJ5JTIwbGlicmFyaWVzJTIwaW4lMjBDb2xhYiUwQSUyMyFwaXAlMjBpbnN0YWxsJTIwLXElMjBkaWZmdXNlcnMlMjB0cmFuc2Zvcm1lcnMlMjBhY2NlbGVyYXRlJTIwaW52aXNpYmxlLXdhdGVybWFyayUzRSUzRDAuMi4w",highlighted:`<span class="hljs-comment"># uncomment to install the necessary libraries in Colab</span>
<span class="hljs-comment">#!pip install -q diffusers transformers accelerate invisible-watermark&gt;=0.2.0</span>`,wrap:!1}}),W=new Gl({props:{warning:!0,$$slots:{default:[$s]},$$scope:{ctx:j}}}),L=new T({props:{title:"Load model checkpoints",local:"load-model-checkpoints",headingTag:"h2"}}),z=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFN0YWJsZURpZmZ1c2lvblhMUGlwZWxpbmUlMkMlMjBTdGFibGVEaWZmdXNpb25YTEltZzJJbWdQaXBlbGluZSUwQWltcG9ydCUyMHRvcmNoJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBTdGFibGVEaWZmdXNpb25YTFBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUyQyUyMHVzZV9zYWZldGVuc29ycyUzRFRydWUlMEEpLnRvKCUyMmN1ZGElMjIpJTBBJTBBcmVmaW5lciUyMCUzRCUyMFN0YWJsZURpZmZ1c2lvblhMSW1nMkltZ1BpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtcmVmaW5lci0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB1c2Vfc2FmZXRlbnNvcnMlM0RUcnVlJTJDJTIwdmFyaWFudCUzRCUyMmZwMTYlMjIlMEEpLnRvKCUyMmN1ZGElMjIp",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
<span class="hljs-keyword">import</span> torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>, torch_dtype=torch.float16, use_safetensors=<span class="hljs-literal">True</span>, variant=<span class="hljs-string">&quot;fp16&quot;</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),D=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFN0YWJsZURpZmZ1c2lvblhMUGlwZWxpbmUlMkMlMjBTdGFibGVEaWZmdXNpb25YTEltZzJJbWdQaXBlbGluZSUwQWltcG9ydCUyMHRvcmNoJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBTdGFibGVEaWZmdXNpb25YTFBpcGVsaW5lLmZyb21fc2luZ2xlX2ZpbGUoJTBBJTIwJTIwJTIwJTIwJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1iYXNlLTEuMCUyRmJsb2IlMkZtYWluJTJGc2RfeGxfYmFzZV8xLjAuc2FmZXRlbnNvcnMlMjIlMkMlMEElMjAlMjAlMjAlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMEEpLnRvKCUyMmN1ZGElMjIpJTBBJTBBcmVmaW5lciUyMCUzRCUyMFN0YWJsZURpZmZ1c2lvblhMSW1nMkltZ1BpcGVsaW5lLmZyb21fc2luZ2xlX2ZpbGUoJTBBJTIwJTIwJTIwJTIwJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1yZWZpbmVyLTEuMCUyRmJsb2IlMkZtYWluJTJGc2RfeGxfcmVmaW5lcl8xLjAuc2FmZXRlbnNvcnMlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMEEpLnRvKCUyMmN1ZGElMjIp",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
<span class="hljs-keyword">import</span> torch

pipeline = StableDiffusionXLPipeline.from_single_file(
    <span class="hljs-string">&quot;https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/sd_xl_base_1.0.safetensors&quot;</span>,
    torch_dtype=torch.float16
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

refiner = StableDiffusionXLImg2ImgPipeline.from_single_file(
    <span class="hljs-string">&quot;https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/blob/main/sd_xl_refiner_1.0.safetensors&quot;</span>, torch_dtype=torch.float16
).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),A=new T({props:{title:"Text-to-image",local:"text-to-image",headingTag:"h2"}}),K=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMEF1dG9QaXBlbGluZUZvclRleHQySW1hZ2UlMEFpbXBvcnQlMjB0b3JjaCUwQSUwQXBpcGVsaW5lX3RleHQyaW1hZ2UlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JUZXh0MkltYWdlLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUyQyUyMHVzZV9zYWZldGVuc29ycyUzRFRydWUlMEEpLnRvKCUyMmN1ZGElMjIpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyQXN0cm9uYXV0JTIwaW4lMjBhJTIwanVuZ2xlJTJDJTIwY29sZCUyMGNvbG9yJTIwcGFsZXR0ZSUyQyUyMG11dGVkJTIwY29sb3JzJTJDJTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmVfdGV4dDJpbWFnZShwcm9tcHQlM0Rwcm9tcHQpLmltYWdlcyU1QjAlNUQlMEFpbWFnZQ==",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForText2Image
<span class="hljs-keyword">import</span> torch

pipeline_text2image = AutoPipelineForText2Image.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>
image = pipeline_text2image(prompt=prompt).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),O=new T({props:{title:"Image-to-image",local:"image-to-image",headingTag:"h2"}}),te=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMEF1dG9QaXBlbGluZUZvckltYWdlMkltYWdlJTBBZnJvbSUyMGRpZmZ1c2Vycy51dGlscyUyMGltcG9ydCUyMGxvYWRfaW1hZ2UlMkMlMjBtYWtlX2ltYWdlX2dyaWQlMEElMEElMjMlMjB1c2UlMjBmcm9tX3BpcGUlMjB0byUyMGF2b2lkJTIwY29uc3VtaW5nJTIwYWRkaXRpb25hbCUyMG1lbW9yeSUyMHdoZW4lMjBsb2FkaW5nJTIwYSUyMGNoZWNrcG9pbnQlMEFwaXBlbGluZSUyMCUzRCUyMEF1dG9QaXBlbGluZUZvckltYWdlMkltYWdlLmZyb21fcGlwZShwaXBlbGluZV90ZXh0MmltYWdlKS50byglMjJjdWRhJTIyKSUwQSUwQXVybCUyMCUzRCUyMCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmh1Z2dpbmdmYWNlJTJGZG9jdW1lbnRhdGlvbi1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRmRpZmZ1c2VycyUyRnNkeGwtdGV4dDJpbWcucG5nJTIyJTBBaW5pdF9pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UodXJsKSUwQXByb21wdCUyMCUzRCUyMCUyMmElMjBkb2clMjBjYXRjaGluZyUyMGElMjBmcmlzYmVlJTIwaW4lMjB0aGUlMjBqdW5nbGUlMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUyQyUyMGltYWdlJTNEaW5pdF9pbWFnZSUyQyUyMHN0cmVuZ3RoJTNEMC44JTJDJTIwZ3VpZGFuY2Vfc2NhbGUlM0QxMC41KS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBpbWFnZSU1RCUyQyUyMHJvd3MlM0QxJTJDJTIwY29scyUzRDIp",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForImage2Image
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

<span class="hljs-comment"># use from_pipe to avoid consuming additional memory when loading a checkpoint</span>
pipeline = AutoPipelineForImage2Image.from_pipe(pipeline_text2image).to(<span class="hljs-string">&quot;cuda&quot;</span>)

url = <span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png&quot;</span>
init_image = load_image(url)
prompt = <span class="hljs-string">&quot;a dog catching a frisbee in the jungle&quot;</span>
image = pipeline(prompt, image=init_image, strength=<span class="hljs-number">0.8</span>, guidance_scale=<span class="hljs-number">10.5</span>).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),le=new T({props:{title:"Inpainting",local:"inpainting",headingTag:"h2"}}),ae=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMEF1dG9QaXBlbGluZUZvcklucGFpbnRpbmclMEFmcm9tJTIwZGlmZnVzZXJzLnV0aWxzJTIwaW1wb3J0JTIwbG9hZF9pbWFnZSUyQyUyMG1ha2VfaW1hZ2VfZ3JpZCUwQSUwQSUyMyUyMHVzZSUyMGZyb21fcGlwZSUyMHRvJTIwYXZvaWQlMjBjb25zdW1pbmclMjBhZGRpdGlvbmFsJTIwbWVtb3J5JTIwd2hlbiUyMGxvYWRpbmclMjBhJTIwY2hlY2twb2ludCUwQXBpcGVsaW5lJTIwJTNEJTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZy5mcm9tX3BpcGUocGlwZWxpbmVfdGV4dDJpbWFnZSkudG8oJTIyY3VkYSUyMiklMEElMEFpbWdfdXJsJTIwJTNEJTIwJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGc2R4bC10ZXh0MmltZy5wbmclMjIlMEFtYXNrX3VybCUyMCUzRCUyMCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmh1Z2dpbmdmYWNlJTJGZG9jdW1lbnRhdGlvbi1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRmRpZmZ1c2VycyUyRnNkeGwtaW5wYWludC1tYXNrLnBuZyUyMiUwQSUwQWluaXRfaW1hZ2UlMjAlM0QlMjBsb2FkX2ltYWdlKGltZ191cmwpJTBBbWFza19pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UobWFza191cmwpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyQSUyMGRlZXAlMjBzZWElMjBkaXZlciUyMGZsb2F0aW5nJTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBpbWFnZSUzRGluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSUyQyUyMHN0cmVuZ3RoJTNEMC44NSUyQyUyMGd1aWRhbmNlX3NjYWxlJTNEMTIuNSkuaW1hZ2VzJTVCMCU1RCUwQW1ha2VfaW1hZ2VfZ3JpZCglNUJpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUyQyUyMGltYWdlJTVEJTJDJTIwcm93cyUzRDElMkMlMjBjb2xzJTNEMyk=",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

<span class="hljs-comment"># use from_pipe to avoid consuming additional memory when loading a checkpoint</span>
pipeline = AutoPipelineForInpainting.from_pipe(pipeline_text2image).to(<span class="hljs-string">&quot;cuda&quot;</span>)

img_url = <span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-text2img.png&quot;</span>
mask_url = <span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/sdxl-inpaint-mask.png&quot;</span>

init_image = load_image(img_url)
mask_image = load_image(mask_url)

prompt = <span class="hljs-string">&quot;A deep sea diver floating&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=<span class="hljs-number">0.85</span>, guidance_scale=<span class="hljs-number">12.5</span>).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),ie=new T({props:{title:"Refine image quality",local:"refine-image-quality",headingTag:"h2"}}),pe=new T({props:{title:"Base + refiner model",local:"base--refiner-model",headingTag:"h3"}}),fe=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFiYXNlJTIwJTNEJTIwRGlmZnVzaW9uUGlwZWxpbmUuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1iYXNlLTEuMCUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTIwdXNlX3NhZmV0ZW5zb3JzJTNEVHJ1ZSUwQSkudG8oJTIyY3VkYSUyMiklMEElMEFyZWZpbmVyJTIwJTNEJTIwRGlmZnVzaW9uUGlwZWxpbmUuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1yZWZpbmVyLTEuMCUyMiUyQyUwQSUyMCUyMCUyMCUyMHRleHRfZW5jb2Rlcl8yJTNEYmFzZS50ZXh0X2VuY29kZXJfMiUyQyUwQSUyMCUyMCUyMCUyMHZhZSUzRGJhc2UudmFlJTJDJTBBJTIwJTIwJTIwJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBJTIwJTIwJTIwJTIwdXNlX3NhZmV0ZW5zb3JzJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTBBKS50byglMjJjdWRhJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline
<span class="hljs-keyword">import</span> torch

base = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

refiner = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>,
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=<span class="hljs-literal">True</span>,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),_=new Gl({props:{$$slots:{default:[Bs]},$$scope:{ctx:j}}}),ue=new b({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyQSUyMG1hamVzdGljJTIwbGlvbiUyMGp1bXBpbmclMjBmcm9tJTIwYSUyMGJpZyUyMHN0b25lJTIwYXQlMjBuaWdodCUyMiUwQSUwQWltYWdlJTIwJTNEJTIwYmFzZSglMEElMjAlMjAlMjAlMjBwcm9tcHQlM0Rwcm9tcHQlMkMlMEElMjAlMjAlMjAlMjBudW1faW5mZXJlbmNlX3N0ZXBzJTNENDAlMkMlMEElMjAlMjAlMjAlMjBkZW5vaXNpbmdfZW5kJTNEMC44JTJDJTBBJTIwJTIwJTIwJTIwb3V0cHV0X3R5cGUlM0QlMjJsYXRlbnQlMjIlMkMlMEEpLmltYWdlcyUwQWltYWdlJTIwJTNEJTIwcmVmaW5lciglMEElMjAlMjAlMjAlMjBwcm9tcHQlM0Rwcm9tcHQlMkMlMEElMjAlMjAlMjAlMjBudW1faW5mZXJlbmNlX3N0ZXBzJTNENDAlMkMlMEElMjAlMjAlMjAlMjBkZW5vaXNpbmdfc3RhcnQlM0QwLjglMkMlMEElMjAlMjAlMjAlMjBpbWFnZSUzRGltYWdlJTJDJTBBKS5pbWFnZXMlNUIwJTVEJTBBaW1hZ2U=",highlighted:`prompt = <span class="hljs-string">&quot;A majestic lion jumping from a big stone at night&quot;</span>

image = base(
    prompt=prompt,
    num_inference_steps=<span class="hljs-number">40</span>,
    denoising_end=<span class="hljs-number">0.8</span>,
    output_type=<span class="hljs-string">&quot;latent&quot;</span>,
).images
image = refiner(
    prompt=prompt,
    num_inference_steps=<span class="hljs-number">40</span>,
    denoising_start=<span class="hljs-number">0.8</span>,
    image=image,
).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),ye=new b({props:{code:"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",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLInpaintPipeline
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid
<span class="hljs-keyword">import</span> torch

base = StableDiffusionXLInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

refiner = StableDiffusionXLInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>,
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=<span class="hljs-literal">True</span>,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

img_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png&quot;</span>
mask_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png&quot;</span>

init_image = load_image(img_url)
mask_image = load_image(mask_url)

prompt = <span class="hljs-string">&quot;A majestic tiger sitting on a bench&quot;</span>
num_inference_steps = <span class="hljs-number">75</span>
high_noise_frac = <span class="hljs-number">0.7</span>

image = base(
    prompt=prompt,
    image=init_image,
    mask_image=mask_image,
    num_inference_steps=num_inference_steps,
    denoising_end=high_noise_frac,
    output_type=<span class="hljs-string">&quot;latent&quot;</span>,
).images
image = refiner(
    prompt=prompt,
    image=image,
    mask_image=mask_image,
    num_inference_steps=num_inference_steps,
    denoising_start=high_noise_frac,
).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image.resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),ge=new T({props:{title:"Base to refiner model",local:"base-to-refiner-model",headingTag:"h3"}}),Te=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFiYXNlJTIwJTNEJTIwRGlmZnVzaW9uUGlwZWxpbmUuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1iYXNlLTEuMCUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTIwdXNlX3NhZmV0ZW5zb3JzJTNEVHJ1ZSUwQSkudG8oJTIyY3VkYSUyMiklMEElMEFyZWZpbmVyJTIwJTNEJTIwRGlmZnVzaW9uUGlwZWxpbmUuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1yZWZpbmVyLTEuMCUyMiUyQyUwQSUyMCUyMCUyMCUyMHRleHRfZW5jb2Rlcl8yJTNEYmFzZS50ZXh0X2VuY29kZXJfMiUyQyUwQSUyMCUyMCUyMCUyMHZhZSUzRGJhc2UudmFlJTJDJTBBJTIwJTIwJTIwJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBJTIwJTIwJTIwJTIwdXNlX3NhZmV0ZW5zb3JzJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTBBKS50byglMjJjdWRhJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline
<span class="hljs-keyword">import</span> torch

base = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

refiner = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>,
    text_encoder_2=base.text_encoder_2,
    vae=base.vae,
    torch_dtype=torch.float16,
    use_safetensors=<span class="hljs-literal">True</span>,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),B=new Gl({props:{warning:!0,$$slots:{default:[ks]},$$scope:{ctx:j}}}),Ze=new b({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyQXN0cm9uYXV0JTIwaW4lMjBhJTIwanVuZ2xlJTJDJTIwY29sZCUyMGNvbG9yJTIwcGFsZXR0ZSUyQyUyMG11dGVkJTIwY29sb3JzJTJDJTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQSUwQWltYWdlJTIwJTNEJTIwYmFzZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBvdXRwdXRfdHlwZSUzRCUyMmxhdGVudCUyMikuaW1hZ2VzJTVCMCU1RA==",highlighted:`prompt = <span class="hljs-string">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>

image = base(prompt=prompt, output_type=<span class="hljs-string">&quot;latent&quot;</span>).images[<span class="hljs-number">0</span>]`,wrap:!1}}),je=new b({props:{code:"aW1hZ2UlMjAlM0QlMjByZWZpbmVyKHByb21wdCUzRHByb21wdCUyQyUyMGltYWdlJTNEaW1hZ2UlNUJOb25lJTJDJTIwJTNBJTVEKS5pbWFnZXMlNUIwJTVE",highlighted:'image = refiner(prompt=prompt, image=image[<span class="hljs-literal">None</span>, :]).images[<span class="hljs-number">0</span>]',wrap:!1}}),Ge=new T({props:{title:"Micro-conditioning",local:"micro-conditioning",headingTag:"h2"}}),X=new Gl({props:{$$slots:{default:[Xs]},$$scope:{ctx:j}}}),Ie=new T({props:{title:"Size conditioning",local:"size-conditioning",headingTag:"h3"}}),ke=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFN0YWJsZURpZmZ1c2lvblhMUGlwZWxpbmUlMEFpbXBvcnQlMjB0b3JjaCUwQSUwQXBpcGUlMjAlM0QlMjBTdGFibGVEaWZmdXNpb25YTFBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUyQyUyMHVzZV9zYWZldGVuc29ycyUzRFRydWUlMEEpLnRvKCUyMmN1ZGElMjIpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyQXN0cm9uYXV0JTIwaW4lMjBhJTIwanVuZ2xlJTJDJTIwY29sZCUyMGNvbG9yJTIwcGFsZXR0ZSUyQyUyMG11dGVkJTIwY29sb3JzJTJDJTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZSglMEElMjAlMjAlMjAlMjBwcm9tcHQlM0Rwcm9tcHQlMkMlMEElMjAlMjAlMjAlMjBuZWdhdGl2ZV9vcmlnaW5hbF9zaXplJTNEKDUxMiUyQyUyMDUxMiklMkMlMEElMjAlMjAlMjAlMjBuZWdhdGl2ZV90YXJnZXRfc2l6ZSUzRCgxMDI0JTJDJTIwMTAyNCklMkMlMEEpLmltYWdlcyU1QjAlNUQ=",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline
<span class="hljs-keyword">import</span> torch

pipe = StableDiffusionXLPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>
image = pipe(
    prompt=prompt,
    negative_original_size=(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),
    negative_target_size=(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>),
).images[<span class="hljs-number">0</span>]`,wrap:!1}}),Xe=new T({props:{title:"Crop conditioning",local:"crop-conditioning",headingTag:"h3"}}),Ce=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFN0YWJsZURpZmZ1c2lvblhMUGlwZWxpbmUlMEFpbXBvcnQlMjB0b3JjaCUwQSUwQXBpcGVsaW5lJTIwJTNEJTIwU3RhYmxlRGlmZnVzaW9uWExQaXBlbGluZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyc3RhYmlsaXR5YWklMkZzdGFibGUtZGlmZnVzaW9uLXhsLWJhc2UtMS4wJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTIwdmFyaWFudCUzRCUyMmZwMTYlMjIlMkMlMjB1c2Vfc2FmZXRlbnNvcnMlM0RUcnVlJTBBKS50byglMjJjdWRhJTIyKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMkFzdHJvbmF1dCUyMGluJTIwYSUyMGp1bmdsZSUyQyUyMGNvbGQlMjBjb2xvciUyMHBhbGV0dGUlMkMlMjBtdXRlZCUyMGNvbG9ycyUyQyUyMGRldGFpbGVkJTJDJTIwOGslMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUzRHByb21wdCUyQyUyMGNyb3BzX2Nvb3Jkc190b3BfbGVmdCUzRCgyNTYlMkMlMjAwKSkuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline
<span class="hljs-keyword">import</span> torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, crops_coords_top_left=(<span class="hljs-number">256</span>, <span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),Ve=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFN0YWJsZURpZmZ1c2lvblhMUGlwZWxpbmUlMEFpbXBvcnQlMjB0b3JjaCUwQSUwQXBpcGUlMjAlM0QlMjBTdGFibGVEaWZmdXNpb25YTFBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUyQyUyMHVzZV9zYWZldGVuc29ycyUzRFRydWUlMEEpLnRvKCUyMmN1ZGElMjIpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyQXN0cm9uYXV0JTIwaW4lMjBhJTIwanVuZ2xlJTJDJTIwY29sZCUyMGNvbG9yJTIwcGFsZXR0ZSUyQyUyMG11dGVkJTIwY29sb3JzJTJDJTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZSglMEElMjAlMjAlMjAlMjBwcm9tcHQlM0Rwcm9tcHQlMkMlMEElMjAlMjAlMjAlMjBuZWdhdGl2ZV9vcmlnaW5hbF9zaXplJTNEKDUxMiUyQyUyMDUxMiklMkMlMEElMjAlMjAlMjAlMjBuZWdhdGl2ZV9jcm9wc19jb29yZHNfdG9wX2xlZnQlM0QoMCUyQyUyMDApJTJDJTBBJTIwJTIwJTIwJTIwbmVnYXRpdmVfdGFyZ2V0X3NpemUlM0QoMTAyNCUyQyUyMDEwMjQpJTJDJTBBKS5pbWFnZXMlNUIwJTVEJTBBaW1hZ2U=",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline
<span class="hljs-keyword">import</span> torch

pipe = StableDiffusionXLPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>
image = pipe(
    prompt=prompt,
    negative_original_size=(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),
    negative_crops_coords_top_left=(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>),
    negative_target_size=(<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>),
).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),Ye=new T({props:{title:"Use a different prompt for each text-encoder",local:"use-a-different-prompt-for-each-text-encoder",headingTag:"h2"}}),Ee=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFN0YWJsZURpZmZ1c2lvblhMUGlwZWxpbmUlMEFpbXBvcnQlMjB0b3JjaCUwQSUwQXBpcGVsaW5lJTIwJTNEJTIwU3RhYmxlRGlmZnVzaW9uWExQaXBlbGluZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyc3RhYmlsaXR5YWklMkZzdGFibGUtZGlmZnVzaW9uLXhsLWJhc2UtMS4wJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTIwdmFyaWFudCUzRCUyMmZwMTYlMjIlMkMlMjB1c2Vfc2FmZXRlbnNvcnMlM0RUcnVlJTBBKS50byglMjJjdWRhJTIyKSUwQSUwQSUyMyUyMHByb21wdCUyMGlzJTIwcGFzc2VkJTIwdG8lMjBPQUklMjBDTElQLVZpVCUyRkwtMTQlMEFwcm9tcHQlMjAlM0QlMjAlMjJBc3Ryb25hdXQlMjBpbiUyMGElMjBqdW5nbGUlMkMlMjBjb2xkJTIwY29sb3IlMjBwYWxldHRlJTJDJTIwbXV0ZWQlMjBjb2xvcnMlMkMlMjBkZXRhaWxlZCUyQyUyMDhrJTIyJTBBJTIzJTIwcHJvbXB0XzIlMjBpcyUyMHBhc3NlZCUyMHRvJTIwT3BlbkNMSVAtVmlUJTJGYmlnRy0xNCUwQXByb21wdF8yJTIwJTNEJTIwJTIyVmFuJTIwR29naCUyMHBhaW50aW5nJTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBwcm9tcHRfMiUzRHByb21wdF8yKS5pbWFnZXMlNUIwJTVEJTBBaW1hZ2U=",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionXLPipeline
<span class="hljs-keyword">import</span> torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

<span class="hljs-comment"># prompt is passed to OAI CLIP-ViT/L-14</span>
prompt = <span class="hljs-string">&quot;Astronaut in a jungle, cold color palette, muted colors, detailed, 8k&quot;</span>
<span class="hljs-comment"># prompt_2 is passed to OpenCLIP-ViT/bigG-14</span>
prompt_2 = <span class="hljs-string">&quot;Van Gogh painting&quot;</span>
image = pipeline(prompt=prompt, prompt_2=prompt_2).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),Qe=new T({props:{title:"Optimizations",local:"optimizations",headingTag:"h2"}}),He=new b({props:{code:"LSUyMGJhc2UudG8oJTIyY3VkYSUyMiklMEEtJTIwcmVmaW5lci50byglMjJjdWRhJTIyKSUwQSUyQiUyMGJhc2UuZW5hYmxlX21vZGVsX2NwdV9vZmZsb2FkKCklMEElMkIlMjByZWZpbmVyLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgp",highlighted:`<span class="hljs-deletion">- base.to(&quot;cuda&quot;)</span>
<span class="hljs-deletion">- refiner.to(&quot;cuda&quot;)</span>
<span class="hljs-addition">+ base.enable_model_cpu_offload()</span>
<span class="hljs-addition">+ refiner.enable_model_cpu_offload()</span>`,wrap:!1}}),ze=new b({props:{code:"JTJCJTIwYmFzZS51bmV0JTIwJTNEJTIwdG9yY2guY29tcGlsZShiYXNlLnVuZXQlMkMlMjBtb2RlJTNEJTIycmVkdWNlLW92ZXJoZWFkJTIyJTJDJTIwZnVsbGdyYXBoJTNEVHJ1ZSklMEElMkIlMjByZWZpbmVyLnVuZXQlMjAlM0QlMjB0b3JjaC5jb21waWxlKHJlZmluZXIudW5ldCUyQyUyMG1vZGUlM0QlMjJyZWR1Y2Utb3ZlcmhlYWQlMjIlMkMlMjBmdWxsZ3JhcGglM0RUcnVlKQ==",highlighted:`<span class="hljs-addition">+ base.unet = torch.compile(base.unet, mode=&quot;reduce-overhead&quot;, fullgraph=True)</span>
<span class="hljs-addition">+ refiner.unet = torch.compile(refiner.unet, mode=&quot;reduce-overhead&quot;, fullgraph=True)</span>`,wrap:!1}}),qe=new b({props:{code:"JTJCJTIwYmFzZS5lbmFibGVfeGZvcm1lcnNfbWVtb3J5X2VmZmljaWVudF9hdHRlbnRpb24oKSUwQSUyQiUyMHJlZmluZXIuZW5hYmxlX3hmb3JtZXJzX21lbW9yeV9lZmZpY2llbnRfYXR0ZW50aW9uKCk=",highlighted:`<span class="hljs-addition">+ base.enable_xformers_memory_efficient_attention()</span>
<span class="hljs-addition">+ refiner.enable_xformers_memory_efficient_attention()</span>`,wrap:!1}}),De=new T({props:{title:"Other resources",local:"other-resources",headingTag:"h2"}}),Pe=new _s({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/using-diffusers/sdxl.md"}}),{c(){r=n("meta"),J=a(),y=n("p"),h=a(),m(w.$$.fragment),g=a(),m(U.$$.fragment),Oe=a(),S=n("p"),S.innerHTML=Il,et=a(),E=n("ol"),E.innerHTML=_l,tt=a(),N=n("p"),N.textContent=$l,lt=a(),Q=n("p"),Q.textContent=Bl,st=a(),m(F.$$.fragment),at=a(),m(W.$$.fragment),it=a(),m(L.$$.fragment),nt=a(),H=n("p"),H.innerHTML=kl,ot=a(),m(z.$$.fragment),pt=a(),q=n("p"),q.innerHTML=Xl,rt=a(),m(D.$$.fragment),mt=a(),m(A.$$.fragment),ft=a(),P=n("p"),P.innerHTML=xl,dt=a(),m(K.$$.fragment),ct=a(),G=n("div"),G.innerHTML=Cl,ut=a(),m(O.$$.fragment),Mt=a(),ee=n("p"),ee.textContent=Rl,yt=a(),m(te.$$.fragment),bt=a(),v=n("div"),v.innerHTML=Vl,gt=a(),m(le.$$.fragment),ht=a(),se=n("p"),se.textContent=Yl,Jt=a(),m(ae.$$.fragment),Tt=a(),I=n("div"),I.innerHTML=Sl,wt=a(),m(ie.$$.fragment),Zt=a(),ne=n("p"),ne.innerHTML=El,Ut=a(),oe=n("ol"),oe.innerHTML=Nl,jt=a(),m(pe.$$.fragment),Wt=a(),re=n("p"),re.innerHTML=Ql,Gt=a(),me=n("p"),me.textContent=Fl,vt=a(),m(fe.$$.fragment),It=a(),de=n("p"),de.innerHTML=Ll,_t=a(),m(_.$$.fragment),$t=a(),ce=n("p"),ce.innerHTML=Hl,Bt=a(),m(ue.$$.fragment),kt=a(),$=n("div"),$.innerHTML=zl,Xt=a(),Me=n("p"),Me.innerHTML=ql,xt=a(),m(ye.$$.fragment),Ct=a(),be=n("p"),be.textContent=Dl,Rt=a(),m(ge.$$.fragment),Vt=a(),he=n("p"),he.textContent=Al,Yt=a(),Je=n("p"),Je.textContent=Pl,St=a(),m(Te.$$.fragment),Et=a(),m(B.$$.fragment),Nt=a(),we=n("p"),we.innerHTML=Kl,Qt=a(),m(Ze.$$.fragment),Ft=a(),Ue=n("p"),Ue.textContent=Ol,Lt=a(),m(je.$$.fragment),Ht=a(),k=n("div"),k.innerHTML=es,zt=a(),We=n("p"),We.innerHTML=ts,qt=a(),m(Ge.$$.fragment),Dt=a(),ve=n("p"),ve.innerHTML=ls,At=a(),m(X.$$.fragment),Pt=a(),m(Ie.$$.fragment),Kt=a(),_e=n("p"),_e.textContent=ss,Ot=a(),$e=n("ul"),$e.innerHTML=as,el=a(),Be=n("p"),Be.textContent=is,tl=a(),m(ke.$$.fragment),ll=a(),x=n("div"),x.innerHTML=ns,sl=a(),m(Xe.$$.fragment),al=a(),xe=n("p"),xe.innerHTML=os,il=a(),m(Ce.$$.fragment),nl=a(),C=n("div"),C.innerHTML=ps,ol=a(),Re=n("p"),Re.textContent=rs,pl=a(),m(Ve.$$.fragment),rl=a(),m(Ye.$$.fragment),ml=a(),Se=n("p"),Se.innerHTML=ms,fl=a(),m(Ee.$$.fragment),dl=a(),R=n("div"),R.innerHTML=fs,cl=a(),Ne=n("p"),Ne.innerHTML=ds,ul=a(),m(Qe.$$.fragment),Ml=a(),Fe=n("p"),Fe.textContent=cs,yl=a(),Le=n("ol"),Le.innerHTML=us,bl=a(),m(He.$$.fragment),gl=a(),V=n("ol"),V.innerHTML=Ms,hl=a(),m(ze.$$.fragment),Jl=a(),Y=n("ol"),Y.innerHTML=ys,Tl=a(),m(qe.$$.fragment),wl=a(),m(De.$$.fragment),Zl=a(),Ae=n("p"),Ae.innerHTML=bs,Ul=a(),m(Pe.$$.fragment),jl=a(),Ke=n("p"),this.h()},l(e){const t=Gs("svelte-u9bgzb",document.head);r=o(t,"META",{name:!0,content:!0}),t.forEach(l),J=i(e),y=o(e,"P",{}),ws(y).forEach(l),h=i(e),f(w.$$.fragment,e),g=i(e),f(U.$$.fragment,e),Oe=i(e),S=o(e,"P",{"data-svelte-h":!0}),p(S)!=="svelte-8e6ihk"&&(S.innerHTML=Il),et=i(e),E=o(e,"OL",{"data-svelte-h":!0}),p(E)!=="svelte-kzd5ve"&&(E.innerHTML=_l),tt=i(e),N=o(e,"P",{"data-svelte-h":!0}),p(N)!=="svelte-1dmebl2"&&(N.textContent=$l),lt=i(e),Q=o(e,"P",{"data-svelte-h":!0}),p(Q)!=="svelte-cwruts"&&(Q.textContent=Bl),st=i(e),f(F.$$.fragment,e),at=i(e),f(W.$$.fragment,e),it=i(e),f(L.$$.fragment,e),nt=i(e),H=o(e,"P",{"data-svelte-h":!0}),p(H)!=="svelte-qmwuv"&&(H.innerHTML=kl),ot=i(e),f(z.$$.fragment,e),pt=i(e),q=o(e,"P",{"data-svelte-h":!0}),p(q)!=="svelte-u81qk1"&&(q.innerHTML=Xl),rt=i(e),f(D.$$.fragment,e),mt=i(e),f(A.$$.fragment,e),ft=i(e),P=o(e,"P",{"data-svelte-h":!0}),p(P)!=="svelte-14g8zj2"&&(P.innerHTML=xl),dt=i(e),f(K.$$.fragment,e),ct=i(e),G=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(G)!=="svelte-olxauf"&&(G.innerHTML=Cl),ut=i(e),f(O.$$.fragment,e),Mt=i(e),ee=o(e,"P",{"data-svelte-h":!0}),p(ee)!=="svelte-1wfw5z2"&&(ee.textContent=Rl),yt=i(e),f(te.$$.fragment,e),bt=i(e),v=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(v)!=="svelte-qmwul6"&&(v.innerHTML=Vl),gt=i(e),f(le.$$.fragment,e),ht=i(e),se=o(e,"P",{"data-svelte-h":!0}),p(se)!=="svelte-9ro4ak"&&(se.textContent=Yl),Jt=i(e),f(ae.$$.fragment,e),Tt=i(e),I=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(I)!=="svelte-oeht90"&&(I.innerHTML=Sl),wt=i(e),f(ie.$$.fragment,e),Zt=i(e),ne=o(e,"P",{"data-svelte-h":!0}),p(ne)!=="svelte-c9rvzh"&&(ne.innerHTML=El),Ut=i(e),oe=o(e,"OL",{"data-svelte-h":!0}),p(oe)!=="svelte-11dgpwz"&&(oe.innerHTML=Nl),jt=i(e),f(pe.$$.fragment,e),Wt=i(e),re=o(e,"P",{"data-svelte-h":!0}),p(re)!=="svelte-13hawme"&&(re.innerHTML=Ql),Gt=i(e),me=o(e,"P",{"data-svelte-h":!0}),p(me)!=="svelte-ytk0zd"&&(me.textContent=Fl),vt=i(e),f(fe.$$.fragment,e),It=i(e),de=o(e,"P",{"data-svelte-h":!0}),p(de)!=="svelte-fh96ip"&&(de.innerHTML=Ll),_t=i(e),f(_.$$.fragment,e),$t=i(e),ce=o(e,"P",{"data-svelte-h":!0}),p(ce)!=="svelte-6bxxkd"&&(ce.innerHTML=Hl),Bt=i(e),f(ue.$$.fragment,e),kt=i(e),$=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p($)!=="svelte-1nh65b"&&($.innerHTML=zl),Xt=i(e),Me=o(e,"P",{"data-svelte-h":!0}),p(Me)!=="svelte-c8hi8d"&&(Me.innerHTML=ql),xt=i(e),f(ye.$$.fragment,e),Ct=i(e),be=o(e,"P",{"data-svelte-h":!0}),p(be)!=="svelte-1x3hdt3"&&(be.textContent=Dl),Rt=i(e),f(ge.$$.fragment,e),Vt=i(e),he=o(e,"P",{"data-svelte-h":!0}),p(he)!=="svelte-1t0l7j9"&&(he.textContent=Al),Yt=i(e),Je=o(e,"P",{"data-svelte-h":!0}),p(Je)!=="svelte-1ct6jhk"&&(Je.textContent=Pl),St=i(e),f(Te.$$.fragment,e),Et=i(e),f(B.$$.fragment,e),Nt=i(e),we=o(e,"P",{"data-svelte-h":!0}),p(we)!=="svelte-10ioafw"&&(we.innerHTML=Kl),Qt=i(e),f(Ze.$$.fragment,e),Ft=i(e),Ue=o(e,"P",{"data-svelte-h":!0}),p(Ue)!=="svelte-ht9d3m"&&(Ue.textContent=Ol),Lt=i(e),f(je.$$.fragment,e),Ht=i(e),k=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(k)!=="svelte-1u8njyh"&&(k.innerHTML=es),zt=i(e),We=o(e,"P",{"data-svelte-h":!0}),p(We)!=="svelte-1bco5ve"&&(We.innerHTML=ts),qt=i(e),f(Ge.$$.fragment,e),Dt=i(e),ve=o(e,"P",{"data-svelte-h":!0}),p(ve)!=="svelte-1jtnlpo"&&(ve.innerHTML=ls),At=i(e),f(X.$$.fragment,e),Pt=i(e),f(Ie.$$.fragment,e),Kt=i(e),_e=o(e,"P",{"data-svelte-h":!0}),p(_e)!=="svelte-h89lzu"&&(_e.textContent=ss),Ot=i(e),$e=o(e,"UL",{"data-svelte-h":!0}),p($e)!=="svelte-bqvi0g"&&($e.innerHTML=as),el=i(e),Be=o(e,"P",{"data-svelte-h":!0}),p(Be)!=="svelte-2b2q2"&&(Be.textContent=is),tl=i(e),f(ke.$$.fragment,e),ll=i(e),x=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(x)!=="svelte-thc7vn"&&(x.innerHTML=ns),sl=i(e),f(Xe.$$.fragment,e),al=i(e),xe=o(e,"P",{"data-svelte-h":!0}),p(xe)!=="svelte-14lnf5x"&&(xe.innerHTML=os),il=i(e),f(Ce.$$.fragment,e),nl=i(e),C=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(C)!=="svelte-167e9h5"&&(C.innerHTML=ps),ol=i(e),Re=o(e,"P",{"data-svelte-h":!0}),p(Re)!=="svelte-f4u8tr"&&(Re.textContent=rs),pl=i(e),f(Ve.$$.fragment,e),rl=i(e),f(Ye.$$.fragment,e),ml=i(e),Se=o(e,"P",{"data-svelte-h":!0}),p(Se)!=="svelte-189in7b"&&(Se.innerHTML=ms),fl=i(e),f(Ee.$$.fragment,e),dl=i(e),R=o(e,"DIV",{class:!0,"data-svelte-h":!0}),p(R)!=="svelte-1h8rgz0"&&(R.innerHTML=fs),cl=i(e),Ne=o(e,"P",{"data-svelte-h":!0}),p(Ne)!=="svelte-5rqyoz"&&(Ne.innerHTML=ds),ul=i(e),f(Qe.$$.fragment,e),Ml=i(e),Fe=o(e,"P",{"data-svelte-h":!0}),p(Fe)!=="svelte-1a85yi5"&&(Fe.textContent=cs),yl=i(e),Le=o(e,"OL",{"data-svelte-h":!0}),p(Le)!=="svelte-dwwg8o"&&(Le.innerHTML=us),bl=i(e),f(He.$$.fragment,e),gl=i(e),V=o(e,"OL",{start:!0,"data-svelte-h":!0}),p(V)!=="svelte-wmj8zo"&&(V.innerHTML=Ms),hl=i(e),f(ze.$$.fragment,e),Jl=i(e),Y=o(e,"OL",{start:!0,"data-svelte-h":!0}),p(Y)!=="svelte-fvjjw8"&&(Y.innerHTML=ys),Tl=i(e),f(qe.$$.fragment,e),wl=i(e),f(De.$$.fragment,e),Zl=i(e),Ae=o(e,"P",{"data-svelte-h":!0}),p(Ae)!=="svelte-1jv4asr"&&(Ae.innerHTML=bs),Ul=i(e),f(Pe.$$.fragment,e),jl=i(e),Ke=o(e,"P",{}),ws(Ke).forEach(l),this.h()},h(){Z(r,"name","hf:doc:metadata"),Z(r,"content",Cs),Z(G,"class","flex justify-center"),Z(v,"class","flex justify-center"),Z(I,"class","flex justify-center"),Z($,"class","flex gap-4"),Z(k,"class","flex gap-4"),Z(x,"class","flex flex-col justify-center"),Z(C,"class","flex justify-center"),Z(R,"class","flex justify-center"),Z(V,"start","2"),Z(Y,"start","3")},m(e,t){vs(document.head,r),s(e,J,t),s(e,y,t),s(e,h,t),d(w,e,t),s(e,g,t),d(U,e,t),s(e,Oe,t),s(e,S,t),s(e,et,t),s(e,E,t),s(e,tt,t),s(e,N,t),s(e,lt,t),s(e,Q,t),s(e,st,t),d(F,e,t),s(e,at,t),d(W,e,t),s(e,it,t),d(L,e,t),s(e,nt,t),s(e,H,t),s(e,ot,t),d(z,e,t),s(e,pt,t),s(e,q,t),s(e,rt,t),d(D,e,t),s(e,mt,t),d(A,e,t),s(e,ft,t),s(e,P,t),s(e,dt,t),d(K,e,t),s(e,ct,t),s(e,G,t),s(e,ut,t),d(O,e,t),s(e,Mt,t),s(e,ee,t),s(e,yt,t),d(te,e,t),s(e,bt,t),s(e,v,t),s(e,gt,t),d(le,e,t),s(e,ht,t),s(e,se,t),s(e,Jt,t),d(ae,e,t),s(e,Tt,t),s(e,I,t),s(e,wt,t),d(ie,e,t),s(e,Zt,t),s(e,ne,t),s(e,Ut,t),s(e,oe,t),s(e,jt,t),d(pe,e,t),s(e,Wt,t),s(e,re,t),s(e,Gt,t),s(e,me,t),s(e,vt,t),d(fe,e,t),s(e,It,t),s(e,de,t),s(e,_t,t),d(_,e,t),s(e,$t,t),s(e,ce,t),s(e,Bt,t),d(ue,e,t),s(e,kt,t),s(e,$,t),s(e,Xt,t),s(e,Me,t),s(e,xt,t),d(ye,e,t),s(e,Ct,t),s(e,be,t),s(e,Rt,t),d(ge,e,t),s(e,Vt,t),s(e,he,t),s(e,Yt,t),s(e,Je,t),s(e,St,t),d(Te,e,t),s(e,Et,t),d(B,e,t),s(e,Nt,t),s(e,we,t),s(e,Qt,t),d(Ze,e,t),s(e,Ft,t),s(e,Ue,t),s(e,Lt,t),d(je,e,t),s(e,Ht,t),s(e,k,t),s(e,zt,t),s(e,We,t),s(e,qt,t),d(Ge,e,t),s(e,Dt,t),s(e,ve,t),s(e,At,t),d(X,e,t),s(e,Pt,t),d(Ie,e,t),s(e,Kt,t),s(e,_e,t),s(e,Ot,t),s(e,$e,t),s(e,el,t),s(e,Be,t),s(e,tl,t),d(ke,e,t),s(e,ll,t),s(e,x,t),s(e,sl,t),d(Xe,e,t),s(e,al,t),s(e,xe,t),s(e,il,t),d(Ce,e,t),s(e,nl,t),s(e,C,t),s(e,ol,t),s(e,Re,t),s(e,pl,t),d(Ve,e,t),s(e,rl,t),d(Ye,e,t),s(e,ml,t),s(e,Se,t),s(e,fl,t),d(Ee,e,t),s(e,dl,t),s(e,R,t),s(e,cl,t),s(e,Ne,t),s(e,ul,t),d(Qe,e,t),s(e,Ml,t),s(e,Fe,t),s(e,yl,t),s(e,Le,t),s(e,bl,t),d(He,e,t),s(e,gl,t),s(e,V,t),s(e,hl,t),d(ze,e,t),s(e,Jl,t),s(e,Y,t),s(e,Tl,t),d(qe,e,t),s(e,wl,t),d(De,e,t),s(e,Zl,t),s(e,Ae,t),s(e,Ul,t),d(Pe,e,t),s(e,jl,t),s(e,Ke,t),Wl=!0},p(e,[t]){const gs={};t&2&&(gs.$$scope={dirty:t,ctx:e}),W.$set(gs);const hs={};t&2&&(hs.$$scope={dirty:t,ctx:e}),_.$set(hs);const Js={};t&2&&(Js.$$scope={dirty:t,ctx:e}),B.$set(Js);const Ts={};t&2&&(Ts.$$scope={dirty:t,ctx:e}),X.$set(Ts)},i(e){Wl||(c(w.$$.fragment,e),c(U.$$.fragment,e),c(F.$$.fragment,e),c(W.$$.fragment,e),c(L.$$.fragment,e),c(z.$$.fragment,e),c(D.$$.fragment,e),c(A.$$.fragment,e),c(K.$$.fragment,e),c(O.$$.fragment,e),c(te.$$.fragment,e),c(le.$$.fragment,e),c(ae.$$.fragment,e),c(ie.$$.fragment,e),c(pe.$$.fragment,e),c(fe.$$.fragment,e),c(_.$$.fragment,e),c(ue.$$.fragment,e),c(ye.$$.fragment,e),c(ge.$$.fragment,e),c(Te.$$.fragment,e),c(B.$$.fragment,e),c(Ze.$$.fragment,e),c(je.$$.fragment,e),c(Ge.$$.fragment,e),c(X.$$.fragment,e),c(Ie.$$.fragment,e),c(ke.$$.fragment,e),c(Xe.$$.fragment,e),c(Ce.$$.fragment,e),c(Ve.$$.fragment,e),c(Ye.$$.fragment,e),c(Ee.$$.fragment,e),c(Qe.$$.fragment,e),c(He.$$.fragment,e),c(ze.$$.fragment,e),c(qe.$$.fragment,e),c(De.$$.fragment,e),c(Pe.$$.fragment,e),Wl=!0)},o(e){u(w.$$.fragment,e),u(U.$$.fragment,e),u(F.$$.fragment,e),u(W.$$.fragment,e),u(L.$$.fragment,e),u(z.$$.fragment,e),u(D.$$.fragment,e),u(A.$$.fragment,e),u(K.$$.fragment,e),u(O.$$.fragment,e),u(te.$$.fragment,e),u(le.$$.fragment,e),u(ae.$$.fragment,e),u(ie.$$.fragment,e),u(pe.$$.fragment,e),u(fe.$$.fragment,e),u(_.$$.fragment,e),u(ue.$$.fragment,e),u(ye.$$.fragment,e),u(ge.$$.fragment,e),u(Te.$$.fragment,e),u(B.$$.fragment,e),u(Ze.$$.fragment,e),u(je.$$.fragment,e),u(Ge.$$.fragment,e),u(X.$$.fragment,e),u(Ie.$$.fragment,e),u(ke.$$.fragment,e),u(Xe.$$.fragment,e),u(Ce.$$.fragment,e),u(Ve.$$.fragment,e),u(Ye.$$.fragment,e),u(Ee.$$.fragment,e),u(Qe.$$.fragment,e),u(He.$$.fragment,e),u(ze.$$.fragment,e),u(qe.$$.fragment,e),u(De.$$.fragment,e),u(Pe.$$.fragment,e),Wl=!1},d(e){e&&(l(J),l(y),l(h),l(g),l(Oe),l(S),l(et),l(E),l(tt),l(N),l(lt),l(Q),l(st),l(at),l(it),l(nt),l(H),l(ot),l(pt),l(q),l(rt),l(mt),l(ft),l(P),l(dt),l(ct),l(G),l(ut),l(Mt),l(ee),l(yt),l(bt),l(v),l(gt),l(ht),l(se),l(Jt),l(Tt),l(I),l(wt),l(Zt),l(ne),l(Ut),l(oe),l(jt),l(Wt),l(re),l(Gt),l(me),l(vt),l(It),l(de),l(_t),l($t),l(ce),l(Bt),l(kt),l($),l(Xt),l(Me),l(xt),l(Ct),l(be),l(Rt),l(Vt),l(he),l(Yt),l(Je),l(St),l(Et),l(Nt),l(we),l(Qt),l(Ft),l(Ue),l(Lt),l(Ht),l(k),l(zt),l(We),l(qt),l(Dt),l(ve),l(At),l(Pt),l(Kt),l(_e),l(Ot),l($e),l(el),l(Be),l(tl),l(ll),l(x),l(sl),l(al),l(xe),l(il),l(nl),l(C),l(ol),l(Re),l(pl),l(rl),l(ml),l(Se),l(fl),l(dl),l(R),l(cl),l(Ne),l(ul),l(Ml),l(Fe),l(yl),l(Le),l(bl),l(gl),l(V),l(hl),l(Jl),l(Y),l(Tl),l(wl),l(Zl),l(Ae),l(Ul),l(jl),l(Ke)),l(r),M(w,e),M(U,e),M(F,e),M(W,e),M(L,e),M(z,e),M(D,e),M(A,e),M(K,e),M(O,e),M(te,e),M(le,e),M(ae,e),M(ie,e),M(pe,e),M(fe,e),M(_,e),M(ue,e),M(ye,e),M(ge,e),M(Te,e),M(B,e),M(Ze,e),M(je,e),M(Ge,e),M(X,e),M(Ie,e),M(ke,e),M(Xe,e),M(Ce,e),M(Ve,e),M(Ye,e),M(Ee,e),M(Qe,e),M(He,e),M(ze,e),M(qe,e),M(De,e),M(Pe,e)}}}const Cs='{"title":"Stable Diffusion XL","local":"stable-diffusion-xl","sections":[{"title":"Load model checkpoints","local":"load-model-checkpoints","sections":[],"depth":2},{"title":"Text-to-image","local":"text-to-image","sections":[],"depth":2},{"title":"Image-to-image","local":"image-to-image","sections":[],"depth":2},{"title":"Inpainting","local":"inpainting","sections":[],"depth":2},{"title":"Refine image quality","local":"refine-image-quality","sections":[{"title":"Base + refiner model","local":"base--refiner-model","sections":[],"depth":3},{"title":"Base to refiner model","local":"base-to-refiner-model","sections":[],"depth":3}],"depth":2},{"title":"Micro-conditioning","local":"micro-conditioning","sections":[{"title":"Size conditioning","local":"size-conditioning","sections":[],"depth":3},{"title":"Crop conditioning","local":"crop-conditioning","sections":[],"depth":3}],"depth":2},{"title":"Use a different prompt for each text-encoder","local":"use-a-different-prompt-for-each-text-encoder","sections":[],"depth":2},{"title":"Optimizations","local":"optimizations","sections":[],"depth":2},{"title":"Other resources","local":"other-resources","sections":[],"depth":2}],"depth":1}';function Rs(j){return Us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fs extends js{constructor(r){super(),Ws(this,r,Rs,xs,Zs,{})}}export{Fs as component};
