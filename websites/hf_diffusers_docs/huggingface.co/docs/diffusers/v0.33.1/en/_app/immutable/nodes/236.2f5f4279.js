import{s as vt,o as xt,n as Bt}from"../chunks/scheduler.8c3d61f6.js";import{S as Rt,i as Ht,g as r,s as n,r as m,A as Yt,h as d,f as a,c as o,j as It,u,x as p,k as Gt,y as Ct,a as l,v as c,d as f,t as M,w as h}from"../chunks/index.da70eac4.js";import{T as Xt}from"../chunks/Tip.1d9b8c37.js";import{C as N}from"../chunks/CodeBlock.a9c4becf.js";import{H as Mt,E as Wt}from"../chunks/index.5d4ab994.js";function zt(q){let s,g='ðŸ’¡ Learn more about how to create an image dataset for training in the <a href="https://huggingface.co/docs/datasets/image_dataset" rel="nofollow">Create an image dataset</a> guide.';return{c(){s=r("p"),s.innerHTML=g},l(i){s=d(i,"P",{"data-svelte-h":!0}),p(s)!=="svelte-yz61dz"&&(s.innerHTML=g)},m(i,y){l(i,s,y)},p:Bt,d(i){i&&a(s)}}}function Ft(q){let s,g='ðŸ’¡ For more details and context about creating and uploading a dataset to the Hub, take a look at the <a href="https://huggingface.co/blog/image-search-datasets" rel="nofollow">Image search with ðŸ¤— Datasets</a> post.';return{c(){s=r("p"),s.innerHTML=g},l(i){s=d(i,"P",{"data-svelte-h":!0}),p(s)!=="svelte-1wagfs8"&&(s.innerHTML=g)},m(i,y){l(i,s,y)},p:Bt,d(i){i&&a(s)}}}function qt(q){let s,g,i,y,J,L,w,ht='There are many datasets on the <a href="https://huggingface.co/datasets?task_categories=task_categories:text-to-image&amp;sort=downloads" rel="nofollow">Hub</a> to train a model on, but if you canâ€™t find one youâ€™re interested in or want to use your own, you can create a dataset with the ðŸ¤— <a href="https://huggingface.co/docs/datasets" rel="nofollow">Datasets</a> library. The dataset structure depends on the task you want to train your model on. The most basic dataset structure is a directory of images for tasks like unconditional image generation. Another dataset structure may be a directory of images and a text file containing their corresponding text captions for tasks like text-to-image generation.',Q,j,gt="This guide will show you two ways to create a dataset to finetune on:",A,_,yt="<li>provide a folder of images to the <code>--train_data_dir</code> argument</li> <li>upload a dataset to the Hub and pass the dataset repository id to the <code>--dataset_name</code> argument</li>",V,T,S,Z,P,b,Tt='For unconditional generation, you can provide your own dataset as a folder of images. The training script uses the <a href="https://huggingface.co/docs/datasets/en/image_dataset#imagefolder" rel="nofollow"><code>ImageFolder</code></a> builder from ðŸ¤— Datasets to automatically build a dataset from the folder. Your directory structure should look like:',D,U,K,k,$t="Pass the path to the dataset directory to the <code>--train_data_dir</code> argument, and then you can start training:",O,I,tt,G,et,$,at,X,Jt='Start by creating a dataset with the <a href="https://huggingface.co/docs/datasets/image_load#imagefolder" rel="nofollow"><code>ImageFolder</code></a> feature, which creates an <code>image</code> column containing the PIL-encoded images.',lt,B,wt="You can use the <code>data_dir</code> or <code>data_files</code> parameters to specify the location of the dataset. The <code>data_files</code> parameter supports mapping specific files to dataset splits like <code>train</code> or <code>test</code>:",st,v,nt,x,jt='Then use the <a href="https://huggingface.co/docs/datasets/v3.5.0/en/package_reference/main_classes#datasets.Dataset.push_to_hub" rel="nofollow">push_to_hub</a> method to upload the dataset to the Hub:',ot,R,it,H,_t="Now the dataset is available for training by passing the dataset name to the <code>--dataset_name</code> argument:",rt,Y,dt,C,pt,W,Zt="Now that youâ€™ve created a dataset, you can plug it into the <code>train_data_dir</code> (if your dataset is local) or <code>dataset_name</code> (if your dataset is on the Hub) arguments of a training script.",mt,z,bt='For your next steps, feel free to try and use your dataset to train a model for <a href="unconditional_training">unconditional generation</a> or <a href="text2image">text-to-image generation</a>!',ut,F,ct,E,ft;return J=new Mt({props:{title:"Create a dataset for training",local:"create-a-dataset-for-training",headingTag:"h1"}}),T=new Xt({props:{$$slots:{default:[zt]},$$scope:{ctx:q}}}),Z=new Mt({props:{title:"Provide a dataset as a folder",local:"provide-a-dataset-as-a-folder",headingTag:"h2"}}),U=new N({props:{code:"ZGF0YV9kaXIlMkZ4eHgucG5nJTBBZGF0YV9kaXIlMkZ4eHkucG5nJTBBZGF0YV9kaXIlMkYlNUIuLi4lNUQlMkZ4eHoucG5n",highlighted:`data_dir/xxx.png
data_dir/xxy.png
data_dir/[...]/xxz.png`,wrap:!1}}),I=new N({props:{code:"YWNjZWxlcmF0ZSUyMGxhdW5jaCUyMHRyYWluX3VuY29uZGl0aW9uYWwucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRyYWluX2RhdGFfZGlyJTIwJTNDcGF0aC10by10cmFpbi1kaXJlY3RvcnklM0UlMjAlNUMlMEElMjAlMjAlMjAlMjAlM0NvdGhlci1hcmd1bWVudHMlM0U=",highlighted:`accelerate launch train_unconditional.py \\
    --train_data_dir &lt;path-to-train-directory&gt; \\
    &lt;other-arguments&gt;`,wrap:!1}}),G=new Mt({props:{title:"Upload your data to the Hub",local:"upload-your-data-to-the-hub",headingTag:"h2"}}),$=new Xt({props:{$$slots:{default:[Ft]},$$scope:{ctx:q}}}),v=new N({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBJTIzJTIwZXhhbXBsZSUyMDElM0ElMjBsb2NhbCUyMGZvbGRlciUwQWRhdGFzZXQlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyaW1hZ2Vmb2xkZXIlMjIlMkMlMjBkYXRhX2RpciUzRCUyMnBhdGhfdG9feW91cl9mb2xkZXIlMjIpJTBBJTBBJTIzJTIwZXhhbXBsZSUyMDIlM0ElMjBsb2NhbCUyMGZpbGVzJTIwKHN1cHBvcnRlZCUyMGZvcm1hdHMlMjBhcmUlMjB0YXIlMkMlMjBnemlwJTJDJTIwemlwJTJDJTIweHolMkMlMjByYXIlMkMlMjB6c3RkKSUwQWRhdGFzZXQlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyaW1hZ2Vmb2xkZXIlMjIlMkMlMjBkYXRhX2ZpbGVzJTNEJTIycGF0aF90b196aXBfZmlsZSUyMiklMEElMEElMjMlMjBleGFtcGxlJTIwMyUzQSUyMHJlbW90ZSUyMGZpbGVzJTIwKHN1cHBvcnRlZCUyMGZvcm1hdHMlMjBhcmUlMjB0YXIlMkMlMjBnemlwJTJDJTIwemlwJTJDJTIweHolMkMlMjByYXIlMkMlMjB6c3RkKSUwQWRhdGFzZXQlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTBBJTIwJTIwJTIwJTIwJTIyaW1hZ2Vmb2xkZXIlMjIlMkMlMEElMjAlMjAlMjAlMjBkYXRhX2ZpbGVzJTNEJTIyaHR0cHMlM0ElMkYlMkZkb3dubG9hZC5taWNyb3NvZnQuY29tJTJGZG93bmxvYWQlMkYzJTJGRSUyRjElMkYzRTFDM0YyMS1FQ0RCLTQ4NjktODM2OC02REVCQTc3QjkxOUYlMkZrYWdnbGVjYXRzYW5kZG9nc18zMzY3YS56aXAlMjIlMkMlMEEpJTBBJTBBJTIzJTIwZXhhbXBsZSUyMDQlM0ElMjBwcm92aWRpbmclMjBzZXZlcmFsJTIwc3BsaXRzJTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMEElMjAlMjAlMjAlMjAlMjJpbWFnZWZvbGRlciUyMiUyQyUyMGRhdGFfZmlsZXMlM0QlN0IlMjJ0cmFpbiUyMiUzQSUyMCU1QiUyMnBhdGglMkZ0byUyRmZpbGUxJTIyJTJDJTIwJTIycGF0aCUyRnRvJTJGZmlsZTIlMjIlNUQlMkMlMjAlMjJ0ZXN0JTIyJTNBJTIwJTVCJTIycGF0aCUyRnRvJTJGZmlsZTMlMjIlMkMlMjAlMjJwYXRoJTJGdG8lMkZmaWxlNCUyMiU1RCU3RCUwQSk=",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-comment"># example 1: local folder</span>
dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;path_to_your_folder&quot;</span>)

<span class="hljs-comment"># example 2: local files (supported formats are tar, gzip, zip, xz, rar, zstd)</span>
dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_files=<span class="hljs-string">&quot;path_to_zip_file&quot;</span>)

<span class="hljs-comment"># example 3: remote files (supported formats are tar, gzip, zip, xz, rar, zstd)</span>
dataset = load_dataset(
    <span class="hljs-string">&quot;imagefolder&quot;</span>,
    data_files=<span class="hljs-string">&quot;https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip&quot;</span>,
)

<span class="hljs-comment"># example 4: providing several splits</span>
dataset = load_dataset(
    <span class="hljs-string">&quot;imagefolder&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: [<span class="hljs-string">&quot;path/to/file1&quot;</span>, <span class="hljs-string">&quot;path/to/file2&quot;</span>], <span class="hljs-string">&quot;test&quot;</span>: [<span class="hljs-string">&quot;path/to/file3&quot;</span>, <span class="hljs-string">&quot;path/to/file4&quot;</span>]}
)`,wrap:!1}}),R=new N({props:{code:"JTIzJTIwYXNzdW1pbmclMjB5b3UlMjBoYXZlJTIwcmFuJTIwdGhlJTIwaHVnZ2luZ2ZhY2UtY2xpJTIwbG9naW4lMjBjb21tYW5kJTIwaW4lMjBhJTIwdGVybWluYWwlMEFkYXRhc2V0LnB1c2hfdG9faHViKCUyMm5hbWVfb2ZfeW91cl9kYXRhc2V0JTIyKSUwQSUwQSUyMyUyMGlmJTIweW91JTIwd2FudCUyMHRvJTIwcHVzaCUyMHRvJTIwYSUyMHByaXZhdGUlMjByZXBvJTJDJTIwc2ltcGx5JTIwcGFzcyUyMHByaXZhdGUlM0RUcnVlJTNBJTBBZGF0YXNldC5wdXNoX3RvX2h1YiglMjJuYW1lX29mX3lvdXJfZGF0YXNldCUyMiUyQyUyMHByaXZhdGUlM0RUcnVlKQ==",highlighted:`<span class="hljs-comment"># assuming you have ran the huggingface-cli login command in a terminal</span>
dataset.push_to_hub(<span class="hljs-string">&quot;name_of_your_dataset&quot;</span>)

<span class="hljs-comment"># if you want to push to a private repo, simply pass private=True:</span>
dataset.push_to_hub(<span class="hljs-string">&quot;name_of_your_dataset&quot;</span>, private=<span class="hljs-literal">True</span>)`,wrap:!1}}),Y=new N({props:{code:"YWNjZWxlcmF0ZSUyMGxhdW5jaCUyMC0tbWl4ZWRfcHJlY2lzaW9uJTNEJTIyZnAxNiUyMiUyMCUyMHRyYWluX3RleHRfdG9faW1hZ2UucHklMjAlNUMlMEElMjAlMjAtLXByZXRyYWluZWRfbW9kZWxfbmFtZV9vcl9wYXRoJTNEJTIyc3RhYmxlLWRpZmZ1c2lvbi12MS01JTJGc3RhYmxlLWRpZmZ1c2lvbi12MS01JTIyJTIwJTVDJTBBJTIwJTIwLS1kYXRhc2V0X25hbWUlM0QlMjJuYW1lX29mX3lvdXJfZGF0YXNldCUyMiUyMCU1QyUwQSUyMCUyMCUzQ290aGVyLWFyZ3VtZW50cyUzRQ==",highlighted:`accelerate launch --mixed_precision=<span class="hljs-string">&quot;fp16&quot;</span>  train_text_to_image.py \\
  --pretrained_model_name_or_path=<span class="hljs-string">&quot;stable-diffusion-v1-5/stable-diffusion-v1-5&quot;</span> \\
  --dataset_name=<span class="hljs-string">&quot;name_of_your_dataset&quot;</span> \\
  &lt;other-arguments&gt;`,wrap:!1}}),C=new Mt({props:{title:"Next steps",local:"next-steps",headingTag:"h2"}}),F=new Wt({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/training/create_dataset.md"}}),{c(){s=r("meta"),g=n(),i=r("p"),y=n(),m(J.$$.fragment),L=n(),w=r("p"),w.innerHTML=ht,Q=n(),j=r("p"),j.textContent=gt,A=n(),_=r("ul"),_.innerHTML=yt,V=n(),m(T.$$.fragment),S=n(),m(Z.$$.fragment),P=n(),b=r("p"),b.innerHTML=Tt,D=n(),m(U.$$.fragment),K=n(),k=r("p"),k.innerHTML=$t,O=n(),m(I.$$.fragment),tt=n(),m(G.$$.fragment),et=n(),m($.$$.fragment),at=n(),X=r("p"),X.innerHTML=Jt,lt=n(),B=r("p"),B.innerHTML=wt,st=n(),m(v.$$.fragment),nt=n(),x=r("p"),x.innerHTML=jt,ot=n(),m(R.$$.fragment),it=n(),H=r("p"),H.innerHTML=_t,rt=n(),m(Y.$$.fragment),dt=n(),m(C.$$.fragment),pt=n(),W=r("p"),W.innerHTML=Zt,mt=n(),z=r("p"),z.innerHTML=bt,ut=n(),m(F.$$.fragment),ct=n(),E=r("p"),this.h()},l(t){const e=Yt("svelte-u9bgzb",document.head);s=d(e,"META",{name:!0,content:!0}),e.forEach(a),g=o(t),i=d(t,"P",{}),It(i).forEach(a),y=o(t),u(J.$$.fragment,t),L=o(t),w=d(t,"P",{"data-svelte-h":!0}),p(w)!=="svelte-1kq6fl5"&&(w.innerHTML=ht),Q=o(t),j=d(t,"P",{"data-svelte-h":!0}),p(j)!=="svelte-1ki6nhc"&&(j.textContent=gt),A=o(t),_=d(t,"UL",{"data-svelte-h":!0}),p(_)!=="svelte-136e0w1"&&(_.innerHTML=yt),V=o(t),u(T.$$.fragment,t),S=o(t),u(Z.$$.fragment,t),P=o(t),b=d(t,"P",{"data-svelte-h":!0}),p(b)!=="svelte-1tbm8ke"&&(b.innerHTML=Tt),D=o(t),u(U.$$.fragment,t),K=o(t),k=d(t,"P",{"data-svelte-h":!0}),p(k)!=="svelte-16r2a6g"&&(k.innerHTML=$t),O=o(t),u(I.$$.fragment,t),tt=o(t),u(G.$$.fragment,t),et=o(t),u($.$$.fragment,t),at=o(t),X=d(t,"P",{"data-svelte-h":!0}),p(X)!=="svelte-117nzzz"&&(X.innerHTML=Jt),lt=o(t),B=d(t,"P",{"data-svelte-h":!0}),p(B)!=="svelte-10hf74w"&&(B.innerHTML=wt),st=o(t),u(v.$$.fragment,t),nt=o(t),x=d(t,"P",{"data-svelte-h":!0}),p(x)!=="svelte-6m5cjh"&&(x.innerHTML=jt),ot=o(t),u(R.$$.fragment,t),it=o(t),H=d(t,"P",{"data-svelte-h":!0}),p(H)!=="svelte-19t9o3p"&&(H.innerHTML=_t),rt=o(t),u(Y.$$.fragment,t),dt=o(t),u(C.$$.fragment,t),pt=o(t),W=d(t,"P",{"data-svelte-h":!0}),p(W)!=="svelte-1ata9m5"&&(W.innerHTML=Zt),mt=o(t),z=d(t,"P",{"data-svelte-h":!0}),p(z)!=="svelte-oyixgb"&&(z.innerHTML=bt),ut=o(t),u(F.$$.fragment,t),ct=o(t),E=d(t,"P",{}),It(E).forEach(a),this.h()},h(){Gt(s,"name","hf:doc:metadata"),Gt(s,"content",Et)},m(t,e){Ct(document.head,s),l(t,g,e),l(t,i,e),l(t,y,e),c(J,t,e),l(t,L,e),l(t,w,e),l(t,Q,e),l(t,j,e),l(t,A,e),l(t,_,e),l(t,V,e),c(T,t,e),l(t,S,e),c(Z,t,e),l(t,P,e),l(t,b,e),l(t,D,e),c(U,t,e),l(t,K,e),l(t,k,e),l(t,O,e),c(I,t,e),l(t,tt,e),c(G,t,e),l(t,et,e),c($,t,e),l(t,at,e),l(t,X,e),l(t,lt,e),l(t,B,e),l(t,st,e),c(v,t,e),l(t,nt,e),l(t,x,e),l(t,ot,e),c(R,t,e),l(t,it,e),l(t,H,e),l(t,rt,e),c(Y,t,e),l(t,dt,e),c(C,t,e),l(t,pt,e),l(t,W,e),l(t,mt,e),l(t,z,e),l(t,ut,e),c(F,t,e),l(t,ct,e),l(t,E,e),ft=!0},p(t,[e]){const Ut={};e&2&&(Ut.$$scope={dirty:e,ctx:t}),T.$set(Ut);const kt={};e&2&&(kt.$$scope={dirty:e,ctx:t}),$.$set(kt)},i(t){ft||(f(J.$$.fragment,t),f(T.$$.fragment,t),f(Z.$$.fragment,t),f(U.$$.fragment,t),f(I.$$.fragment,t),f(G.$$.fragment,t),f($.$$.fragment,t),f(v.$$.fragment,t),f(R.$$.fragment,t),f(Y.$$.fragment,t),f(C.$$.fragment,t),f(F.$$.fragment,t),ft=!0)},o(t){M(J.$$.fragment,t),M(T.$$.fragment,t),M(Z.$$.fragment,t),M(U.$$.fragment,t),M(I.$$.fragment,t),M(G.$$.fragment,t),M($.$$.fragment,t),M(v.$$.fragment,t),M(R.$$.fragment,t),M(Y.$$.fragment,t),M(C.$$.fragment,t),M(F.$$.fragment,t),ft=!1},d(t){t&&(a(g),a(i),a(y),a(L),a(w),a(Q),a(j),a(A),a(_),a(V),a(S),a(P),a(b),a(D),a(K),a(k),a(O),a(tt),a(et),a(at),a(X),a(lt),a(B),a(st),a(nt),a(x),a(ot),a(it),a(H),a(rt),a(dt),a(pt),a(W),a(mt),a(z),a(ut),a(ct),a(E)),a(s),h(J,t),h(T,t),h(Z,t),h(U,t),h(I,t),h(G,t),h($,t),h(v,t),h(R,t),h(Y,t),h(C,t),h(F,t)}}}const Et='{"title":"Create a dataset for training","local":"create-a-dataset-for-training","sections":[{"title":"Provide a dataset as a folder","local":"provide-a-dataset-as-a-folder","sections":[],"depth":2},{"title":"Upload your data to the Hub","local":"upload-your-data-to-the-hub","sections":[],"depth":2},{"title":"Next steps","local":"next-steps","sections":[],"depth":2}],"depth":1}';function Nt(q){return xt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Pt extends Rt{constructor(s){super(),Ht(this,s,Nt,qt,vt,{})}}export{Pt as component};
