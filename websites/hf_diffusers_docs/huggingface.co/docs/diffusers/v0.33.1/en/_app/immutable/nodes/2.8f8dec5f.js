import{s as tl,f as al,o as sl,n as nl}from"../chunks/scheduler.8c3d61f6.js";import{S as il,i as pl,g as i,s,r as m,A as Ml,h as p,f as t,c as n,j as Ae,u as y,x as r,k as j,y as rl,a,v as u,d as c,t as d,w}from"../chunks/index.da70eac4.js";import{T as ol}from"../chunks/Tip.1d9b8c37.js";import{C as g}from"../chunks/CodeBlock.a9c4becf.js";import{H as Ge,E as ml}from"../chunks/index.5d4ab994.js";function yl(le){let o,k="Now is a good time to free up some memory if you’re running low!",T,h,U;return h=new g({props:{code:"cGlwZWxpbmUlM0ROb25lJTBBdG9yY2guY3VkYS5lbXB0eV9jYWNoZSgp",highlighted:`pipeline=<span class="hljs-literal">None</span>
torch.cuda.empty_cache()`,wrap:!1}}),{c(){o=i("p"),o.textContent=k,T=s(),m(h.$$.fragment)},l(M){o=p(M,"P",{"data-svelte-h":!0}),r(o)!=="svelte-81ikpi"&&(o.textContent=k),T=n(M),y(h.$$.fragment,M)},m(M,J){a(M,o,J),a(M,T,J),u(h,M,J),U=!0},p:nl,i(M){U||(c(h.$$.fragment,M),U=!0)},o(M){d(h.$$.fragment,M),U=!1},d(M){M&&(t(o),t(T)),w(h,M)}}}function ul(le){let o,k,T,h,U,M,J,Re='Outpainting extends an image beyond its original boundaries, allowing you to add, replace, or modify visual elements in an image while preserving the original image. Like <a href="../using-diffusers/inpaint">inpainting</a>, you want to fill the white area (in this case, the area outside of the original image) with new visual elements while keeping the original image (represented by a mask of black pixels). There are a couple of ways to outpaint, such as with a <a href="https://hf.co/blog/OzzyGT/outpainting-controlnet" rel="nofollow">ControlNet</a> or with <a href="https://hf.co/blog/OzzyGT/outpainting-differential-diffusion" rel="nofollow">Differential Diffusion</a>.',te,v,Ve="This guide will show you how to outpaint with an inpainting model, ControlNet, and a ZoeDepth estimator.",ae,_,Ee='Before you begin, make sure you have the <a href="https://github.com/huggingface/controlnet_aux" rel="nofollow">controlnet_aux</a> library installed so you can use the ZoeDepth estimator.',se,X,ne,A,ie,G,Qe='Start by picking an image to outpaint with and remove the background with a Space like <a href="https://hf.co/spaces/briaai/BRIA-RMBG-1.4" rel="nofollow">BRIA-RMBG-1.4</a>.',pe,b,Se,Me,R,$e="For example, remove the background from this image of a pair of shoes.",re,f,Fe='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/original-jordan.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">original image</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/no-background-jordan.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">background removed</figcaption></div>',oe,V,xe='<a href="../using-diffusers/sdxl">Stable Diffusion XL (SDXL)</a> models work best with 1024x1024 images, but you can resize the image to any size as long as your hardware has enough memory to support it. The transparent background in the image should also be replaced with a white background. Create a function (like the one below) that scales and pastes the image onto a white background.',me,E,ye,Q,Ne="To avoid adding unwanted extra details, use the ZoeDepth estimator to provide additional guidance during generation and to ensure the shoes remain consistent with the original image.",ue,S,ce,C,ze='<img src="https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/zoedepth-jordan.png"/>',de,$,we,F,He='Once your image is ready, you can generate content in the white area around the shoes with <a href="https://hf.co/destitech/controlnet-inpaint-dreamer-sdxl" rel="nofollow">controlnet-inpaint-dreamer-sdxl</a>, a SDXL ControlNet trained for inpainting.',he,x,Ye='Load the inpainting ControlNet, ZoeDepth model, VAE and pass them to the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/controlnet_sdxl#diffusers.StableDiffusionXLControlNetPipeline">StableDiffusionXLControlNetPipeline</a>. Then you can create an optional <code>generate_image</code> function (for convenience) to outpaint an initial image.',Ue,N,Je,z,De="Paste the original image over the initial outpainted image. You’ll improve the outpainted background in a later step.",je,H,Te,Z,Le='<img src="https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/initial-outpaint.png"/>',be,I,ge,Y,qe='Now that you have an initial outpainted image, load the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/stable_diffusion_xl#diffusers.StableDiffusionXLInpaintPipeline">StableDiffusionXLInpaintPipeline</a> with the <a href="https://hf.co/SG161222/RealVisXL_V4.0" rel="nofollow">RealVisXL</a> model to generate the final outpainted image with better quality.',fe,D,Ce,L,Ke="Prepare a mask for the final outpainted image. To create a more natural transition between the original image and the outpainted background, blur the mask to help it blend better.",Ze,q,Ie,W,Pe='<img src="https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/blurred-mask.png"/>',We,K,Oe="Create a better prompt and pass it to the <code>generate_outpaint</code> function to generate the final outpainted image. Again, paste the original image over the final outpainted background.",Be,P,ke,B,el='<img src="https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/final-outpaint.png"/>',ve,O,_e,ee,Xe;return U=new Ge({props:{title:"Outpainting",local:"outpainting",headingTag:"h1"}}),X=new g({props:{code:"IXBpcCUyMGluc3RhbGwlMjAtcSUyMGNvbnRyb2xuZXRfYXV4",highlighted:"!pip install -q controlnet_aux",wrap:!1}}),A=new Ge({props:{title:"Image preparation",local:"image-preparation",headingTag:"h2"}}),E=new g({props:{code:"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",highlighted:`<span class="hljs-keyword">import</span> random

<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> controlnet_aux <span class="hljs-keyword">import</span> ZoeDetector
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image, ImageOps

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> (
    AutoencoderKL,
    ControlNetModel,
    StableDiffusionXLControlNetPipeline,
    StableDiffusionXLInpaintPipeline,
)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">scale_and_paste</span>(<span class="hljs-params">original_image</span>):
    aspect_ratio = original_image.width / original_image.height

    <span class="hljs-keyword">if</span> original_image.width &gt; original_image.height:
        new_width = <span class="hljs-number">1024</span>
        new_height = <span class="hljs-built_in">round</span>(new_width / aspect_ratio)
    <span class="hljs-keyword">else</span>:
        new_height = <span class="hljs-number">1024</span>
        new_width = <span class="hljs-built_in">round</span>(new_height * aspect_ratio)

    resized_original = original_image.resize((new_width, new_height), Image.LANCZOS)
    white_background = Image.new(<span class="hljs-string">&quot;RGBA&quot;</span>, (<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>), <span class="hljs-string">&quot;white&quot;</span>)
    x = (<span class="hljs-number">1024</span> - new_width) // <span class="hljs-number">2</span>
    y = (<span class="hljs-number">1024</span> - new_height) // <span class="hljs-number">2</span>
    white_background.paste(resized_original, (x, y), resized_original)

    <span class="hljs-keyword">return</span> resized_original, white_background

original_image = Image.<span class="hljs-built_in">open</span>(
    requests.get(
        <span class="hljs-string">&quot;https://huggingface.co/datasets/stevhliu/testing-images/resolve/main/no-background-jordan.png&quot;</span>,
        stream=<span class="hljs-literal">True</span>,
    ).raw
).convert(<span class="hljs-string">&quot;RGBA&quot;</span>)
resized_img, white_bg_image = scale_and_paste(original_image)`,wrap:!1}}),S=new g({props:{code:"em9lJTIwJTNEJTIwWm9lRGV0ZWN0b3IuZnJvbV9wcmV0cmFpbmVkKCUyMmxsbHlhc3ZpZWwlMkZBbm5vdGF0b3JzJTIyKSUwQWltYWdlX3pvZSUyMCUzRCUyMHpvZSh3aGl0ZV9iZ19pbWFnZSUyQyUyMGRldGVjdF9yZXNvbHV0aW9uJTNENTEyJTJDJTIwaW1hZ2VfcmVzb2x1dGlvbiUzRDEwMjQpJTBBaW1hZ2Vfem9l",highlighted:`zoe = ZoeDetector.from_pretrained(<span class="hljs-string">&quot;lllyasviel/Annotators&quot;</span>)
image_zoe = zoe(white_bg_image, detect_resolution=<span class="hljs-number">512</span>, image_resolution=<span class="hljs-number">1024</span>)
image_zoe`,wrap:!1}}),$=new Ge({props:{title:"Outpaint",local:"outpaint",headingTag:"h2"}}),N=new g({props:{code:"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",highlighted:`controlnets = [
    ControlNetModel.from_pretrained(
        <span class="hljs-string">&quot;destitech/controlnet-inpaint-dreamer-sdxl&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
    ),
    ControlNetModel.from_pretrained(
        <span class="hljs-string">&quot;diffusers/controlnet-zoe-depth-sdxl-1.0&quot;</span>, torch_dtype=torch.float16
    ),
]
vae = AutoencoderKL.from_pretrained(<span class="hljs-string">&quot;madebyollin/sdxl-vae-fp16-fix&quot;</span>, torch_dtype=torch.float16).to(<span class="hljs-string">&quot;cuda&quot;</span>)
pipeline = StableDiffusionXLControlNetPipeline.from_pretrained(
    <span class="hljs-string">&quot;SG161222/RealVisXL_V4.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, controlnet=controlnets, vae=vae
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_image</span>(<span class="hljs-params">prompt, negative_prompt, inpaint_image, zoe_image, seed: <span class="hljs-built_in">int</span> = <span class="hljs-literal">None</span></span>):
    <span class="hljs-keyword">if</span> seed <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
        seed = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>**<span class="hljs-number">32</span> - <span class="hljs-number">1</span>)

    generator = torch.Generator(device=<span class="hljs-string">&quot;cpu&quot;</span>).manual_seed(seed)

    image = pipeline(
        prompt,
        negative_prompt=negative_prompt,
        image=[inpaint_image, zoe_image],
        guidance_scale=<span class="hljs-number">6.5</span>,
        num_inference_steps=<span class="hljs-number">25</span>,
        generator=generator,
        controlnet_conditioning_scale=[<span class="hljs-number">0.5</span>, <span class="hljs-number">0.8</span>],
        control_guidance_end=[<span class="hljs-number">0.9</span>, <span class="hljs-number">0.6</span>],
    ).images[<span class="hljs-number">0</span>]

    <span class="hljs-keyword">return</span> image

prompt = <span class="hljs-string">&quot;nike air jordans on a basketball court&quot;</span>
negative_prompt = <span class="hljs-string">&quot;&quot;</span>

temp_image = generate_image(prompt, negative_prompt, white_bg_image, image_zoe, <span class="hljs-number">908097</span>)`,wrap:!1}}),H=new g({props:{code:"eCUyMCUzRCUyMCgxMDI0JTIwLSUyMHJlc2l6ZWRfaW1nLndpZHRoKSUyMCUyRiUyRiUyMDIlMEF5JTIwJTNEJTIwKDEwMjQlMjAtJTIwcmVzaXplZF9pbWcuaGVpZ2h0KSUyMCUyRiUyRiUyMDIlMEF0ZW1wX2ltYWdlLnBhc3RlKHJlc2l6ZWRfaW1nJTJDJTIwKHglMkMlMjB5KSUyQyUyMHJlc2l6ZWRfaW1nKSUwQXRlbXBfaW1hZ2U=",highlighted:`x = (<span class="hljs-number">1024</span> - resized_img.width) // <span class="hljs-number">2</span>
y = (<span class="hljs-number">1024</span> - resized_img.height) // <span class="hljs-number">2</span>
temp_image.paste(resized_img, (x, y), resized_img)
temp_image`,wrap:!1}}),I=new ol({props:{warning:!1,$$slots:{default:[yl]},$$scope:{ctx:le}}}),D=new g({props:{code:"cGlwZWxpbmUlMjAlM0QlMjBTdGFibGVEaWZmdXNpb25YTElucGFpbnRQaXBlbGluZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyT3p6eUdUJTJGUmVhbFZpc1hMX1Y0LjBfaW5wYWludGluZyUyMiUyQyUwQSUyMCUyMCUyMCUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUwQSUyMCUyMCUyMCUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTBBJTIwJTIwJTIwJTIwdmFlJTNEdmFlJTJDJTBBKS50byglMjJjdWRhJTIyKQ==",highlighted:`pipeline = StableDiffusionXLInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;OzzyGT/RealVisXL_V4.0_inpainting&quot;</span>,
    torch_dtype=torch.float16,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
    vae=vae,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),q=new g({props:{code:"bWFzayUyMCUzRCUyMEltYWdlLm5ldyglMjJMJTIyJTJDJTIwdGVtcF9pbWFnZS5zaXplKSUwQW1hc2sucGFzdGUocmVzaXplZF9pbWcuc3BsaXQoKSU1QjMlNUQlMkMlMjAoeCUyQyUyMHkpKSUwQW1hc2slMjAlM0QlMjBJbWFnZU9wcy5pbnZlcnQobWFzayklMEFmaW5hbF9tYXNrJTIwJTNEJTIwbWFzay5wb2ludChsYW1iZGElMjBwJTNBJTIwcCUyMCUzRSUyMDEyOCUyMGFuZCUyMDI1NSklMEFtYXNrX2JsdXJyZWQlMjAlM0QlMjBwaXBlbGluZS5tYXNrX3Byb2Nlc3Nvci5ibHVyKGZpbmFsX21hc2slMkMlMjBibHVyX2ZhY3RvciUzRDIwKSUwQW1hc2tfYmx1cnJlZA==",highlighted:`mask = Image.new(<span class="hljs-string">&quot;L&quot;</span>, temp_image.size)
mask.paste(resized_img.split()[<span class="hljs-number">3</span>], (x, y))
mask = ImageOps.invert(mask)
final_mask = mask.point(<span class="hljs-keyword">lambda</span> p: p &gt; <span class="hljs-number">128</span> <span class="hljs-keyword">and</span> <span class="hljs-number">255</span>)
mask_blurred = pipeline.mask_processor.blur(final_mask, blur_factor=<span class="hljs-number">20</span>)
mask_blurred`,wrap:!1}}),P=new g({props:{code:"ZGVmJTIwZ2VuZXJhdGVfb3V0cGFpbnQocHJvbXB0JTJDJTIwbmVnYXRpdmVfcHJvbXB0JTJDJTIwaW1hZ2UlMkMlMjBtYXNrJTJDJTIwc2VlZCUzQSUyMGludCUyMCUzRCUyME5vbmUpJTNBJTBBJTIwJTIwJTIwJTIwaWYlMjBzZWVkJTIwaXMlMjBOb25lJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwc2VlZCUyMCUzRCUyMHJhbmRvbS5yYW5kaW50KDAlMkMlMjAyKiozMiUyMC0lMjAxKSUwQSUwQSUyMCUyMCUyMCUyMGdlbmVyYXRvciUyMCUzRCUyMHRvcmNoLkdlbmVyYXRvcihkZXZpY2UlM0QlMjJjcHUlMjIpLm1hbnVhbF9zZWVkKHNlZWQpJTBBJTBBJTIwJTIwJTIwJTIwaW1hZ2UlMjAlM0QlMjBwaXBlbGluZSglMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBwcm9tcHQlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBuZWdhdGl2ZV9wcm9tcHQlM0RuZWdhdGl2ZV9wcm9tcHQlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBpbWFnZSUzRGltYWdlJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbWFza19pbWFnZSUzRG1hc2slMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBndWlkYW5jZV9zY2FsZSUzRDEwLjAlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBzdHJlbmd0aCUzRDAuOCUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG51bV9pbmZlcmVuY2Vfc3RlcHMlM0QzMCUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGdlbmVyYXRvciUzRGdlbmVyYXRvciUyQyUwQSUyMCUyMCUyMCUyMCkuaW1hZ2VzJTVCMCU1RCUwQSUwQSUyMCUyMCUyMCUyMHJldHVybiUyMGltYWdlJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyaGlnaCUyMHF1YWxpdHklMjBwaG90byUyMG9mJTIwbmlrZSUyMGFpciUyMGpvcmRhbnMlMjBvbiUyMGElMjBiYXNrZXRiYWxsJTIwY291cnQlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyMiUwQW5lZ2F0aXZlX3Byb21wdCUyMCUzRCUyMCUyMiUyMiUwQSUwQWZpbmFsX2ltYWdlJTIwJTNEJTIwZ2VuZXJhdGVfb3V0cGFpbnQocHJvbXB0JTJDJTIwbmVnYXRpdmVfcHJvbXB0JTJDJTIwdGVtcF9pbWFnZSUyQyUyMG1hc2tfYmx1cnJlZCUyQyUyMDc2ODg3NzgpJTBBeCUyMCUzRCUyMCgxMDI0JTIwLSUyMHJlc2l6ZWRfaW1nLndpZHRoKSUyMCUyRiUyRiUyMDIlMEF5JTIwJTNEJTIwKDEwMjQlMjAtJTIwcmVzaXplZF9pbWcuaGVpZ2h0KSUyMCUyRiUyRiUyMDIlMEFmaW5hbF9pbWFnZS5wYXN0ZShyZXNpemVkX2ltZyUyQyUyMCh4JTJDJTIweSklMkMlMjByZXNpemVkX2ltZyklMEFmaW5hbF9pbWFnZQ==",highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_outpaint</span>(<span class="hljs-params">prompt, negative_prompt, image, mask, seed: <span class="hljs-built_in">int</span> = <span class="hljs-literal">None</span></span>):
    <span class="hljs-keyword">if</span> seed <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
        seed = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>**<span class="hljs-number">32</span> - <span class="hljs-number">1</span>)

    generator = torch.Generator(device=<span class="hljs-string">&quot;cpu&quot;</span>).manual_seed(seed)

    image = pipeline(
        prompt,
        negative_prompt=negative_prompt,
        image=image,
        mask_image=mask,
        guidance_scale=<span class="hljs-number">10.0</span>,
        strength=<span class="hljs-number">0.8</span>,
        num_inference_steps=<span class="hljs-number">30</span>,
        generator=generator,
    ).images[<span class="hljs-number">0</span>]

    <span class="hljs-keyword">return</span> image

prompt = <span class="hljs-string">&quot;high quality photo of nike air jordans on a basketball court, highly detailed&quot;</span>
negative_prompt = <span class="hljs-string">&quot;&quot;</span>

final_image = generate_outpaint(prompt, negative_prompt, temp_image, mask_blurred, <span class="hljs-number">7688778</span>)
x = (<span class="hljs-number">1024</span> - resized_img.width) // <span class="hljs-number">2</span>
y = (<span class="hljs-number">1024</span> - resized_img.height) // <span class="hljs-number">2</span>
final_image.paste(resized_img, (x, y), resized_img)
final_image`,wrap:!1}}),O=new ml({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/advanced_inference/outpaint.md"}}),{c(){o=i("meta"),k=s(),T=i("p"),h=s(),m(U.$$.fragment),M=s(),J=i("p"),J.innerHTML=Re,te=s(),v=i("p"),v.textContent=Ve,ae=s(),_=i("p"),_.innerHTML=Ee,se=s(),m(X.$$.fragment),ne=s(),m(A.$$.fragment),ie=s(),G=i("p"),G.innerHTML=Qe,pe=s(),b=i("iframe"),Me=s(),R=i("p"),R.textContent=$e,re=s(),f=i("div"),f.innerHTML=Fe,oe=s(),V=i("p"),V.innerHTML=xe,me=s(),m(E.$$.fragment),ye=s(),Q=i("p"),Q.textContent=Ne,ue=s(),m(S.$$.fragment),ce=s(),C=i("div"),C.innerHTML=ze,de=s(),m($.$$.fragment),we=s(),F=i("p"),F.innerHTML=He,he=s(),x=i("p"),x.innerHTML=Ye,Ue=s(),m(N.$$.fragment),Je=s(),z=i("p"),z.textContent=De,je=s(),m(H.$$.fragment),Te=s(),Z=i("div"),Z.innerHTML=Le,be=s(),m(I.$$.fragment),ge=s(),Y=i("p"),Y.innerHTML=qe,fe=s(),m(D.$$.fragment),Ce=s(),L=i("p"),L.textContent=Ke,Ze=s(),m(q.$$.fragment),Ie=s(),W=i("div"),W.innerHTML=Pe,We=s(),K=i("p"),K.innerHTML=Oe,Be=s(),m(P.$$.fragment),ke=s(),B=i("div"),B.innerHTML=el,ve=s(),m(O.$$.fragment),_e=s(),ee=i("p"),this.h()},l(e){const l=Ml("svelte-u9bgzb",document.head);o=p(l,"META",{name:!0,content:!0}),l.forEach(t),k=n(e),T=p(e,"P",{}),Ae(T).forEach(t),h=n(e),y(U.$$.fragment,e),M=n(e),J=p(e,"P",{"data-svelte-h":!0}),r(J)!=="svelte-16ua5v0"&&(J.innerHTML=Re),te=n(e),v=p(e,"P",{"data-svelte-h":!0}),r(v)!=="svelte-6ts35n"&&(v.textContent=Ve),ae=n(e),_=p(e,"P",{"data-svelte-h":!0}),r(_)!=="svelte-ftdr0t"&&(_.innerHTML=Ee),se=n(e),y(X.$$.fragment,e),ne=n(e),y(A.$$.fragment,e),ie=n(e),G=p(e,"P",{"data-svelte-h":!0}),r(G)!=="svelte-1qxxpsh"&&(G.innerHTML=Qe),pe=n(e),b=p(e,"IFRAME",{src:!0,frameborder:!0,width:!0,height:!0}),Ae(b).forEach(t),Me=n(e),R=p(e,"P",{"data-svelte-h":!0}),r(R)!=="svelte-1mizknk"&&(R.textContent=$e),re=n(e),f=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(f)!=="svelte-1jvhkj8"&&(f.innerHTML=Fe),oe=n(e),V=p(e,"P",{"data-svelte-h":!0}),r(V)!=="svelte-1jea20f"&&(V.innerHTML=xe),me=n(e),y(E.$$.fragment,e),ye=n(e),Q=p(e,"P",{"data-svelte-h":!0}),r(Q)!=="svelte-ksi0ug"&&(Q.textContent=Ne),ue=n(e),y(S.$$.fragment,e),ce=n(e),C=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(C)!=="svelte-rp0vpr"&&(C.innerHTML=ze),de=n(e),y($.$$.fragment,e),we=n(e),F=p(e,"P",{"data-svelte-h":!0}),r(F)!=="svelte-1p8ap7h"&&(F.innerHTML=He),he=n(e),x=p(e,"P",{"data-svelte-h":!0}),r(x)!=="svelte-1afmflu"&&(x.innerHTML=Ye),Ue=n(e),y(N.$$.fragment,e),Je=n(e),z=p(e,"P",{"data-svelte-h":!0}),r(z)!=="svelte-13kbyjh"&&(z.textContent=De),je=n(e),y(H.$$.fragment,e),Te=n(e),Z=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(Z)!=="svelte-1f58coy"&&(Z.innerHTML=Le),be=n(e),y(I.$$.fragment,e),ge=n(e),Y=p(e,"P",{"data-svelte-h":!0}),r(Y)!=="svelte-1tjls8w"&&(Y.innerHTML=qe),fe=n(e),y(D.$$.fragment,e),Ce=n(e),L=p(e,"P",{"data-svelte-h":!0}),r(L)!=="svelte-n4298l"&&(L.textContent=Ke),Ze=n(e),y(q.$$.fragment,e),Ie=n(e),W=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(W)!=="svelte-1anr4fy"&&(W.innerHTML=Pe),We=n(e),K=p(e,"P",{"data-svelte-h":!0}),r(K)!=="svelte-ktwg6k"&&(K.innerHTML=Oe),Be=n(e),y(P.$$.fragment,e),ke=n(e),B=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(B)!=="svelte-1r64xky"&&(B.innerHTML=el),ve=n(e),y(O.$$.fragment,e),_e=n(e),ee=p(e,"P",{}),Ae(ee).forEach(t),this.h()},h(){j(o,"name","hf:doc:metadata"),j(o,"content",cl),al(b.src,Se="https://briaai-bria-rmbg-1-4.hf.space")||j(b,"src",Se),j(b,"frameborder","0"),j(b,"width","850"),j(b,"height","450"),j(f,"class","flex flex-row gap-4"),j(C,"class","flex justify-center"),j(Z,"class","flex justify-center"),j(W,"class","flex justify-center"),j(B,"class","flex justify-center")},m(e,l){rl(document.head,o),a(e,k,l),a(e,T,l),a(e,h,l),u(U,e,l),a(e,M,l),a(e,J,l),a(e,te,l),a(e,v,l),a(e,ae,l),a(e,_,l),a(e,se,l),u(X,e,l),a(e,ne,l),u(A,e,l),a(e,ie,l),a(e,G,l),a(e,pe,l),a(e,b,l),a(e,Me,l),a(e,R,l),a(e,re,l),a(e,f,l),a(e,oe,l),a(e,V,l),a(e,me,l),u(E,e,l),a(e,ye,l),a(e,Q,l),a(e,ue,l),u(S,e,l),a(e,ce,l),a(e,C,l),a(e,de,l),u($,e,l),a(e,we,l),a(e,F,l),a(e,he,l),a(e,x,l),a(e,Ue,l),u(N,e,l),a(e,Je,l),a(e,z,l),a(e,je,l),u(H,e,l),a(e,Te,l),a(e,Z,l),a(e,be,l),u(I,e,l),a(e,ge,l),a(e,Y,l),a(e,fe,l),u(D,e,l),a(e,Ce,l),a(e,L,l),a(e,Ze,l),u(q,e,l),a(e,Ie,l),a(e,W,l),a(e,We,l),a(e,K,l),a(e,Be,l),u(P,e,l),a(e,ke,l),a(e,B,l),a(e,ve,l),u(O,e,l),a(e,_e,l),a(e,ee,l),Xe=!0},p(e,[l]){const ll={};l&2&&(ll.$$scope={dirty:l,ctx:e}),I.$set(ll)},i(e){Xe||(c(U.$$.fragment,e),c(X.$$.fragment,e),c(A.$$.fragment,e),c(E.$$.fragment,e),c(S.$$.fragment,e),c($.$$.fragment,e),c(N.$$.fragment,e),c(H.$$.fragment,e),c(I.$$.fragment,e),c(D.$$.fragment,e),c(q.$$.fragment,e),c(P.$$.fragment,e),c(O.$$.fragment,e),Xe=!0)},o(e){d(U.$$.fragment,e),d(X.$$.fragment,e),d(A.$$.fragment,e),d(E.$$.fragment,e),d(S.$$.fragment,e),d($.$$.fragment,e),d(N.$$.fragment,e),d(H.$$.fragment,e),d(I.$$.fragment,e),d(D.$$.fragment,e),d(q.$$.fragment,e),d(P.$$.fragment,e),d(O.$$.fragment,e),Xe=!1},d(e){e&&(t(k),t(T),t(h),t(M),t(J),t(te),t(v),t(ae),t(_),t(se),t(ne),t(ie),t(G),t(pe),t(b),t(Me),t(R),t(re),t(f),t(oe),t(V),t(me),t(ye),t(Q),t(ue),t(ce),t(C),t(de),t(we),t(F),t(he),t(x),t(Ue),t(Je),t(z),t(je),t(Te),t(Z),t(be),t(ge),t(Y),t(fe),t(Ce),t(L),t(Ze),t(Ie),t(W),t(We),t(K),t(Be),t(ke),t(B),t(ve),t(_e),t(ee)),t(o),w(U,e),w(X,e),w(A,e),w(E,e),w(S,e),w($,e),w(N,e),w(H,e),w(I,e),w(D,e),w(q,e),w(P,e),w(O,e)}}}const cl='{"title":"Outpainting","local":"outpainting","sections":[{"title":"Image preparation","local":"image-preparation","sections":[],"depth":2},{"title":"Outpaint","local":"outpaint","sections":[],"depth":2}],"depth":1}';function dl(le){return sl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Tl extends il{constructor(o){super(),pl(this,o,dl,ul,tl,{})}}export{Tl as component};
