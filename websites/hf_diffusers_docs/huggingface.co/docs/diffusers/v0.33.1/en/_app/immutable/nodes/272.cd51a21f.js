import{s as qn,f as An,o as Dn,n as ka}from"../chunks/scheduler.8c3d61f6.js";import{S as Pn,i as Kn,g as m,s as n,r as c,A as On,h as o,f as l,c as s,j as _t,u as d,x as r,k as W,y as es,a as t,v as g,d as u,t as f,w as h}from"../chunks/index.da70eac4.js";import{T as En}from"../chunks/Tip.1d9b8c37.js";import{C as b}from"../chunks/CodeBlock.a9c4becf.js";import{D as as}from"../chunks/DocNotebookDropdown.48852948.js";import{H as w,E as ls}from"../chunks/index.5d4ab994.js";import{H as Ln,a as Xt}from"../chunks/HfOption.6ab18950.js";function ts(T){let i,y='You’ll notice throughout the guide, we use <a href="/docs/diffusers/v0.33.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.enable_model_cpu_offload">enable_model_cpu_offload()</a> and <a href="/docs/diffusers/v0.33.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.enable_xformers_memory_efficient_attention">enable_xformers_memory_efficient_attention()</a>, to save memory and increase inference speed. If you’re using PyTorch 2.0, it’s not necessary to call <a href="/docs/diffusers/v0.33.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.enable_xformers_memory_efficient_attention">enable_xformers_memory_efficient_attention()</a> on your pipeline because it’ll already be using PyTorch 2.0’s native <a href="../optimization/torch2.0#scaled-dot-product-attention">scaled-dot product attention</a>.';return{c(){i=m("p"),i.innerHTML=y},l(p){i=o(p,"P",{"data-svelte-h":!0}),r(i)!=="svelte-1yxmmqr"&&(i.innerHTML=y)},m(p,J){t(p,i,J)},p:ka,d(p){p&&l(i)}}}function ns(T){let i,y;return i=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFibGUtZGlmZnVzaW9uLXYxLTUlMkZzdGFibGUtZGlmZnVzaW9uLXYxLTUlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUwQSklMEFwaXBlbGluZS5lbmFibGVfbW9kZWxfY3B1X29mZmxvYWQoKSUwQSUyMyUyMHJlbW92ZSUyMGZvbGxvd2luZyUyMGxpbmUlMjBpZiUyMHhGb3JtZXJzJTIwaXMlMjBub3QlMjBpbnN0YWxsZWQlMjBvciUyMHlvdSUyMGhhdmUlMjBQeVRvcmNoJTIwMi4wJTIwb3IlMjBoaWdoZXIlMjBpbnN0YWxsZWQlMEFwaXBlbGluZS5lbmFibGVfeGZvcm1lcnNfbWVtb3J5X2VmZmljaWVudF9hdHRlbnRpb24oKSUwQSUwQSUyMyUyMGxvYWQlMjBiYXNlJTIwYW5kJTIwbWFzayUyMGltYWdlJTBBaW5pdF9pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGaW5wYWludC5wbmclMjIpJTBBbWFza19pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGaW5wYWludF9tYXNrLnBuZyUyMiklMEElMEFnZW5lcmF0b3IlMjAlM0QlMjB0b3JjaC5HZW5lcmF0b3IoJTIyY3VkYSUyMikubWFudWFsX3NlZWQoOTIpJTBBcHJvbXB0JTIwJTNEJTIwJTIyY29uY2VwdCUyMGFydCUyMGRpZ2l0YWwlMjBwYWludGluZyUyMG9mJTIwYW4lMjBlbHZlbiUyMGNhc3RsZSUyQyUyMGluc3BpcmVkJTIwYnklMjBsb3JkJTIwb2YlMjB0aGUlMjByaW5ncyUyQyUyMGhpZ2hseSUyMGRldGFpbGVkJTJDJTIwOGslMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUzRHByb21wdCUyQyUyMGltYWdlJTNEaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlM0RtYXNrX2ltYWdlJTJDJTIwZ2VuZXJhdG9yJTNEZ2VuZXJhdG9yKS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBpbWFnZSU1RCUyQyUyMHJvd3MlM0QxJTJDJTIwY29scyUzRDIp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;stable-diffusion-v1-5/stable-diffusion-v1-5&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

generator = torch.Generator(<span class="hljs-string">&quot;cuda&quot;</span>).manual_seed(<span class="hljs-number">92</span>)
prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),{c(){c(i.$$.fragment)},l(p){d(i.$$.fragment,p)},m(p,J){g(i,p,J),y=!0},p:ka,i(p){y||(u(i.$$.fragment,p),y=!0)},o(p){f(i.$$.fragment,p),y=!1},d(p){h(i,p)}}}function ss(T){let i,y;return i=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJydW53YXltbCUyRnN0YWJsZS1kaWZmdXNpb24taW5wYWludGluZyUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50X21hc2sucG5nJTIyKSUwQSUwQWdlbmVyYXRvciUyMCUzRCUyMHRvcmNoLkdlbmVyYXRvciglMjJjdWRhJTIyKS5tYW51YWxfc2VlZCg5MiklMEFwcm9tcHQlMjAlM0QlMjAlMjJjb25jZXB0JTIwYXJ0JTIwZGlnaXRhbCUyMHBhaW50aW5nJTIwb2YlMjBhbiUyMGVsdmVuJTIwY2FzdGxlJTJDJTIwaW5zcGlyZWQlMjBieSUyMGxvcmQlMjBvZiUyMHRoZSUyMHJpbmdzJTJDJTIwaGlnaGx5JTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEcHJvbXB0JTJDJTIwaW1hZ2UlM0Rpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUzRG1hc2tfaW1hZ2UlMkMlMjBnZW5lcmF0b3IlM0RnZW5lcmF0b3IpLmltYWdlcyU1QjAlNUQlMEFtYWtlX2ltYWdlX2dyaWQoJTVCaW5pdF9pbWFnZSUyQyUyMGltYWdlJTVEJTJDJTIwcm93cyUzRDElMkMlMjBjb2xzJTNEMik=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

generator = torch.Generator(<span class="hljs-string">&quot;cuda&quot;</span>).manual_seed(<span class="hljs-number">92</span>)
prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),{c(){c(i.$$.fragment)},l(p){d(i.$$.fragment,p)},m(p,J){g(i,p,J),y=!0},p:ka,i(p){y||(u(i.$$.fragment,p),y=!0)},o(p){f(i.$$.fragment,p),y=!1},d(p){h(i,p)}}}function is(T){let i,y,p,J;return i=new Xt({props:{id:"regular-specific",option:"stable-diffusion-v1-5/stable-diffusion-v1-5",$$slots:{default:[ns]},$$scope:{ctx:T}}}),p=new Xt({props:{id:"regular-specific",option:"runwayml/stable-diffusion-inpainting",$$slots:{default:[ss]},$$scope:{ctx:T}}}),{c(){c(i.$$.fragment),y=n(),c(p.$$.fragment)},l(M){d(i.$$.fragment,M),y=s(M),d(p.$$.fragment,M)},m(M,Z){g(i,M,Z),t(M,y,Z),g(p,M,Z),J=!0},p(M,Z){const U={};Z&2&&(U.$$scope={dirty:Z,ctx:M}),i.$set(U);const j={};Z&2&&(j.$$scope={dirty:Z,ctx:M}),p.$set(j)},i(M){J||(u(i.$$.fragment,M),u(p.$$.fragment,M),J=!0)},o(M){f(i.$$.fragment,M),f(p.$$.fragment,M),J=!1},d(M){M&&l(y),h(i,M),h(p,M)}}}function ps(T){let i,y;return i=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFibGUtZGlmZnVzaW9uLXYxLTUlMkZzdGFibGUtZGlmZnVzaW9uLXYxLTUlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUwQSklMEFwaXBlbGluZS5lbmFibGVfbW9kZWxfY3B1X29mZmxvYWQoKSUwQSUyMyUyMHJlbW92ZSUyMGZvbGxvd2luZyUyMGxpbmUlMjBpZiUyMHhGb3JtZXJzJTIwaXMlMjBub3QlMjBpbnN0YWxsZWQlMjBvciUyMHlvdSUyMGhhdmUlMjBQeVRvcmNoJTIwMi4wJTIwb3IlMjBoaWdoZXIlMjBpbnN0YWxsZWQlMEFwaXBlbGluZS5lbmFibGVfeGZvcm1lcnNfbWVtb3J5X2VmZmljaWVudF9hdHRlbnRpb24oKSUwQSUwQSUyMyUyMGxvYWQlMjBiYXNlJTIwYW5kJTIwbWFzayUyMGltYWdlJTBBaW5pdF9pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGaW5wYWludC5wbmclMjIpJTBBbWFza19pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGcm9hZC1tYXNrLnBuZyUyMiklMEElMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUzRCUyMnJvYWQlMjIlMkMlMjBpbWFnZSUzRGluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSkuaW1hZ2VzJTVCMCU1RCUwQW1ha2VfaW1hZ2VfZ3JpZCglNUJpbml0X2ltYWdlJTJDJTIwaW1hZ2UlNUQlMkMlMjByb3dzJTNEMSUyQyUyMGNvbHMlM0QyKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;stable-diffusion-v1-5/stable-diffusion-v1-5&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png&quot;</span>)

image = pipeline(prompt=<span class="hljs-string">&quot;road&quot;</span>, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),{c(){c(i.$$.fragment)},l(p){d(i.$$.fragment,p)},m(p,J){g(i,p,J),y=!0},p:ka,i(p){y||(u(i.$$.fragment,p),y=!0)},o(p){f(i.$$.fragment,p),y=!1},d(p){h(i,p)}}}function ms(T){let i,y;return i=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJydW53YXltbCUyRnN0YWJsZS1kaWZmdXNpb24taW5wYWludGluZyUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZyb2FkLW1hc2sucG5nJTIyKSUwQSUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEJTIycm9hZCUyMiUyQyUyMGltYWdlJTNEaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlM0RtYXNrX2ltYWdlKS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBpbWFnZSU1RCUyQyUyMHJvd3MlM0QxJTJDJTIwY29scyUzRDIp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/road-mask.png&quot;</span>)

image = pipeline(prompt=<span class="hljs-string">&quot;road&quot;</span>, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),{c(){c(i.$$.fragment)},l(p){d(i.$$.fragment,p)},m(p,J){g(i,p,J),y=!0},p:ka,i(p){y||(u(i.$$.fragment,p),y=!0)},o(p){f(i.$$.fragment,p),y=!1},d(p){h(i,p)}}}function os(T){let i,y,p,J;return i=new Xt({props:{id:"inpaint",option:"stable-diffusion-v1-5/stable-diffusion-v1-5",$$slots:{default:[ps]},$$scope:{ctx:T}}}),p=new Xt({props:{id:"inpaint",option:"runwayml/stable-diffusion-inpaint",$$slots:{default:[ms]},$$scope:{ctx:T}}}),{c(){c(i.$$.fragment),y=n(),c(p.$$.fragment)},l(M){d(i.$$.fragment,M),y=s(M),d(p.$$.fragment,M)},m(M,Z){g(i,M,Z),t(M,y,Z),g(p,M,Z),J=!0},p(M,Z){const U={};Z&2&&(U.$$scope={dirty:Z,ctx:M}),i.$set(U);const j={};Z&2&&(j.$$scope={dirty:Z,ctx:M}),p.$set(j)},i(M){J||(u(i.$$.fragment,M),u(p.$$.fragment,M),J=!0)},o(M){f(i.$$.fragment,M),f(p.$$.fragment,M),J=!1},d(M){M&&l(y),h(i,M),h(p,M)}}}function rs(T){let i,y='It is important to specify <code>output_type=&quot;latent&quot;</code> in the pipeline to keep all the outputs in latent space to avoid an unnecessary decode-encode step. This only works if the chained pipelines are using the same VAE. For example, in the <a href="#text-to-image-to-inpaint">Text-to-image-to-inpaint</a> section, Kandinsky 2.2 uses a different VAE class than the Stable Diffusion model so it won’t work. But if you use Stable Diffusion v1.5 for both pipelines, then you can keep everything in latent space because they both use <a href="/docs/diffusers/v0.33.1/en/api/models/autoencoderkl#diffusers.AutoencoderKL">AutoencoderKL</a>.';return{c(){i=m("p"),i.innerHTML=y},l(p){i=o(p,"P",{"data-svelte-h":!0}),r(i)!=="svelte-15v4byk"&&(i.innerHTML=y)},m(p,J){t(p,i,J)},p:ka,d(p){p&&l(i)}}}function cs(T){let i,y,p,J,M,Z,U,j,E,Yt="Inpainting replaces or edits specific areas of an image. This makes it a useful tool for image restoration like removing defects and artifacts, or even replacing an image area with something entirely new. Inpainting relies on a mask to determine which regions of an image to fill in; the area to inpaint is represented by white pixels and the area to keep is represented by black pixels. The white pixels are filled in by the prompt.",va,L,Ft="With 🤗 Diffusers, here is how you can do inpainting:",Ia,q,Rt='<li>Load an inpainting checkpoint with the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting">AutoPipelineForInpainting</a> class. This’ll automatically detect the appropriate pipeline class to load based on the checkpoint:</li>',Xa,A,_a,k,Ya,B,Vt="<li>Load the base and mask images:</li>",Fa,D,Ra,v,xt="<li>Create a prompt to inpaint the image with and pass it to the pipeline with the base and mask images:</li>",Va,P,xa,I,$t='<div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">base image</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">mask image</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-cat.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">generated image</figcaption></div>',$a,K,Ca,O,Ct="Throughout this guide, the mask image is provided in all of the code examples for convenience. You can inpaint on your own images, but you’ll need to create a mask image for it. Use the Space below to easily create a mask image.",Na,ee,Nt="Upload a base image to inpaint on and use the sketch tool to draw a mask. Once you’re done, click <strong>Run</strong> to generate and download the mask image.",Qa,G,Qt,Sa,ae,Ha,le,St="The <code>~VaeImageProcessor.blur</code> method provides an option for how to blend the original image and inpaint area. The amount of blur is determined by the <code>blur_factor</code> parameter. Increasing the <code>blur_factor</code> increases the amount of blur applied to the mask edges, softening the transition between the original image and inpaint area. A low or zero <code>blur_factor</code> preserves the sharper edges of the mask.",za,te,Ht="To use this, create a blurred mask with the image processor.",Ea,ne,La,X,zt='<div><img class="rounded-xl" src="https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">mask with no blur</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/mask_blurred.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">mask with blur applied</figcaption></div>',qa,se,Aa,ie,Et='<a href="https://huggingface.co/runwayml/stable-diffusion-inpainting" rel="nofollow">Stable Diffusion Inpainting</a>, <a href="https://huggingface.co/diffusers/stable-diffusion-xl-1.0-inpainting-0.1" rel="nofollow">Stable Diffusion XL (SDXL) Inpainting</a>, and <a href="https://huggingface.co/kandinsky-community/kandinsky-2-2-decoder-inpaint" rel="nofollow">Kandinsky 2.2 Inpainting</a> are among the most popular models for inpainting. SDXL typically produces higher resolution images than Stable Diffusion v1.5, and Kandinsky 2.2 is also capable of generating high-quality images.',Da,pe,Pa,me,Lt="Stable Diffusion Inpainting is a latent diffusion model finetuned on 512x512 images on inpainting. It is a good starting point because it is relatively fast and generates good quality images. To use this model for inpainting, you’ll need to pass a prompt, base and mask image to the pipeline:",Ka,oe,Oa,re,el,ce,qt='SDXL is a larger and more powerful version of Stable Diffusion v1.5. This model can follow a two-stage model process (though each model can also be used alone); the base model generates an image, and a refiner model takes that image and further enhances its details and quality. Take a look at the <a href="sdxl">SDXL</a> guide for a more comprehensive guide on how to use SDXL and configure it’s parameters.',al,de,ll,ge,tl,ue,At='The Kandinsky model family is similar to SDXL because it uses two models as well; the image prior model creates image embeddings, and the diffusion model generates images from them. You can load the image prior and diffusion model separately, but the easiest way to use Kandinsky 2.2 is to load it into the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting">AutoPipelineForInpainting</a> class which uses the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/kandinsky_v22#diffusers.KandinskyV22InpaintCombinedPipeline">KandinskyV22InpaintCombinedPipeline</a> under the hood.',nl,fe,sl,_,Dt='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">base image</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdv1.5.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">Stable Diffusion Inpainting</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-sdxl.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">Stable Diffusion XL Inpainting</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-kandinsky.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">Kandinsky 2.2 Inpainting</figcaption></div>',il,he,pl,Me,Pt='So far, this guide has used inpaint specific checkpoints such as <a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-inpainting" rel="nofollow">stable-diffusion-v1-5/stable-diffusion-inpainting</a>. But you can also use regular checkpoints like <a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5" rel="nofollow">stable-diffusion-v1-5/stable-diffusion-v1-5</a>. Let’s compare the results of the two checkpoints.',ml,ye,Kt="The image on the left is generated from a regular checkpoint, and the image on the right is from an inpaint checkpoint. You’ll immediately notice the image on the left is not as clean, and you can still see the outline of the area the model is supposed to inpaint. The image on the right is much cleaner and the inpainted area appears more natural.",ol,Y,rl,F,Ot='<div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/non-inpaint-specific.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">stable-diffusion-v1-5/stable-diffusion-v1-5</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-specific.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-inpainting</figcaption></div>',cl,be,en="However, for more basic tasks like erasing an object from an image (like the rocks in the road for example), a regular checkpoint yields pretty good results. There isn’t as noticeable of difference between the regular and inpaint checkpoint.",dl,R,gl,V,an='<div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/regular-inpaint-basic.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">stable-diffusion-v1-5/stable-diffusion-v1-5</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/specific-inpaint-basic.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">runwayml/stable-diffusion-inpainting</figcaption></div>',ul,Je,ln="The trade-off of using a non-inpaint specific checkpoint is the overall image quality may be lower, but it generally tends to preserve the mask area (that is why you can see the mask outline). The inpaint specific checkpoints are intentionally trained to generate higher quality inpainted images, and that includes creating a more natural transition between the masked and unmasked areas. As a result, these checkpoints are more likely to change your unmasked area.",fl,Ze,tn="If preserving the unmasked area is important for your task, you can use the <code>VaeImageProcessor.apply_overlay</code> method to force the unmasked area of an image to remain the same at the expense of some more unnatural transitions between the masked and unmasked areas.",hl,We,Ml,we,yl,Te,nn="Image features - like quality and “creativity” - are dependent on pipeline parameters. Knowing what these parameters do is important for getting the results you want. Let’s take a look at the most important parameters and see how changing them affects the output.",bl,Ue,Jl,je,sn="<code>strength</code> is a measure of how much noise is added to the base image, which influences how similar the output is to the base image.",Zl,Ge,pn="<li>📈 a high <code>strength</code> value means more noise is added to an image and the denoising process takes longer, but you’ll get higher quality images that are more different from the base image</li> <li>📉 a low <code>strength</code> value means less noise is added to an image and the denoising process is faster, but the image quality may not be as great and the generated image resembles the base image more</li>",Wl,ke,wl,x,mn='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.6.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.6</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-0.8.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 0.8</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-strength-1.0.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">strength = 1.0</figcaption></div>',Tl,Be,Ul,ve,on="<code>guidance_scale</code> affects how aligned the text prompt and generated image are.",jl,Ie,rn="<li>📈 a high <code>guidance_scale</code> value means the prompt and generated image are closely aligned, so the output is a stricter interpretation of the prompt</li> <li>📉 a low <code>guidance_scale</code> value means the prompt and generated image are more loosely aligned, so the output may be more varied from the prompt</li>",Gl,Xe,cn="You can use <code>strength</code> and <code>guidance_scale</code> together for more control over how expressive the model is. For example, a combination high <code>strength</code> and <code>guidance_scale</code> values gives the model the most creative freedom.",kl,_e,Bl,$,dn='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-2.5.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 2.5</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-7.5.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 7.5</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-guidance-12.5.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">guidance_scale = 12.5</figcaption></div>',vl,Ye,Il,Fe,gn="A negative prompt assumes the opposite role of a prompt; it guides the model away from generating certain things in an image. This is useful for quickly improving image quality and preventing the model from generating things you don’t want.",Xl,Re,_l,C,un='<figure><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-negative.png"/> <figcaption class="text-center">negative_prompt = &quot;bad architecture, unstable, poor details, blurry&quot;</figcaption></figure>',Yl,Ve,Fl,xe,fn='A method for increasing the inpainting image quality is to use the <a href="https://huggingface.co/docs/diffusers/v0.25.0/en/api/pipelines/stable_diffusion/inpaint#diffusers.StableDiffusionInpaintPipeline.__call__.padding_mask_crop" rel="nofollow"><code>padding_mask_crop</code></a> parameter. When enabled, this option crops the masked area with some user-specified padding and it’ll also crop the same area from the original image. Both the image and mask are upscaled to a higher resolution for inpainting, and then overlaid on the original image. This is a quick and easy way to improve image quality without using a separate pipeline like <a href="/docs/diffusers/v0.33.1/en/api/pipelines/stable_diffusion/upscale#diffusers.StableDiffusionUpscalePipeline">StableDiffusionUpscalePipeline</a>.',Rl,$e,hn="Add the <code>padding_mask_crop</code> parameter to the pipeline call and set it to the desired padding value.",Vl,Ce,xl,N,Mn='<div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/baseline_inpaint.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">default inpaint image</figcaption></div> <div><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/padding_mask_crop_inpaint.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint image with `padding_mask_crop` enabled</figcaption></div>',$l,Ne,Cl,Qe,yn='<a href="/docs/diffusers/v0.33.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting">AutoPipelineForInpainting</a> can be chained with other 🤗 Diffusers pipelines to edit their outputs. This is often useful for improving the output quality from your other diffusion pipelines, and if you’re using multiple pipelines, it can be more memory-efficient to chain them together to keep the outputs in latent space and reuse the same pipeline components.',Nl,Se,Ql,He,bn="Chaining a text-to-image and inpainting pipeline allows you to inpaint the generated image, and you don’t have to provide a base image to begin with. This makes it convenient to edit your favorite text-to-image outputs without having to generate an entirely new image.",Sl,ze,Jn="Start with the text-to-image pipeline to create a castle:",Hl,Ee,zl,Le,Zn="Load the mask image of the output from above:",El,qe,Ll,Ae,Wn="And let’s inpaint the masked area with a waterfall:",ql,De,Al,Q,wn='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">text-to-image</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-text-chain-out.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint</figcaption></div>',Dl,Pe,Pl,Ke,Tn="You can also chain an inpainting pipeline before another pipeline like image-to-image or an upscaler to improve the quality.",Kl,Oe,Un="Begin by inpainting an image:",Ol,ea,et,aa,jn="Now let’s pass the image to another inpainting pipeline with SDXL’s refiner model to enhance the image details and quality:",at,la,lt,S,tt,ta,Gn='Finally, you can pass this image to an image-to-image pipeline to put the finishing touches on it. It is more efficient to use the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForImage2Image.from_pipe">from_pipe()</a> method to reuse the existing pipeline components, and avoid unnecessarily loading all the pipeline components into memory again.',nt,na,st,H,kn='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">initial image</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-chain.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">inpaint</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-to-image-final.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">image-to-image</figcaption></div>',it,sa,Bn="Image-to-image and inpainting are actually very similar tasks. Image-to-image generates a new image that resembles the existing provided image. Inpainting does the same thing, but it only transforms the image area defined by the mask and the rest of the image is unchanged. You can think of inpainting as a more precise tool for making specific changes and image-to-image has a broader scope for making more sweeping changes.",pt,ia,mt,pa,vn="Getting an image to look exactly the way you want is challenging because the denoising process is random. While you can control certain aspects of generation by configuring parameters like <code>negative_prompt</code>, there are better and more efficient methods for controlling image generation.",ot,ma,rt,oa,In='Prompt weighting provides a quantifiable way to scale the representation of concepts in a prompt. You can use it to increase or decrease the magnitude of the text embedding vector for each concept in the prompt, which subsequently determines how much of each concept is generated. The <a href="https://github.com/damian0815/compel" rel="nofollow">Compel</a> library offers an intuitive syntax for scaling the prompt weights and generating the embeddings. Learn how to create the embeddings in the <a href="../using-diffusers/weighted_prompts">Prompt weighting</a> guide.',ct,ra,Xn='Once you’ve generated the embeddings, pass them to the <code>prompt_embeds</code> (and <code>negative_prompt_embeds</code> if you’re using a negative prompt) parameter in the <a href="/docs/diffusers/v0.33.1/en/api/pipelines/auto_pipeline#diffusers.AutoPipelineForInpainting">AutoPipelineForInpainting</a>. The embeddings replace the <code>prompt</code> parameter:',dt,ca,gt,da,ut,ga,_n="ControlNet models are used with other diffusion models like Stable Diffusion, and they provide an even more flexible and accurate way to control how an image is generated. A ControlNet accepts an additional conditioning image input that guides the diffusion model to preserve the features in it.",ft,ua,Yn="For example, let’s condition an image with a ControlNet pretrained on inpaint images:",ht,fa,Mt,ha,Fn="Now generate an image from the base, mask and control images. You’ll notice features of the base image are strongly preserved in the generated image.",yt,Ma,bt,ya,Rn='You can take this a step further and chain it with an image-to-image pipeline to apply a new <a href="https://huggingface.co/nitrosocke/elden-ring-diffusion" rel="nofollow">style</a>:',Jt,ba,Zt,z,Vn='<div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">initial image</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-controlnet.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">ControlNet inpaint</figcaption></div> <div class="flex-1"><img class="rounded-xl" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint-img2img.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">image-to-image</figcaption></div>',Wt,Ja,wt,Za,xn='It can be difficult and slow to run diffusion models if you’re resource constrained, but it doesn’t have to be with a few optimization tricks. One of the biggest (and easiest) optimizations you can enable is switching to memory-efficient attention. If you’re using PyTorch 2.0, <a href="../optimization/torch2.0#scaled-dot-product-attention">scaled-dot product attention</a> is automatically enabled and you don’t need to do anything else. For non-PyTorch 2.0 users, you can install and use <a href="../optimization/xformers">xFormers</a>’s implementation of memory-efficient attention. Both options reduce memory usage and accelerate inference.',Tt,Wa,$n="You can also offload the model to the CPU to save even more memory:",Ut,wa,jt,Ta,Cn='To speed-up your inference code even more, use <a href="../optimization/torch2.0#torchcompile"><code>torch_compile</code></a>. You should wrap <code>torch.compile</code> around the most intensive component in the pipeline which is typically the UNet:',Gt,Ua,kt,ja,Nn='Learn more in the <a href="../optimization/memory">Reduce memory usage</a> and <a href="../optimization/torch2.0">Torch 2.0</a> guides.',Bt,Ga,vt,Ba,It;return M=new w({props:{title:"Inpainting",local:"inpainting",headingTag:"h1"}}),U=new as({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/inpaint.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/inpaint.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/tensorflow/inpaint.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/inpaint.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/inpaint.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/tensorflow/inpaint.ipynb"}]}}),A=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJrYW5kaW5za3ktY29tbXVuaXR5JTJGa2FuZGluc2t5LTItMi1kZWNvZGVyLWlucGFpbnQlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMEEpJTBBcGlwZWxpbmUuZW5hYmxlX21vZGVsX2NwdV9vZmZsb2FkKCklMEElMjMlMjByZW1vdmUlMjBmb2xsb3dpbmclMjBsaW5lJTIwaWYlMjB4Rm9ybWVycyUyMGlzJTIwbm90JTIwaW5zdGFsbGVkJTIwb3IlMjB5b3UlMjBoYXZlJTIwUHlUb3JjaCUyMDIuMCUyMG9yJTIwaGlnaGVyJTIwaW5zdGFsbGVkJTBBcGlwZWxpbmUuZW5hYmxlX3hmb3JtZXJzX21lbW9yeV9lZmZpY2llbnRfYXR0ZW50aW9uKCk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;kandinsky-community/kandinsky-2-2-decoder-inpaint&quot;</span>, torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()`,wrap:!1}}),k=new En({props:{$$slots:{default:[ts]},$$scope:{ctx:T}}}),D=new b({props:{code:"aW5pdF9pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGaW5wYWludC5wbmclMjIpJTBBbWFza19pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGaW5wYWludF9tYXNrLnBuZyUyMik=",highlighted:`init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)`,wrap:!1}}),P=new b({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyYSUyMGJsYWNrJTIwY2F0JTIwd2l0aCUyMGdsb3dpbmclMjBleWVzJTJDJTIwY3V0ZSUyQyUyMGFkb3JhYmxlJTJDJTIwZGlzbmV5JTJDJTIwcGl4YXIlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyQyUyMDhrJTIyJTBBbmVnYXRpdmVfcHJvbXB0JTIwJTNEJTIwJTIyYmFkJTIwYW5hdG9teSUyQyUyMGRlZm9ybWVkJTJDJTIwdWdseSUyQyUyMGRpc2ZpZ3VyZWQlMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUzRHByb21wdCUyQyUyMG5lZ2F0aXZlX3Byb21wdCUzRG5lZ2F0aXZlX3Byb21wdCUyQyUyMGltYWdlJTNEaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlM0RtYXNrX2ltYWdlKS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTJDJTIwaW1hZ2UlNUQlMkMlMjByb3dzJTNEMSUyQyUyMGNvbHMlM0QzKQ==",highlighted:`prompt = <span class="hljs-string">&quot;a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k&quot;</span>
negative_prompt = <span class="hljs-string">&quot;bad anatomy, deformed, ugly, disfigured&quot;</span>
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),K=new w({props:{title:"Create a mask image",local:"create-a-mask-image",headingTag:"h2"}}),ae=new w({props:{title:"Mask blur",local:"mask-blur",headingTag:"h3"}}),ne=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTBBZnJvbSUyMFBJTCUyMGltcG9ydCUyMEltYWdlJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMjJzdGFibGUtZGlmZnVzaW9uLXYxLTUlMkZzdGFibGUtZGlmZnVzaW9uLXYxLTUlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYpLnRvKCdjdWRhJyklMEElMEFtYXNrJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZZaVlpWHUlMkZ0ZXN0aW5nLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGc2Vhc2hvcmVfbWFzay5wbmclMjIpJTBBYmx1cnJlZF9tYXNrJTIwJTNEJTIwcGlwZWxpbmUubWFza19wcm9jZXNzb3IuYmx1cihtYXNrJTJDJTIwYmx1cl9mYWN0b3IlM0QzMyklMEFibHVycmVkX21hc2s=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image

pipeline = AutoPipelineForInpainting.from_pretrained(<span class="hljs-string">&quot;stable-diffusion-v1-5/stable-diffusion-v1-5&quot;</span>, torch_dtype=torch.float16).to(<span class="hljs-string">&#x27;cuda&#x27;</span>)

mask = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png&quot;</span>)
blurred_mask = pipeline.mask_processor.blur(mask, blur_factor=<span class="hljs-number">33</span>)
blurred_mask`,wrap:!1}}),se=new w({props:{title:"Popular models",local:"popular-models",headingTag:"h2"}}),pe=new w({props:{title:"Stable Diffusion Inpainting",local:"stable-diffusion-inpainting",headingTag:"h3"}}),oe=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJydW53YXltbCUyRnN0YWJsZS1kaWZmdXNpb24taW5wYWludGluZyUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50X21hc2sucG5nJTIyKSUwQSUwQWdlbmVyYXRvciUyMCUzRCUyMHRvcmNoLkdlbmVyYXRvciglMjJjdWRhJTIyKS5tYW51YWxfc2VlZCg5MiklMEFwcm9tcHQlMjAlM0QlMjAlMjJjb25jZXB0JTIwYXJ0JTIwZGlnaXRhbCUyMHBhaW50aW5nJTIwb2YlMjBhbiUyMGVsdmVuJTIwY2FzdGxlJTJDJTIwaW5zcGlyZWQlMjBieSUyMGxvcmQlMjBvZiUyMHRoZSUyMHJpbmdzJTJDJTIwaGlnaGx5JTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEcHJvbXB0JTJDJTIwaW1hZ2UlM0Rpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUzRG1hc2tfaW1hZ2UlMkMlMjBnZW5lcmF0b3IlM0RnZW5lcmF0b3IpLmltYWdlcyU1QjAlNUQlMEFtYWtlX2ltYWdlX2dyaWQoJTVCaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlMkMlMjBpbWFnZSU1RCUyQyUyMHJvd3MlM0QxJTJDJTIwY29scyUzRDMp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

generator = torch.Generator(<span class="hljs-string">&quot;cuda&quot;</span>).manual_seed(<span class="hljs-number">92</span>)
prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),re=new w({props:{title:"Stable Diffusion XL (SDXL) Inpainting",local:"stable-diffusion-xl-sdxl-inpainting",headingTag:"h3"}}),de=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJkaWZmdXNlcnMlMkZzdGFibGUtZGlmZnVzaW9uLXhsLTEuMC1pbnBhaW50aW5nLTAuMSUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50X21hc2sucG5nJTIyKSUwQSUwQWdlbmVyYXRvciUyMCUzRCUyMHRvcmNoLkdlbmVyYXRvciglMjJjdWRhJTIyKS5tYW51YWxfc2VlZCg5MiklMEFwcm9tcHQlMjAlM0QlMjAlMjJjb25jZXB0JTIwYXJ0JTIwZGlnaXRhbCUyMHBhaW50aW5nJTIwb2YlMjBhbiUyMGVsdmVuJTIwY2FzdGxlJTJDJTIwaW5zcGlyZWQlMjBieSUyMGxvcmQlMjBvZiUyMHRoZSUyMHJpbmdzJTJDJTIwaGlnaGx5JTIwZGV0YWlsZWQlMkMlMjA4ayUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEcHJvbXB0JTJDJTIwaW1hZ2UlM0Rpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUzRG1hc2tfaW1hZ2UlMkMlMjBnZW5lcmF0b3IlM0RnZW5lcmF0b3IpLmltYWdlcyU1QjAlNUQlMEFtYWtlX2ltYWdlX2dyaWQoJTVCaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlMkMlMjBpbWFnZSU1RCUyQyUyMHJvd3MlM0QxJTJDJTIwY29scyUzRDMp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;diffusers/stable-diffusion-xl-1.0-inpainting-0.1&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

generator = torch.Generator(<span class="hljs-string">&quot;cuda&quot;</span>).manual_seed(<span class="hljs-number">92</span>)
prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),ge=new w({props:{title:"Kandinsky 2.2 Inpainting",local:"kandinsky-22-inpainting",headingTag:"h3"}}),fe=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJrYW5kaW5za3ktY29tbXVuaXR5JTJGa2FuZGluc2t5LTItMi1kZWNvZGVyLWlucGFpbnQlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMEEpJTBBcGlwZWxpbmUuZW5hYmxlX21vZGVsX2NwdV9vZmZsb2FkKCklMEElMjMlMjByZW1vdmUlMjBmb2xsb3dpbmclMjBsaW5lJTIwaWYlMjB4Rm9ybWVycyUyMGlzJTIwbm90JTIwaW5zdGFsbGVkJTIwb3IlMjB5b3UlMjBoYXZlJTIwUHlUb3JjaCUyMDIuMCUyMG9yJTIwaGlnaGVyJTIwaW5zdGFsbGVkJTBBcGlwZWxpbmUuZW5hYmxlX3hmb3JtZXJzX21lbW9yeV9lZmZpY2llbnRfYXR0ZW50aW9uKCklMEElMEElMjMlMjBsb2FkJTIwYmFzZSUyMGFuZCUyMG1hc2slMjBpbWFnZSUwQWluaXRfaW1hZ2UlMjAlM0QlMjBsb2FkX2ltYWdlKCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmh1Z2dpbmdmYWNlJTJGZG9jdW1lbnRhdGlvbi1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRmRpZmZ1c2VycyUyRmlucGFpbnQucG5nJTIyKSUwQW1hc2tfaW1hZ2UlMjAlM0QlMjBsb2FkX2ltYWdlKCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmh1Z2dpbmdmYWNlJTJGZG9jdW1lbnRhdGlvbi1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRmRpZmZ1c2VycyUyRmlucGFpbnRfbWFzay5wbmclMjIpJTBBJTBBZ2VuZXJhdG9yJTIwJTNEJTIwdG9yY2guR2VuZXJhdG9yKCUyMmN1ZGElMjIpLm1hbnVhbF9zZWVkKDkyKSUwQXByb21wdCUyMCUzRCUyMCUyMmNvbmNlcHQlMjBhcnQlMjBkaWdpdGFsJTIwcGFpbnRpbmclMjBvZiUyMGFuJTIwZWx2ZW4lMjBjYXN0bGUlMkMlMjBpbnNwaXJlZCUyMGJ5JTIwbG9yZCUyMG9mJTIwdGhlJTIwcmluZ3MlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyQyUyMDhrJTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBpbWFnZSUzRGluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSUyQyUyMGdlbmVyYXRvciUzRGdlbmVyYXRvcikuaW1hZ2VzJTVCMCU1RCUwQW1ha2VfaW1hZ2VfZ3JpZCglNUJpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUyQyUyMGltYWdlJTVEJTJDJTIwcm93cyUzRDElMkMlMjBjb2xzJTNEMyk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;kandinsky-community/kandinsky-2-2-decoder-inpaint&quot;</span>, torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

generator = torch.Generator(<span class="hljs-string">&quot;cuda&quot;</span>).manual_seed(<span class="hljs-number">92</span>)
prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, generator=generator).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),he=new w({props:{title:"Non-inpaint specific checkpoints",local:"non-inpaint-specific-checkpoints",headingTag:"h2"}}),Y=new Ln({props:{id:"regular-specific",options:["stable-diffusion-v1-5/stable-diffusion-v1-5","runwayml/stable-diffusion-inpainting"],$$slots:{default:[is]},$$scope:{ctx:T}}}),R=new Ln({props:{id:"inpaint",options:["stable-diffusion-v1-5/stable-diffusion-v1-5","runwayml/stable-diffusion-inpaint"],$$slots:{default:[os]},$$scope:{ctx:T}}}),We=new b({props:{code:"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",highlighted:`<span class="hljs-keyword">import</span> PIL
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

device = <span class="hljs-string">&quot;cuda&quot;</span>
pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>,
    torch_dtype=torch.float16,
)
pipeline = pipeline.to(device)

img_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png&quot;</span>
mask_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png&quot;</span>

init_image = load_image(img_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))
mask_image = load_image(mask_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))

prompt = <span class="hljs-string">&quot;Face of a yellow cat, high resolution, sitting on a park bench&quot;</span>
repainted_image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]
repainted_image.save(<span class="hljs-string">&quot;repainted_image.png&quot;</span>)

unmasked_unchanged_image = pipeline.image_processor.apply_overlay(mask_image, init_image, repainted_image)
unmasked_unchanged_image.save(<span class="hljs-string">&quot;force_unmasked_unchanged.png&quot;</span>)
make_image_grid([init_image, mask_image, repainted_image, unmasked_unchanged_image], rows=<span class="hljs-number">2</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),we=new w({props:{title:"Configure pipeline parameters",local:"configure-pipeline-parameters",headingTag:"h2"}}),Ue=new w({props:{title:"Strength",local:"strength",headingTag:"h3"}}),ke=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJydW53YXltbCUyRnN0YWJsZS1kaWZmdXNpb24taW5wYWludGluZyUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50X21hc2sucG5nJTIyKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMmNvbmNlcHQlMjBhcnQlMjBkaWdpdGFsJTIwcGFpbnRpbmclMjBvZiUyMGFuJTIwZWx2ZW4lMjBjYXN0bGUlMkMlMjBpbnNwaXJlZCUyMGJ5JTIwbG9yZCUyMG9mJTIwdGhlJTIwcmluZ3MlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyQyUyMDhrJTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBpbWFnZSUzRGluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSUyQyUyMHN0cmVuZ3RoJTNEMC42KS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTJDJTIwaW1hZ2UlNUQlMkMlMjByb3dzJTNEMSUyQyUyMGNvbHMlM0QzKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, strength=<span class="hljs-number">0.6</span>).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),Be=new w({props:{title:"Guidance scale",local:"guidance-scale",headingTag:"h3"}}),_e=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJydW53YXltbCUyRnN0YWJsZS1kaWZmdXNpb24taW5wYWludGluZyUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50X21hc2sucG5nJTIyKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMmNvbmNlcHQlMjBhcnQlMjBkaWdpdGFsJTIwcGFpbnRpbmclMjBvZiUyMGFuJTIwZWx2ZW4lMjBjYXN0bGUlMkMlMjBpbnNwaXJlZCUyMGJ5JTIwbG9yZCUyMG9mJTIwdGhlJTIwcmluZ3MlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyQyUyMDhrJTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBpbWFnZSUzRGluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSUyQyUyMGd1aWRhbmNlX3NjYWxlJTNEMi41KS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTJDJTIwaW1hZ2UlNUQlMkMlMjByb3dzJTNEMSUyQyUyMGNvbHMlM0QzKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, guidance_scale=<span class="hljs-number">2.5</span>).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),Ye=new w({props:{title:"Negative prompt",local:"negative-prompt",headingTag:"h3"}}),Re=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTJDJTIwbWFrZV9pbWFnZV9ncmlkJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJydW53YXltbCUyRnN0YWJsZS1kaWZmdXNpb24taW5wYWludGluZyUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBJTIzJTIwbG9hZCUyMGJhc2UlMjBhbmQlMjBtYXNrJTIwaW1hZ2UlMEFpbml0X2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50LnBuZyUyMiklMEFtYXNrX2ltYWdlJTIwJTNEJTIwbG9hZF9pbWFnZSglMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZodWdnaW5nZmFjZSUyRmRvY3VtZW50YXRpb24taW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZkaWZmdXNlcnMlMkZpbnBhaW50X21hc2sucG5nJTIyKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMmNvbmNlcHQlMjBhcnQlMjBkaWdpdGFsJTIwcGFpbnRpbmclMjBvZiUyMGFuJTIwZWx2ZW4lMjBjYXN0bGUlMkMlMjBpbnNwaXJlZCUyMGJ5JTIwbG9yZCUyMG9mJTIwdGhlJTIwcmluZ3MlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyQyUyMDhrJTIyJTBBbmVnYXRpdmVfcHJvbXB0JTIwJTNEJTIwJTIyYmFkJTIwYXJjaGl0ZWN0dXJlJTJDJTIwdW5zdGFibGUlMkMlMjBwb29yJTIwZGV0YWlscyUyQyUyMGJsdXJyeSUyMiUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEcHJvbXB0JTJDJTIwbmVnYXRpdmVfcHJvbXB0JTNEbmVnYXRpdmVfcHJvbXB0JTJDJTIwaW1hZ2UlM0Rpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUzRG1hc2tfaW1hZ2UpLmltYWdlcyU1QjAlNUQlMEFtYWtlX2ltYWdlX2dyaWQoJTVCaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlMkMlMjBpbWFnZSU1RCUyQyUyMHJvd3MlM0QxJTJDJTIwY29scyUzRDMp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
negative_prompt = <span class="hljs-string">&quot;bad architecture, unstable, poor details, blurry&quot;</span>
image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),Ve=new w({props:{title:"Padding mask crop",local:"padding-mask-crop",headingTag:"h3"}}),Ce=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBsb2FkX2ltYWdlJTBBZnJvbSUyMFBJTCUyMGltcG9ydCUyMEltYWdlJTBBJTBBZ2VuZXJhdG9yJTIwJTNEJTIwdG9yY2guR2VuZXJhdG9yKGRldmljZSUzRCdjdWRhJykubWFudWFsX3NlZWQoMCklMEFwaXBlbGluZSUyMCUzRCUyMEF1dG9QaXBlbGluZUZvcklucGFpbnRpbmcuZnJvbV9wcmV0cmFpbmVkKCUyMnN0YWJsZS1kaWZmdXNpb24tdjEtNSUyRnN0YWJsZS1kaWZmdXNpb24tdjEtNSUyMiUyQyUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNikudG8oJ2N1ZGEnKSUwQSUwQWJhc2UlMjAlM0QlMjBsb2FkX2ltYWdlKCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRllpWWlYdSUyRnRlc3RpbmctaW1hZ2VzJTJGcmVzb2x2ZSUyRm1haW4lMkZzZWFzaG9yZS5wbmclMjIpJTBBbWFzayUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGWWlZaVh1JTJGdGVzdGluZy1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRnNlYXNob3JlX21hc2sucG5nJTIyKSUwQSUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUoJTIyYm9hdCUyMiUyQyUyMGltYWdlJTNEYmFzZSUyQyUyMG1hc2tfaW1hZ2UlM0RtYXNrJTJDJTIwc3RyZW5ndGglM0QwLjc1JTJDJTIwZ2VuZXJhdG9yJTNEZ2VuZXJhdG9yJTJDJTIwcGFkZGluZ19tYXNrX2Nyb3AlM0QzMikuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image

generator = torch.Generator(device=<span class="hljs-string">&#x27;cuda&#x27;</span>).manual_seed(<span class="hljs-number">0</span>)
pipeline = AutoPipelineForInpainting.from_pretrained(<span class="hljs-string">&quot;stable-diffusion-v1-5/stable-diffusion-v1-5&quot;</span>, torch_dtype=torch.float16).to(<span class="hljs-string">&#x27;cuda&#x27;</span>)

base = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore.png&quot;</span>)
mask = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/YiYiXu/testing-images/resolve/main/seashore_mask.png&quot;</span>)

image = pipeline(<span class="hljs-string">&quot;boat&quot;</span>, image=base, mask_image=mask, strength=<span class="hljs-number">0.75</span>, generator=generator, padding_mask_crop=<span class="hljs-number">32</span>).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),Ne=new w({props:{title:"Chained inpainting pipelines",local:"chained-inpainting-pipelines",headingTag:"h2"}}),Se=new w({props:{title:"Text-to-image-to-inpaint",local:"text-to-image-to-inpaint",headingTag:"h3"}}),Ee=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9yVGV4dDJJbWFnZSUyQyUyMEF1dG9QaXBlbGluZUZvcklucGFpbnRpbmclMEFmcm9tJTIwZGlmZnVzZXJzLnV0aWxzJTIwaW1wb3J0JTIwbG9hZF9pbWFnZSUyQyUyMG1ha2VfaW1hZ2VfZ3JpZCUwQSUwQXBpcGVsaW5lJTIwJTNEJTIwQXV0b1BpcGVsaW5lRm9yVGV4dDJJbWFnZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyc3RhYmxlLWRpZmZ1c2lvbi12MS01JTJGc3RhYmxlLWRpZmZ1c2lvbi12MS01JTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTIwdmFyaWFudCUzRCUyMmZwMTYlMjIlMkMlMjB1c2Vfc2FmZXRlbnNvcnMlM0RUcnVlJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBdGV4dDJpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKCUyMmNvbmNlcHQlMjBhcnQlMjBkaWdpdGFsJTIwcGFpbnRpbmclMjBvZiUyMGFuJTIwZWx2ZW4lMjBjYXN0bGUlMkMlMjBpbnNwaXJlZCUyMGJ5JTIwbG9yZCUyMG9mJTIwdGhlJTIwcmluZ3MlMkMlMjBoaWdobHklMjBkZXRhaWxlZCUyQyUyMDhrJTIyKS5pbWFnZXMlNUIwJTVE",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForText2Image, AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForText2Image.from_pretrained(
    <span class="hljs-string">&quot;stable-diffusion-v1-5/stable-diffusion-v1-5&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

text2image = pipeline(<span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>).images[<span class="hljs-number">0</span>]`,wrap:!1}}),qe=new b({props:{code:"bWFza19pbWFnZSUyMCUzRCUyMGxvYWRfaW1hZ2UoJTIyaHR0cHMlM0ElMkYlMkZodWdnaW5nZmFjZS5jbyUyRmRhdGFzZXRzJTJGaHVnZ2luZ2ZhY2UlMkZkb2N1bWVudGF0aW9uLWltYWdlcyUyRnJlc29sdmUlMkZtYWluJTJGZGlmZnVzZXJzJTJGaW5wYWludF90ZXh0LWNoYWluLW1hc2sucG5nJTIyKQ==",highlighted:'mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_text-chain-mask.png&quot;</span>)',wrap:!1}}),De=new b({props:{code:"cGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJrYW5kaW5za3ktY29tbXVuaXR5JTJGa2FuZGluc2t5LTItMi1kZWNvZGVyLWlucGFpbnQlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMEEpJTBBcGlwZWxpbmUuZW5hYmxlX21vZGVsX2NwdV9vZmZsb2FkKCklMEElMjMlMjByZW1vdmUlMjBmb2xsb3dpbmclMjBsaW5lJTIwaWYlMjB4Rm9ybWVycyUyMGlzJTIwbm90JTIwaW5zdGFsbGVkJTIwb3IlMjB5b3UlMjBoYXZlJTIwUHlUb3JjaCUyMDIuMCUyMG9yJTIwaGlnaGVyJTIwaW5zdGFsbGVkJTBBcGlwZWxpbmUuZW5hYmxlX3hmb3JtZXJzX21lbW9yeV9lZmZpY2llbnRfYXR0ZW50aW9uKCklMEElMEFwcm9tcHQlMjAlM0QlMjAlMjJkaWdpdGFsJTIwcGFpbnRpbmclMjBvZiUyMGElMjBmYW50YXN5JTIwd2F0ZXJmYWxsJTJDJTIwY2xvdWR5JTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBpbWFnZSUzRHRleHQyaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSkuaW1hZ2VzJTVCMCU1RCUwQW1ha2VfaW1hZ2VfZ3JpZCglNUJ0ZXh0MmltYWdlJTJDJTIwbWFza19pbWFnZSUyQyUyMGltYWdlJTVEJTJDJTIwcm93cyUzRDElMkMlMjBjb2xzJTNEMyk=",highlighted:`pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;kandinsky-community/kandinsky-2-2-decoder-inpaint&quot;</span>, torch_dtype=torch.float16
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

prompt = <span class="hljs-string">&quot;digital painting of a fantasy waterfall, cloudy&quot;</span>
image = pipeline(prompt=prompt, image=text2image, mask_image=mask_image).images[<span class="hljs-number">0</span>]
make_image_grid([text2image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),Pe=new w({props:{title:"Inpaint-to-image-to-image",local:"inpaint-to-image-to-image",headingTag:"h3"}}),ea=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUyQyUyMEF1dG9QaXBlbGluZUZvckltYWdlMkltYWdlJTBBZnJvbSUyMGRpZmZ1c2Vycy51dGlscyUyMGltcG9ydCUyMGxvYWRfaW1hZ2UlMkMlMjBtYWtlX2ltYWdlX2dyaWQlMEElMEFwaXBlbGluZSUyMCUzRCUyMEF1dG9QaXBlbGluZUZvcklucGFpbnRpbmcuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnJ1bndheW1sJTJGc3RhYmxlLWRpZmZ1c2lvbi1pbnBhaW50aW5nJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTIwdmFyaWFudCUzRCUyMmZwMTYlMjIlMEEpJTBBcGlwZWxpbmUuZW5hYmxlX21vZGVsX2NwdV9vZmZsb2FkKCklMEElMjMlMjByZW1vdmUlMjBmb2xsb3dpbmclMjBsaW5lJTIwaWYlMjB4Rm9ybWVycyUyMGlzJTIwbm90JTIwaW5zdGFsbGVkJTIwb3IlMjB5b3UlMjBoYXZlJTIwUHlUb3JjaCUyMDIuMCUyMG9yJTIwaGlnaGVyJTIwaW5zdGFsbGVkJTBBcGlwZWxpbmUuZW5hYmxlX3hmb3JtZXJzX21lbW9yeV9lZmZpY2llbnRfYXR0ZW50aW9uKCklMEElMEElMjMlMjBsb2FkJTIwYmFzZSUyMGFuZCUyMG1hc2slMjBpbWFnZSUwQWluaXRfaW1hZ2UlMjAlM0QlMjBsb2FkX2ltYWdlKCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmh1Z2dpbmdmYWNlJTJGZG9jdW1lbnRhdGlvbi1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRmRpZmZ1c2VycyUyRmlucGFpbnQucG5nJTIyKSUwQW1hc2tfaW1hZ2UlMjAlM0QlMjBsb2FkX2ltYWdlKCUyMmh0dHBzJTNBJTJGJTJGaHVnZ2luZ2ZhY2UuY28lMkZkYXRhc2V0cyUyRmh1Z2dpbmdmYWNlJTJGZG9jdW1lbnRhdGlvbi1pbWFnZXMlMkZyZXNvbHZlJTJGbWFpbiUyRmRpZmZ1c2VycyUyRmlucGFpbnRfbWFzay5wbmclMjIpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyY29uY2VwdCUyMGFydCUyMGRpZ2l0YWwlMjBwYWludGluZyUyMG9mJTIwYW4lMjBlbHZlbiUyMGNhc3RsZSUyQyUyMGluc3BpcmVkJTIwYnklMjBsb3JkJTIwb2YlMjB0aGUlMjByaW5ncyUyQyUyMGhpZ2hseSUyMGRldGFpbGVkJTJDJTIwOGslMjIlMEFpbWFnZV9pbnBhaW50aW5nJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEcHJvbXB0JTJDJTIwaW1hZ2UlM0Rpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUzRG1hc2tfaW1hZ2UpLmltYWdlcyU1QjAlNUQlMEElMEElMjMlMjByZXNpemUlMjBpbWFnZSUyMHRvJTIwMTAyNHgxMDI0JTIwZm9yJTIwU0RYTCUwQWltYWdlX2lucGFpbnRpbmclMjAlM0QlMjBpbWFnZV9pbnBhaW50aW5nLnJlc2l6ZSgoMTAyNCUyQyUyMDEwMjQpKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting, AutoPipelineForImage2Image
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image_inpainting = pipeline(prompt=prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]

<span class="hljs-comment"># resize image to 1024x1024 for SDXL</span>
image_inpainting = image_inpainting.resize((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>))`,wrap:!1}}),la=new b({props:{code:"cGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbnBhaW50aW5nLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtcmVmaW5lci0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUwQSklMEFwaXBlbGluZS5lbmFibGVfbW9kZWxfY3B1X29mZmxvYWQoKSUwQSUyMyUyMHJlbW92ZSUyMGZvbGxvd2luZyUyMGxpbmUlMjBpZiUyMHhGb3JtZXJzJTIwaXMlMjBub3QlMjBpbnN0YWxsZWQlMjBvciUyMHlvdSUyMGhhdmUlMjBQeVRvcmNoJTIwMi4wJTIwb3IlMjBoaWdoZXIlMjBpbnN0YWxsZWQlMEFwaXBlbGluZS5lbmFibGVfeGZvcm1lcnNfbWVtb3J5X2VmZmljaWVudF9hdHRlbnRpb24oKSUwQSUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTNEcHJvbXB0JTJDJTIwaW1hZ2UlM0RpbWFnZV9pbnBhaW50aW5nJTJDJTIwbWFza19pbWFnZSUzRG1hc2tfaW1hZ2UlMkMlMjBvdXRwdXRfdHlwZSUzRCUyMmxhdGVudCUyMikuaW1hZ2VzJTVCMCU1RA==",highlighted:`pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-refiner-1.0&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image_inpainting, mask_image=mask_image, output_type=<span class="hljs-string">&quot;latent&quot;</span>).images[<span class="hljs-number">0</span>]`,wrap:!1}}),S=new En({props:{$$slots:{default:[rs]},$$scope:{ctx:T}}}),na=new b({props:{code:"cGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbWFnZTJJbWFnZS5mcm9tX3BpcGUocGlwZWxpbmUpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlM0Rwcm9tcHQlMkMlMjBpbWFnZSUzRGltYWdlKS5pbWFnZXMlNUIwJTVEJTBBbWFrZV9pbWFnZV9ncmlkKCU1QmluaXRfaW1hZ2UlMkMlMjBtYXNrX2ltYWdlJTJDJTIwaW1hZ2VfaW5wYWludGluZyUyQyUyMGltYWdlJTVEJTJDJTIwcm93cyUzRDIlMkMlMjBjb2xzJTNEMik=",highlighted:`pipeline = AutoPipelineForImage2Image.from_pipe(pipeline)
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt=prompt, image=image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image_inpainting, image], rows=<span class="hljs-number">2</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),ia=new w({props:{title:"Control image generation",local:"control-image-generation",headingTag:"h2"}}),ma=new w({props:{title:"Prompt weighting",local:"prompt-weighting",headingTag:"h3"}}),ca=new b({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGlmZnVzZXJzJTIwaW1wb3J0JTIwQXV0b1BpcGVsaW5lRm9ySW5wYWludGluZyUwQWZyb20lMjBkaWZmdXNlcnMudXRpbHMlMjBpbXBvcnQlMjBtYWtlX2ltYWdlX2dyaWQlMEElMEFwaXBlbGluZSUyMCUzRCUyMEF1dG9QaXBlbGluZUZvcklucGFpbnRpbmcuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnJ1bndheW1sJTJGc3RhYmxlLWRpZmZ1c2lvbi1pbnBhaW50aW5nJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHRfZW1iZWRzJTNEcHJvbXB0X2VtYmVkcyUyQyUyMCUyMyUyMGdlbmVyYXRlZCUyMGZyb20lMjBDb21wZWwlMEElMjAlMjAlMjAlMjBuZWdhdGl2ZV9wcm9tcHRfZW1iZWRzJTNEbmVnYXRpdmVfcHJvbXB0X2VtYmVkcyUyQyUyMCUyMyUyMGdlbmVyYXRlZCUyMGZyb20lMjBDb21wZWwlMEElMjAlMjAlMjAlMjBpbWFnZSUzRGluaXRfaW1hZ2UlMkMlMEElMjAlMjAlMjAlMjBtYXNrX2ltYWdlJTNEbWFza19pbWFnZSUwQSkuaW1hZ2VzJTVCMCU1RCUwQW1ha2VfaW1hZ2VfZ3JpZCglNUJpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUyQyUyMGltYWdlJTVEJTJDJTIwcm93cyUzRDElMkMlMjBjb2xzJTNEMyk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForInpainting
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> make_image_grid

pipeline = AutoPipelineForInpainting.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

image = pipeline(prompt_embeds=prompt_embeds, <span class="hljs-comment"># generated from Compel</span>
    negative_prompt_embeds=negative_prompt_embeds, <span class="hljs-comment"># generated from Compel</span>
    image=init_image,
    mask_image=mask_image
).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image], rows=<span class="hljs-number">1</span>, cols=<span class="hljs-number">3</span>)`,wrap:!1}}),da=new w({props:{title:"ControlNet",local:"controlnet",headingTag:"h3"}}),fa=new b({props:{code:"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",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> ControlNetModel, StableDiffusionControlNetInpaintPipeline
<span class="hljs-keyword">from</span> diffusers.utils <span class="hljs-keyword">import</span> load_image, make_image_grid

<span class="hljs-comment"># load ControlNet</span>
controlnet = ControlNetModel.from_pretrained(<span class="hljs-string">&quot;lllyasviel/control_v11p_sd15_inpaint&quot;</span>, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>)

<span class="hljs-comment"># pass ControlNet to the pipeline</span>
pipeline = StableDiffusionControlNetInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>, controlnet=controlnet, torch_dtype=torch.float16, variant=<span class="hljs-string">&quot;fp16&quot;</span>
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

<span class="hljs-comment"># load base and mask image</span>
init_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png&quot;</span>)
mask_image = load_image(<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png&quot;</span>)

<span class="hljs-comment"># prepare control image</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">make_inpaint_condition</span>(<span class="hljs-params">init_image, mask_image</span>):
    init_image = np.array(init_image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)).astype(np.float32) / <span class="hljs-number">255.0</span>
    mask_image = np.array(mask_image.convert(<span class="hljs-string">&quot;L&quot;</span>)).astype(np.float32) / <span class="hljs-number">255.0</span>

    <span class="hljs-keyword">assert</span> init_image.shape[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>] == mask_image.shape[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>], <span class="hljs-string">&quot;image and image_mask must have the same image size&quot;</span>
    init_image[mask_image &gt; <span class="hljs-number">0.5</span>] = -<span class="hljs-number">1.0</span>  <span class="hljs-comment"># set as masked pixel</span>
    init_image = np.expand_dims(init_image, <span class="hljs-number">0</span>).transpose(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
    init_image = torch.from_numpy(init_image)
    <span class="hljs-keyword">return</span> init_image

control_image = make_inpaint_condition(init_image, mask_image)`,wrap:!1}}),Ma=new b({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyY29uY2VwdCUyMGFydCUyMGRpZ2l0YWwlMjBwYWludGluZyUyMG9mJTIwYW4lMjBlbHZlbiUyMGNhc3RsZSUyQyUyMGluc3BpcmVkJTIwYnklMjBsb3JkJTIwb2YlMjB0aGUlMjByaW5ncyUyQyUyMGhpZ2hseSUyMGRldGFpbGVkJTJDJTIwOGslMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKHByb21wdCUzRHByb21wdCUyQyUyMGltYWdlJTNEaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlM0RtYXNrX2ltYWdlJTJDJTIwY29udHJvbF9pbWFnZSUzRGNvbnRyb2xfaW1hZ2UpLmltYWdlcyU1QjAlNUQlMEFtYWtlX2ltYWdlX2dyaWQoJTVCaW5pdF9pbWFnZSUyQyUyMG1hc2tfaW1hZ2UlMkMlMjBQSUwuSW1hZ2UuZnJvbWFycmF5KG5wLnVpbnQ4KGNvbnRyb2xfaW1hZ2UlNUIwJTVEJTVCMCU1RCkpLmNvbnZlcnQoJ1JHQicpJTJDJTIwaW1hZ2UlNUQlMkMlMjByb3dzJTNEMiUyQyUyMGNvbHMlM0QyKQ==",highlighted:`prompt = <span class="hljs-string">&quot;concept art digital painting of an elven castle, inspired by lord of the rings, highly detailed, 8k&quot;</span>
image = pipeline(prompt=prompt, image=init_image, mask_image=mask_image, control_image=control_image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, PIL.Image.fromarray(np.uint8(control_image[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>), image], rows=<span class="hljs-number">2</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),ba=new b({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMEF1dG9QaXBlbGluZUZvckltYWdlMkltYWdlJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBBdXRvUGlwZWxpbmVGb3JJbWFnZTJJbWFnZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIybml0cm9zb2NrZSUyRmVsZGVuLXJpbmctZGlmZnVzaW9uJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBKSUwQXBpcGVsaW5lLmVuYWJsZV9tb2RlbF9jcHVfb2ZmbG9hZCgpJTBBJTIzJTIwcmVtb3ZlJTIwZm9sbG93aW5nJTIwbGluZSUyMGlmJTIweEZvcm1lcnMlMjBpcyUyMG5vdCUyMGluc3RhbGxlZCUyMG9yJTIweW91JTIwaGF2ZSUyMFB5VG9yY2glMjAyLjAlMjBvciUyMGhpZ2hlciUyMGluc3RhbGxlZCUwQXBpcGVsaW5lLmVuYWJsZV94Zm9ybWVyc19tZW1vcnlfZWZmaWNpZW50X2F0dGVudGlvbigpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIyZWxkZW4lMjByaW5nJTIwc3R5bGUlMjBjYXN0bGUlMjIlMjAlMjMlMjBpbmNsdWRlJTIwdGhlJTIwdG9rZW4lMjAlMjJlbGRlbiUyMHJpbmclMjBzdHlsZSUyMiUyMGluJTIwdGhlJTIwcHJvbXB0JTBBbmVnYXRpdmVfcHJvbXB0JTIwJTNEJTIwJTIyYmFkJTIwYXJjaGl0ZWN0dXJlJTJDJTIwZGVmb3JtZWQlMkMlMjBkaXNmaWd1cmVkJTJDJTIwcG9vciUyMGRldGFpbHMlMjIlMEElMEFpbWFnZV9lbGRlbl9yaW5nJTIwJTNEJTIwcGlwZWxpbmUocHJvbXB0JTJDJTIwbmVnYXRpdmVfcHJvbXB0JTNEbmVnYXRpdmVfcHJvbXB0JTJDJTIwaW1hZ2UlM0RpbWFnZSkuaW1hZ2VzJTVCMCU1RCUwQW1ha2VfaW1hZ2VfZ3JpZCglNUJpbml0X2ltYWdlJTJDJTIwbWFza19pbWFnZSUyQyUyMGltYWdlJTJDJTIwaW1hZ2VfZWxkZW5fcmluZyU1RCUyQyUyMHJvd3MlM0QyJTJDJTIwY29scyUzRDIp",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> AutoPipelineForImage2Image

pipeline = AutoPipelineForImage2Image.from_pretrained(
    <span class="hljs-string">&quot;nitrosocke/elden-ring-diffusion&quot;</span>, torch_dtype=torch.float16,
)
pipeline.enable_model_cpu_offload()
<span class="hljs-comment"># remove following line if xFormers is not installed or you have PyTorch 2.0 or higher installed</span>
pipeline.enable_xformers_memory_efficient_attention()

prompt = <span class="hljs-string">&quot;elden ring style castle&quot;</span> <span class="hljs-comment"># include the token &quot;elden ring style&quot; in the prompt</span>
negative_prompt = <span class="hljs-string">&quot;bad architecture, deformed, disfigured, poor details&quot;</span>

image_elden_ring = pipeline(prompt, negative_prompt=negative_prompt, image=image).images[<span class="hljs-number">0</span>]
make_image_grid([init_image, mask_image, image, image_elden_ring], rows=<span class="hljs-number">2</span>, cols=<span class="hljs-number">2</span>)`,wrap:!1}}),Ja=new w({props:{title:"Optimize",local:"optimize",headingTag:"h2"}}),wa=new b({props:{code:"JTJCJTIwcGlwZWxpbmUuZW5hYmxlX3hmb3JtZXJzX21lbW9yeV9lZmZpY2llbnRfYXR0ZW50aW9uKCklMEElMkIlMjBwaXBlbGluZS5lbmFibGVfbW9kZWxfY3B1X29mZmxvYWQoKQ==",highlighted:`<span class="hljs-addition">+ pipeline.enable_xformers_memory_efficient_attention()</span>
<span class="hljs-addition">+ pipeline.enable_model_cpu_offload()</span>`,wrap:!1}}),Ua=new b({props:{code:"cGlwZWxpbmUudW5ldCUyMCUzRCUyMHRvcmNoLmNvbXBpbGUocGlwZWxpbmUudW5ldCUyQyUyMG1vZGUlM0QlMjJyZWR1Y2Utb3ZlcmhlYWQlMjIlMkMlMjBmdWxsZ3JhcGglM0RUcnVlKQ==",highlighted:'pipeline.unet = torch.<span class="hljs-built_in">compile</span>(pipeline.unet, mode=<span class="hljs-string">&quot;reduce-overhead&quot;</span>, fullgraph=<span class="hljs-literal">True</span>)',wrap:!1}}),Ga=new ls({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/using-diffusers/inpaint.md"}}),{c(){i=m("meta"),y=n(),p=m("p"),J=n(),c(M.$$.fragment),Z=n(),c(U.$$.fragment),j=n(),E=m("p"),E.textContent=Yt,va=n(),L=m("p"),L.textContent=Ft,Ia=n(),q=m("ol"),q.innerHTML=Rt,Xa=n(),c(A.$$.fragment),_a=n(),c(k.$$.fragment),Ya=n(),B=m("ol"),B.innerHTML=Vt,Fa=n(),c(D.$$.fragment),Ra=n(),v=m("ol"),v.innerHTML=xt,Va=n(),c(P.$$.fragment),xa=n(),I=m("div"),I.innerHTML=$t,$a=n(),c(K.$$.fragment),Ca=n(),O=m("p"),O.textContent=Ct,Na=n(),ee=m("p"),ee.innerHTML=Nt,Qa=n(),G=m("iframe"),Sa=n(),c(ae.$$.fragment),Ha=n(),le=m("p"),le.innerHTML=St,za=n(),te=m("p"),te.textContent=Ht,Ea=n(),c(ne.$$.fragment),La=n(),X=m("div"),X.innerHTML=zt,qa=n(),c(se.$$.fragment),Aa=n(),ie=m("p"),ie.innerHTML=Et,Da=n(),c(pe.$$.fragment),Pa=n(),me=m("p"),me.textContent=Lt,Ka=n(),c(oe.$$.fragment),Oa=n(),c(re.$$.fragment),el=n(),ce=m("p"),ce.innerHTML=qt,al=n(),c(de.$$.fragment),ll=n(),c(ge.$$.fragment),tl=n(),ue=m("p"),ue.innerHTML=At,nl=n(),c(fe.$$.fragment),sl=n(),_=m("div"),_.innerHTML=Dt,il=n(),c(he.$$.fragment),pl=n(),Me=m("p"),Me.innerHTML=Pt,ml=n(),ye=m("p"),ye.textContent=Kt,ol=n(),c(Y.$$.fragment),rl=n(),F=m("div"),F.innerHTML=Ot,cl=n(),be=m("p"),be.textContent=en,dl=n(),c(R.$$.fragment),gl=n(),V=m("div"),V.innerHTML=an,ul=n(),Je=m("p"),Je.textContent=ln,fl=n(),Ze=m("p"),Ze.innerHTML=tn,hl=n(),c(We.$$.fragment),Ml=n(),c(we.$$.fragment),yl=n(),Te=m("p"),Te.textContent=nn,bl=n(),c(Ue.$$.fragment),Jl=n(),je=m("p"),je.innerHTML=sn,Zl=n(),Ge=m("ul"),Ge.innerHTML=pn,Wl=n(),c(ke.$$.fragment),wl=n(),x=m("div"),x.innerHTML=mn,Tl=n(),c(Be.$$.fragment),Ul=n(),ve=m("p"),ve.innerHTML=on,jl=n(),Ie=m("ul"),Ie.innerHTML=rn,Gl=n(),Xe=m("p"),Xe.innerHTML=cn,kl=n(),c(_e.$$.fragment),Bl=n(),$=m("div"),$.innerHTML=dn,vl=n(),c(Ye.$$.fragment),Il=n(),Fe=m("p"),Fe.textContent=gn,Xl=n(),c(Re.$$.fragment),_l=n(),C=m("div"),C.innerHTML=un,Yl=n(),c(Ve.$$.fragment),Fl=n(),xe=m("p"),xe.innerHTML=fn,Rl=n(),$e=m("p"),$e.innerHTML=hn,Vl=n(),c(Ce.$$.fragment),xl=n(),N=m("div"),N.innerHTML=Mn,$l=n(),c(Ne.$$.fragment),Cl=n(),Qe=m("p"),Qe.innerHTML=yn,Nl=n(),c(Se.$$.fragment),Ql=n(),He=m("p"),He.textContent=bn,Sl=n(),ze=m("p"),ze.textContent=Jn,Hl=n(),c(Ee.$$.fragment),zl=n(),Le=m("p"),Le.textContent=Zn,El=n(),c(qe.$$.fragment),Ll=n(),Ae=m("p"),Ae.textContent=Wn,ql=n(),c(De.$$.fragment),Al=n(),Q=m("div"),Q.innerHTML=wn,Dl=n(),c(Pe.$$.fragment),Pl=n(),Ke=m("p"),Ke.textContent=Tn,Kl=n(),Oe=m("p"),Oe.textContent=Un,Ol=n(),c(ea.$$.fragment),et=n(),aa=m("p"),aa.textContent=jn,at=n(),c(la.$$.fragment),lt=n(),c(S.$$.fragment),tt=n(),ta=m("p"),ta.innerHTML=Gn,nt=n(),c(na.$$.fragment),st=n(),H=m("div"),H.innerHTML=kn,it=n(),sa=m("p"),sa.textContent=Bn,pt=n(),c(ia.$$.fragment),mt=n(),pa=m("p"),pa.innerHTML=vn,ot=n(),c(ma.$$.fragment),rt=n(),oa=m("p"),oa.innerHTML=In,ct=n(),ra=m("p"),ra.innerHTML=Xn,dt=n(),c(ca.$$.fragment),gt=n(),c(da.$$.fragment),ut=n(),ga=m("p"),ga.textContent=_n,ft=n(),ua=m("p"),ua.textContent=Yn,ht=n(),c(fa.$$.fragment),Mt=n(),ha=m("p"),ha.textContent=Fn,yt=n(),c(Ma.$$.fragment),bt=n(),ya=m("p"),ya.innerHTML=Rn,Jt=n(),c(ba.$$.fragment),Zt=n(),z=m("div"),z.innerHTML=Vn,Wt=n(),c(Ja.$$.fragment),wt=n(),Za=m("p"),Za.innerHTML=xn,Tt=n(),Wa=m("p"),Wa.textContent=$n,Ut=n(),c(wa.$$.fragment),jt=n(),Ta=m("p"),Ta.innerHTML=Cn,Gt=n(),c(Ua.$$.fragment),kt=n(),ja=m("p"),ja.innerHTML=Nn,Bt=n(),c(Ga.$$.fragment),vt=n(),Ba=m("p"),this.h()},l(e){const a=On("svelte-u9bgzb",document.head);i=o(a,"META",{name:!0,content:!0}),a.forEach(l),y=s(e),p=o(e,"P",{}),_t(p).forEach(l),J=s(e),d(M.$$.fragment,e),Z=s(e),d(U.$$.fragment,e),j=s(e),E=o(e,"P",{"data-svelte-h":!0}),r(E)!=="svelte-1vjeoqc"&&(E.textContent=Yt),va=s(e),L=o(e,"P",{"data-svelte-h":!0}),r(L)!=="svelte-1t7j32f"&&(L.textContent=Ft),Ia=s(e),q=o(e,"OL",{"data-svelte-h":!0}),r(q)!=="svelte-5y4l00"&&(q.innerHTML=Rt),Xa=s(e),d(A.$$.fragment,e),_a=s(e),d(k.$$.fragment,e),Ya=s(e),B=o(e,"OL",{start:!0,"data-svelte-h":!0}),r(B)!=="svelte-1jtpcib"&&(B.innerHTML=Vt),Fa=s(e),d(D.$$.fragment,e),Ra=s(e),v=o(e,"OL",{start:!0,"data-svelte-h":!0}),r(v)!=="svelte-1przvba"&&(v.innerHTML=xt),Va=s(e),d(P.$$.fragment,e),xa=s(e),I=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(I)!=="svelte-72kdzo"&&(I.innerHTML=$t),$a=s(e),d(K.$$.fragment,e),Ca=s(e),O=o(e,"P",{"data-svelte-h":!0}),r(O)!=="svelte-ic55ez"&&(O.textContent=Ct),Na=s(e),ee=o(e,"P",{"data-svelte-h":!0}),r(ee)!=="svelte-87gmw5"&&(ee.innerHTML=Nt),Qa=s(e),G=o(e,"IFRAME",{src:!0,frameborder:!0,width:!0,height:!0}),_t(G).forEach(l),Sa=s(e),d(ae.$$.fragment,e),Ha=s(e),le=o(e,"P",{"data-svelte-h":!0}),r(le)!=="svelte-1oce9nc"&&(le.innerHTML=St),za=s(e),te=o(e,"P",{"data-svelte-h":!0}),r(te)!=="svelte-94ubh1"&&(te.textContent=Ht),Ea=s(e),d(ne.$$.fragment,e),La=s(e),X=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(X)!=="svelte-8eokiu"&&(X.innerHTML=zt),qa=s(e),d(se.$$.fragment,e),Aa=s(e),ie=o(e,"P",{"data-svelte-h":!0}),r(ie)!=="svelte-5vkfn3"&&(ie.innerHTML=Et),Da=s(e),d(pe.$$.fragment,e),Pa=s(e),me=o(e,"P",{"data-svelte-h":!0}),r(me)!=="svelte-siyv04"&&(me.textContent=Lt),Ka=s(e),d(oe.$$.fragment,e),Oa=s(e),d(re.$$.fragment,e),el=s(e),ce=o(e,"P",{"data-svelte-h":!0}),r(ce)!=="svelte-1grw9dr"&&(ce.innerHTML=qt),al=s(e),d(de.$$.fragment,e),ll=s(e),d(ge.$$.fragment,e),tl=s(e),ue=o(e,"P",{"data-svelte-h":!0}),r(ue)!=="svelte-vuam68"&&(ue.innerHTML=At),nl=s(e),d(fe.$$.fragment,e),sl=s(e),_=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(_)!=="svelte-xc2o0t"&&(_.innerHTML=Dt),il=s(e),d(he.$$.fragment,e),pl=s(e),Me=o(e,"P",{"data-svelte-h":!0}),r(Me)!=="svelte-1f7rg9f"&&(Me.innerHTML=Pt),ml=s(e),ye=o(e,"P",{"data-svelte-h":!0}),r(ye)!=="svelte-wgq5zt"&&(ye.textContent=Kt),ol=s(e),d(Y.$$.fragment,e),rl=s(e),F=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(F)!=="svelte-5lzd2z"&&(F.innerHTML=Ot),cl=s(e),be=o(e,"P",{"data-svelte-h":!0}),r(be)!=="svelte-2plak"&&(be.textContent=en),dl=s(e),d(R.$$.fragment,e),gl=s(e),V=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(V)!=="svelte-kg15p1"&&(V.innerHTML=an),ul=s(e),Je=o(e,"P",{"data-svelte-h":!0}),r(Je)!=="svelte-duydyd"&&(Je.textContent=ln),fl=s(e),Ze=o(e,"P",{"data-svelte-h":!0}),r(Ze)!=="svelte-tdq62e"&&(Ze.innerHTML=tn),hl=s(e),d(We.$$.fragment,e),Ml=s(e),d(we.$$.fragment,e),yl=s(e),Te=o(e,"P",{"data-svelte-h":!0}),r(Te)!=="svelte-13ocbdc"&&(Te.textContent=nn),bl=s(e),d(Ue.$$.fragment,e),Jl=s(e),je=o(e,"P",{"data-svelte-h":!0}),r(je)!=="svelte-qcb5md"&&(je.innerHTML=sn),Zl=s(e),Ge=o(e,"UL",{"data-svelte-h":!0}),r(Ge)!=="svelte-vvcg88"&&(Ge.innerHTML=pn),Wl=s(e),d(ke.$$.fragment,e),wl=s(e),x=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(x)!=="svelte-1vmqp5s"&&(x.innerHTML=mn),Tl=s(e),d(Be.$$.fragment,e),Ul=s(e),ve=o(e,"P",{"data-svelte-h":!0}),r(ve)!=="svelte-zcb81p"&&(ve.innerHTML=on),jl=s(e),Ie=o(e,"UL",{"data-svelte-h":!0}),r(Ie)!=="svelte-cnggx4"&&(Ie.innerHTML=rn),Gl=s(e),Xe=o(e,"P",{"data-svelte-h":!0}),r(Xe)!=="svelte-196id8d"&&(Xe.innerHTML=cn),kl=s(e),d(_e.$$.fragment,e),Bl=s(e),$=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r($)!=="svelte-1cwhpu7"&&($.innerHTML=dn),vl=s(e),d(Ye.$$.fragment,e),Il=s(e),Fe=o(e,"P",{"data-svelte-h":!0}),r(Fe)!=="svelte-1ru9kar"&&(Fe.textContent=gn),Xl=s(e),d(Re.$$.fragment,e),_l=s(e),C=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(C)!=="svelte-15bd4ta"&&(C.innerHTML=un),Yl=s(e),d(Ve.$$.fragment,e),Fl=s(e),xe=o(e,"P",{"data-svelte-h":!0}),r(xe)!=="svelte-1rr3oox"&&(xe.innerHTML=fn),Rl=s(e),$e=o(e,"P",{"data-svelte-h":!0}),r($e)!=="svelte-1kzwzp9"&&($e.innerHTML=hn),Vl=s(e),d(Ce.$$.fragment,e),xl=s(e),N=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(N)!=="svelte-107i7jo"&&(N.innerHTML=Mn),$l=s(e),d(Ne.$$.fragment,e),Cl=s(e),Qe=o(e,"P",{"data-svelte-h":!0}),r(Qe)!=="svelte-rttn8"&&(Qe.innerHTML=yn),Nl=s(e),d(Se.$$.fragment,e),Ql=s(e),He=o(e,"P",{"data-svelte-h":!0}),r(He)!=="svelte-1uqw6jr"&&(He.textContent=bn),Sl=s(e),ze=o(e,"P",{"data-svelte-h":!0}),r(ze)!=="svelte-1kzp8f0"&&(ze.textContent=Jn),Hl=s(e),d(Ee.$$.fragment,e),zl=s(e),Le=o(e,"P",{"data-svelte-h":!0}),r(Le)!=="svelte-yqefj6"&&(Le.textContent=Zn),El=s(e),d(qe.$$.fragment,e),Ll=s(e),Ae=o(e,"P",{"data-svelte-h":!0}),r(Ae)!=="svelte-ua49j1"&&(Ae.textContent=Wn),ql=s(e),d(De.$$.fragment,e),Al=s(e),Q=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(Q)!=="svelte-15ens2s"&&(Q.innerHTML=wn),Dl=s(e),d(Pe.$$.fragment,e),Pl=s(e),Ke=o(e,"P",{"data-svelte-h":!0}),r(Ke)!=="svelte-16qmg1v"&&(Ke.textContent=Tn),Kl=s(e),Oe=o(e,"P",{"data-svelte-h":!0}),r(Oe)!=="svelte-1du3njh"&&(Oe.textContent=Un),Ol=s(e),d(ea.$$.fragment,e),et=s(e),aa=o(e,"P",{"data-svelte-h":!0}),r(aa)!=="svelte-j4alid"&&(aa.textContent=jn),at=s(e),d(la.$$.fragment,e),lt=s(e),d(S.$$.fragment,e),tt=s(e),ta=o(e,"P",{"data-svelte-h":!0}),r(ta)!=="svelte-1u4zq70"&&(ta.innerHTML=Gn),nt=s(e),d(na.$$.fragment,e),st=s(e),H=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(H)!=="svelte-1lbnv8n"&&(H.innerHTML=kn),it=s(e),sa=o(e,"P",{"data-svelte-h":!0}),r(sa)!=="svelte-1fd5b22"&&(sa.textContent=Bn),pt=s(e),d(ia.$$.fragment,e),mt=s(e),pa=o(e,"P",{"data-svelte-h":!0}),r(pa)!=="svelte-1gc804h"&&(pa.innerHTML=vn),ot=s(e),d(ma.$$.fragment,e),rt=s(e),oa=o(e,"P",{"data-svelte-h":!0}),r(oa)!=="svelte-6zcpc0"&&(oa.innerHTML=In),ct=s(e),ra=o(e,"P",{"data-svelte-h":!0}),r(ra)!=="svelte-1r8bykz"&&(ra.innerHTML=Xn),dt=s(e),d(ca.$$.fragment,e),gt=s(e),d(da.$$.fragment,e),ut=s(e),ga=o(e,"P",{"data-svelte-h":!0}),r(ga)!=="svelte-3rypf9"&&(ga.textContent=_n),ft=s(e),ua=o(e,"P",{"data-svelte-h":!0}),r(ua)!=="svelte-1x7ee8u"&&(ua.textContent=Yn),ht=s(e),d(fa.$$.fragment,e),Mt=s(e),ha=o(e,"P",{"data-svelte-h":!0}),r(ha)!=="svelte-db3ja"&&(ha.textContent=Fn),yt=s(e),d(Ma.$$.fragment,e),bt=s(e),ya=o(e,"P",{"data-svelte-h":!0}),r(ya)!=="svelte-iaoixt"&&(ya.innerHTML=Rn),Jt=s(e),d(ba.$$.fragment,e),Zt=s(e),z=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(z)!=="svelte-9rfwwm"&&(z.innerHTML=Vn),Wt=s(e),d(Ja.$$.fragment,e),wt=s(e),Za=o(e,"P",{"data-svelte-h":!0}),r(Za)!=="svelte-1f04pnr"&&(Za.innerHTML=xn),Tt=s(e),Wa=o(e,"P",{"data-svelte-h":!0}),r(Wa)!=="svelte-1eqbc05"&&(Wa.textContent=$n),Ut=s(e),d(wa.$$.fragment,e),jt=s(e),Ta=o(e,"P",{"data-svelte-h":!0}),r(Ta)!=="svelte-c3yozi"&&(Ta.innerHTML=Cn),Gt=s(e),d(Ua.$$.fragment,e),kt=s(e),ja=o(e,"P",{"data-svelte-h":!0}),r(ja)!=="svelte-ve8eie"&&(ja.innerHTML=Nn),Bt=s(e),d(Ga.$$.fragment,e),vt=s(e),Ba=o(e,"P",{}),_t(Ba).forEach(l),this.h()},h(){W(i,"name","hf:doc:metadata"),W(i,"content",ds),W(B,"start","2"),W(v,"start","3"),W(I,"class","flex gap-4"),An(G.src,Qt="https://stevhliu-inpaint-mask-maker.hf.space")||W(G,"src",Qt),W(G,"frameborder","0"),W(G,"width","850"),W(G,"height","450"),W(X,"class","flex gap-4"),W(_,"class","flex flex-row gap-4"),W(F,"class","flex gap-4"),W(V,"class","flex gap-4"),W(x,"class","flex flex-row gap-4"),W($,"class","flex flex-row gap-4"),W(C,"class","flex justify-center"),W(N,"class","flex gap-4"),W(Q,"class","flex flex-row gap-4"),W(H,"class","flex flex-row gap-4"),W(z,"class","flex flex-row gap-4")},m(e,a){es(document.head,i),t(e,y,a),t(e,p,a),t(e,J,a),g(M,e,a),t(e,Z,a),g(U,e,a),t(e,j,a),t(e,E,a),t(e,va,a),t(e,L,a),t(e,Ia,a),t(e,q,a),t(e,Xa,a),g(A,e,a),t(e,_a,a),g(k,e,a),t(e,Ya,a),t(e,B,a),t(e,Fa,a),g(D,e,a),t(e,Ra,a),t(e,v,a),t(e,Va,a),g(P,e,a),t(e,xa,a),t(e,I,a),t(e,$a,a),g(K,e,a),t(e,Ca,a),t(e,O,a),t(e,Na,a),t(e,ee,a),t(e,Qa,a),t(e,G,a),t(e,Sa,a),g(ae,e,a),t(e,Ha,a),t(e,le,a),t(e,za,a),t(e,te,a),t(e,Ea,a),g(ne,e,a),t(e,La,a),t(e,X,a),t(e,qa,a),g(se,e,a),t(e,Aa,a),t(e,ie,a),t(e,Da,a),g(pe,e,a),t(e,Pa,a),t(e,me,a),t(e,Ka,a),g(oe,e,a),t(e,Oa,a),g(re,e,a),t(e,el,a),t(e,ce,a),t(e,al,a),g(de,e,a),t(e,ll,a),g(ge,e,a),t(e,tl,a),t(e,ue,a),t(e,nl,a),g(fe,e,a),t(e,sl,a),t(e,_,a),t(e,il,a),g(he,e,a),t(e,pl,a),t(e,Me,a),t(e,ml,a),t(e,ye,a),t(e,ol,a),g(Y,e,a),t(e,rl,a),t(e,F,a),t(e,cl,a),t(e,be,a),t(e,dl,a),g(R,e,a),t(e,gl,a),t(e,V,a),t(e,ul,a),t(e,Je,a),t(e,fl,a),t(e,Ze,a),t(e,hl,a),g(We,e,a),t(e,Ml,a),g(we,e,a),t(e,yl,a),t(e,Te,a),t(e,bl,a),g(Ue,e,a),t(e,Jl,a),t(e,je,a),t(e,Zl,a),t(e,Ge,a),t(e,Wl,a),g(ke,e,a),t(e,wl,a),t(e,x,a),t(e,Tl,a),g(Be,e,a),t(e,Ul,a),t(e,ve,a),t(e,jl,a),t(e,Ie,a),t(e,Gl,a),t(e,Xe,a),t(e,kl,a),g(_e,e,a),t(e,Bl,a),t(e,$,a),t(e,vl,a),g(Ye,e,a),t(e,Il,a),t(e,Fe,a),t(e,Xl,a),g(Re,e,a),t(e,_l,a),t(e,C,a),t(e,Yl,a),g(Ve,e,a),t(e,Fl,a),t(e,xe,a),t(e,Rl,a),t(e,$e,a),t(e,Vl,a),g(Ce,e,a),t(e,xl,a),t(e,N,a),t(e,$l,a),g(Ne,e,a),t(e,Cl,a),t(e,Qe,a),t(e,Nl,a),g(Se,e,a),t(e,Ql,a),t(e,He,a),t(e,Sl,a),t(e,ze,a),t(e,Hl,a),g(Ee,e,a),t(e,zl,a),t(e,Le,a),t(e,El,a),g(qe,e,a),t(e,Ll,a),t(e,Ae,a),t(e,ql,a),g(De,e,a),t(e,Al,a),t(e,Q,a),t(e,Dl,a),g(Pe,e,a),t(e,Pl,a),t(e,Ke,a),t(e,Kl,a),t(e,Oe,a),t(e,Ol,a),g(ea,e,a),t(e,et,a),t(e,aa,a),t(e,at,a),g(la,e,a),t(e,lt,a),g(S,e,a),t(e,tt,a),t(e,ta,a),t(e,nt,a),g(na,e,a),t(e,st,a),t(e,H,a),t(e,it,a),t(e,sa,a),t(e,pt,a),g(ia,e,a),t(e,mt,a),t(e,pa,a),t(e,ot,a),g(ma,e,a),t(e,rt,a),t(e,oa,a),t(e,ct,a),t(e,ra,a),t(e,dt,a),g(ca,e,a),t(e,gt,a),g(da,e,a),t(e,ut,a),t(e,ga,a),t(e,ft,a),t(e,ua,a),t(e,ht,a),g(fa,e,a),t(e,Mt,a),t(e,ha,a),t(e,yt,a),g(Ma,e,a),t(e,bt,a),t(e,ya,a),t(e,Jt,a),g(ba,e,a),t(e,Zt,a),t(e,z,a),t(e,Wt,a),g(Ja,e,a),t(e,wt,a),t(e,Za,a),t(e,Tt,a),t(e,Wa,a),t(e,Ut,a),g(wa,e,a),t(e,jt,a),t(e,Ta,a),t(e,Gt,a),g(Ua,e,a),t(e,kt,a),t(e,ja,a),t(e,Bt,a),g(Ga,e,a),t(e,vt,a),t(e,Ba,a),It=!0},p(e,[a]){const Qn={};a&2&&(Qn.$$scope={dirty:a,ctx:e}),k.$set(Qn);const Sn={};a&2&&(Sn.$$scope={dirty:a,ctx:e}),Y.$set(Sn);const Hn={};a&2&&(Hn.$$scope={dirty:a,ctx:e}),R.$set(Hn);const zn={};a&2&&(zn.$$scope={dirty:a,ctx:e}),S.$set(zn)},i(e){It||(u(M.$$.fragment,e),u(U.$$.fragment,e),u(A.$$.fragment,e),u(k.$$.fragment,e),u(D.$$.fragment,e),u(P.$$.fragment,e),u(K.$$.fragment,e),u(ae.$$.fragment,e),u(ne.$$.fragment,e),u(se.$$.fragment,e),u(pe.$$.fragment,e),u(oe.$$.fragment,e),u(re.$$.fragment,e),u(de.$$.fragment,e),u(ge.$$.fragment,e),u(fe.$$.fragment,e),u(he.$$.fragment,e),u(Y.$$.fragment,e),u(R.$$.fragment,e),u(We.$$.fragment,e),u(we.$$.fragment,e),u(Ue.$$.fragment,e),u(ke.$$.fragment,e),u(Be.$$.fragment,e),u(_e.$$.fragment,e),u(Ye.$$.fragment,e),u(Re.$$.fragment,e),u(Ve.$$.fragment,e),u(Ce.$$.fragment,e),u(Ne.$$.fragment,e),u(Se.$$.fragment,e),u(Ee.$$.fragment,e),u(qe.$$.fragment,e),u(De.$$.fragment,e),u(Pe.$$.fragment,e),u(ea.$$.fragment,e),u(la.$$.fragment,e),u(S.$$.fragment,e),u(na.$$.fragment,e),u(ia.$$.fragment,e),u(ma.$$.fragment,e),u(ca.$$.fragment,e),u(da.$$.fragment,e),u(fa.$$.fragment,e),u(Ma.$$.fragment,e),u(ba.$$.fragment,e),u(Ja.$$.fragment,e),u(wa.$$.fragment,e),u(Ua.$$.fragment,e),u(Ga.$$.fragment,e),It=!0)},o(e){f(M.$$.fragment,e),f(U.$$.fragment,e),f(A.$$.fragment,e),f(k.$$.fragment,e),f(D.$$.fragment,e),f(P.$$.fragment,e),f(K.$$.fragment,e),f(ae.$$.fragment,e),f(ne.$$.fragment,e),f(se.$$.fragment,e),f(pe.$$.fragment,e),f(oe.$$.fragment,e),f(re.$$.fragment,e),f(de.$$.fragment,e),f(ge.$$.fragment,e),f(fe.$$.fragment,e),f(he.$$.fragment,e),f(Y.$$.fragment,e),f(R.$$.fragment,e),f(We.$$.fragment,e),f(we.$$.fragment,e),f(Ue.$$.fragment,e),f(ke.$$.fragment,e),f(Be.$$.fragment,e),f(_e.$$.fragment,e),f(Ye.$$.fragment,e),f(Re.$$.fragment,e),f(Ve.$$.fragment,e),f(Ce.$$.fragment,e),f(Ne.$$.fragment,e),f(Se.$$.fragment,e),f(Ee.$$.fragment,e),f(qe.$$.fragment,e),f(De.$$.fragment,e),f(Pe.$$.fragment,e),f(ea.$$.fragment,e),f(la.$$.fragment,e),f(S.$$.fragment,e),f(na.$$.fragment,e),f(ia.$$.fragment,e),f(ma.$$.fragment,e),f(ca.$$.fragment,e),f(da.$$.fragment,e),f(fa.$$.fragment,e),f(Ma.$$.fragment,e),f(ba.$$.fragment,e),f(Ja.$$.fragment,e),f(wa.$$.fragment,e),f(Ua.$$.fragment,e),f(Ga.$$.fragment,e),It=!1},d(e){e&&(l(y),l(p),l(J),l(Z),l(j),l(E),l(va),l(L),l(Ia),l(q),l(Xa),l(_a),l(Ya),l(B),l(Fa),l(Ra),l(v),l(Va),l(xa),l(I),l($a),l(Ca),l(O),l(Na),l(ee),l(Qa),l(G),l(Sa),l(Ha),l(le),l(za),l(te),l(Ea),l(La),l(X),l(qa),l(Aa),l(ie),l(Da),l(Pa),l(me),l(Ka),l(Oa),l(el),l(ce),l(al),l(ll),l(tl),l(ue),l(nl),l(sl),l(_),l(il),l(pl),l(Me),l(ml),l(ye),l(ol),l(rl),l(F),l(cl),l(be),l(dl),l(gl),l(V),l(ul),l(Je),l(fl),l(Ze),l(hl),l(Ml),l(yl),l(Te),l(bl),l(Jl),l(je),l(Zl),l(Ge),l(Wl),l(wl),l(x),l(Tl),l(Ul),l(ve),l(jl),l(Ie),l(Gl),l(Xe),l(kl),l(Bl),l($),l(vl),l(Il),l(Fe),l(Xl),l(_l),l(C),l(Yl),l(Fl),l(xe),l(Rl),l($e),l(Vl),l(xl),l(N),l($l),l(Cl),l(Qe),l(Nl),l(Ql),l(He),l(Sl),l(ze),l(Hl),l(zl),l(Le),l(El),l(Ll),l(Ae),l(ql),l(Al),l(Q),l(Dl),l(Pl),l(Ke),l(Kl),l(Oe),l(Ol),l(et),l(aa),l(at),l(lt),l(tt),l(ta),l(nt),l(st),l(H),l(it),l(sa),l(pt),l(mt),l(pa),l(ot),l(rt),l(oa),l(ct),l(ra),l(dt),l(gt),l(ut),l(ga),l(ft),l(ua),l(ht),l(Mt),l(ha),l(yt),l(bt),l(ya),l(Jt),l(Zt),l(z),l(Wt),l(wt),l(Za),l(Tt),l(Wa),l(Ut),l(jt),l(Ta),l(Gt),l(kt),l(ja),l(Bt),l(vt),l(Ba)),l(i),h(M,e),h(U,e),h(A,e),h(k,e),h(D,e),h(P,e),h(K,e),h(ae,e),h(ne,e),h(se,e),h(pe,e),h(oe,e),h(re,e),h(de,e),h(ge,e),h(fe,e),h(he,e),h(Y,e),h(R,e),h(We,e),h(we,e),h(Ue,e),h(ke,e),h(Be,e),h(_e,e),h(Ye,e),h(Re,e),h(Ve,e),h(Ce,e),h(Ne,e),h(Se,e),h(Ee,e),h(qe,e),h(De,e),h(Pe,e),h(ea,e),h(la,e),h(S,e),h(na,e),h(ia,e),h(ma,e),h(ca,e),h(da,e),h(fa,e),h(Ma,e),h(ba,e),h(Ja,e),h(wa,e),h(Ua,e),h(Ga,e)}}}const ds='{"title":"Inpainting","local":"inpainting","sections":[{"title":"Create a mask image","local":"create-a-mask-image","sections":[{"title":"Mask blur","local":"mask-blur","sections":[],"depth":3}],"depth":2},{"title":"Popular models","local":"popular-models","sections":[{"title":"Stable Diffusion Inpainting","local":"stable-diffusion-inpainting","sections":[],"depth":3},{"title":"Stable Diffusion XL (SDXL) Inpainting","local":"stable-diffusion-xl-sdxl-inpainting","sections":[],"depth":3},{"title":"Kandinsky 2.2 Inpainting","local":"kandinsky-22-inpainting","sections":[],"depth":3}],"depth":2},{"title":"Non-inpaint specific checkpoints","local":"non-inpaint-specific-checkpoints","sections":[],"depth":2},{"title":"Configure pipeline parameters","local":"configure-pipeline-parameters","sections":[{"title":"Strength","local":"strength","sections":[],"depth":3},{"title":"Guidance scale","local":"guidance-scale","sections":[],"depth":3},{"title":"Negative prompt","local":"negative-prompt","sections":[],"depth":3},{"title":"Padding mask crop","local":"padding-mask-crop","sections":[],"depth":3}],"depth":2},{"title":"Chained inpainting pipelines","local":"chained-inpainting-pipelines","sections":[{"title":"Text-to-image-to-inpaint","local":"text-to-image-to-inpaint","sections":[],"depth":3},{"title":"Inpaint-to-image-to-image","local":"inpaint-to-image-to-image","sections":[],"depth":3}],"depth":2},{"title":"Control image generation","local":"control-image-generation","sections":[{"title":"Prompt weighting","local":"prompt-weighting","sections":[],"depth":3},{"title":"ControlNet","local":"controlnet","sections":[],"depth":3}],"depth":2},{"title":"Optimize","local":"optimize","sections":[],"depth":2}],"depth":1}';function gs(T){return Dn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Zs extends Pn{constructor(i){super(),Kn(this,i,gs,cs,qn,{})}}export{Zs as component};
