import{s as ss,o as ls,n as Ut}from"../chunks/scheduler.8c3d61f6.js";import{S as as,i as ns,g as o,s as a,r as d,A as is,h as p,f as s,c as n,j as ts,u,x as r,k as Je,y as os,a as l,v as h,d as m,t as f,w as c}from"../chunks/index.da70eac4.js";import{T as Zt}from"../chunks/Tip.1d9b8c37.js";import{C as y}from"../chunks/CodeBlock.a9c4becf.js";import{H as be,E as ps}from"../chunks/index.5d4ab994.js";function rs(J){let i,g='This is an experimental method that adds PEFTs <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> method to Diffusers to enable more efficient merging methods. Check out this <a href="https://github.com/huggingface/diffusers/issues/6892" rel="nofollow">issue</a> if youâ€™re interested in learning more about the motivation and design behind this integration.';return{c(){i=o("p"),i.innerHTML=g},l(M){i=p(M,"P",{"data-svelte-h":!0}),r(i)!=="svelte-ukm7y9"&&(i.innerHTML=g)},m(M,w){l(M,i,w)},p:Ut,d(M){M&&s(i)}}}function ds(J){let i,g="You can optionally push the ikea_peft_model to the Hub by calling <code>ikea_peft_model.push_to_hub(&quot;ikea_peft_model&quot;, token=TOKEN)</code>.";return{c(){i=o("p"),i.innerHTML=g},l(M){i=p(M,"P",{"data-svelte-h":!0}),r(i)!=="svelte-1m0icqe"&&(i.innerHTML=g)},m(M,w){l(M,i,w)},p:Ut,d(M){M&&s(i)}}}function us(J){let i,g="Keep in mind the LoRAs need to have the same rank to be merged!";return{c(){i=o("p"),i.textContent=g},l(M){i=p(M,"P",{"data-svelte-h":!0}),r(i)!=="svelte-1g1f7t1"&&(i.textContent=g)},m(M,w){l(M,i,w)},p:Ut,d(M){M&&s(i)}}}function hs(J){let i,g,M,w,k,Ze,I,jt='It can be fun and creative to use multiple <a href="(https://huggingface.co/docs/peft/conceptual_guides/adapter#low-rank-adaptation-lora)">LoRAs</a> together to generate something entirely new and unique. This works by merging multiple LoRA weights together to produce images that are a blend of different styles. Diffusers provides a few methods to merge LoRAs depending on <em>how</em> you want to merge their weights, which can affect image quality.',Ue,$,_t='This guide will show you how to merge LoRAs using the <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a> and <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> methods. To improve inference speed and reduce memory-usage of merged LoRAs, youâ€™ll also see how to use the <code>fuse_lora()</code> method to fuse the LoRA weights with the original weights of the underlying model.',je,G,Wt='For this guide, load a Stable Diffusion XL (SDXL) checkpoint and the <a href="https://huggingface.co/KappaNeuro/studio-ghibli-style" rel="nofollow">KappaNeuro/studio-ghibli-style</a> and <a href="https://huggingface.co/Norod78/sdxl-chalkboarddrawing-lora" rel="nofollow">Norod78/sdxl-chalkboarddrawing-lora</a> LoRAs with the <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.StableDiffusionLoraLoaderMixin.load_lora_weights">load_lora_weights()</a> method. Youâ€™ll need to assign each LoRA an <code>adapter_name</code> to combine them later.',_e,v,We,R,ke,V,kt='The <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a> method merges LoRA adapters by concatenating their weighted matrices. Use the adapter name to specify which LoRAs to merge, and the <code>adapter_weights</code> parameter to control the scaling for each LoRA. For example, if <code>adapter_weights=[0.5, 0.5]</code>, then the merged LoRA output is an average of both LoRAs. Try adjusting the adapter weights to see how it affects the generated image!',Ie,B,$e,b,It='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/lora_merge_set_adapters.png"/>',Ge,C,ve,T,Re,L,$t='The <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> method provides access to more efficient merging method such as <a href="https://huggingface.co/docs/peft/developer_guides/model_merging" rel="nofollow">TIES and DARE</a>. To use these merging methods, make sure you have the latest stable version of Diffusers and PEFT installed.',Ve,q,Be,X,Gt='There are three steps to merge LoRAs with the <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> method:',Ce,F,vt='<li>Create a <a href="https://huggingface.co/docs/peft/package_reference/peft_model#peft.PeftModel" rel="nofollow">PeftModel</a> from the underlying model and LoRA checkpoint.</li> <li>Load a base UNet model and the LoRA adapters.</li> <li>Merge the adapters using the <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> method and the merging method of your choice.</li>',Le,Y,Rt="Letâ€™s dive deeper into what these steps entail.",qe,N,Vt="<li>Load a UNet that corresponds to the UNet in the LoRA checkpoint. In this case, both LoRAs use the SDXL UNet as their base model.</li>",Xe,x,Fe,E,Bt='Load the SDXL pipeline and the LoRA checkpoints, starting with the <a href="https://huggingface.co/ostris/ikea-instructions-lora-sdxl" rel="nofollow">ostris/ikea-instructions-lora-sdxl</a> LoRA.',Ye,Q,Ne,H,Ct='Now youâ€™ll create a <a href="https://huggingface.co/docs/peft/package_reference/peft_model#peft.PeftModel" rel="nofollow">PeftModel</a> from the loaded LoRA checkpoint by combining the SDXL UNet and the LoRA UNet from the pipeline.',xe,S,Ee,Z,Qe,z,Lt='Repeat this process to create a <a href="https://huggingface.co/docs/peft/package_reference/peft_model#peft.PeftModel" rel="nofollow">PeftModel</a> from the <a href="https://huggingface.co/lordjia/by-feng-zikai" rel="nofollow">lordjia/by-feng-zikai</a> LoRA.',He,A,Se,U,qt="<li>Load a base UNet model and then load the adapters onto it.</li>",ze,D,Ae,j,Xt='<li>Merge the adapters using the <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> method and the merging method of your choice (learn more about other merging methods in this <a href="https://huggingface.co/blog/peft_merging" rel="nofollow">blog post</a>). For this example, letâ€™s use the <code>&quot;dare_linear&quot;</code> method to merge the LoRAs.</li>',De,_,Pe,P,Ke,K,Ft="Now you can generate an image with the merged LoRA.",Oe,O,et,W,Yt='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/ikea-feng-dare-linear.png"/>',tt,ee,st,te,Nt='Both the <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a> and <a href="https://huggingface.co/docs/peft/package_reference/lora#peft.LoraModel.add_weighted_adapter" rel="nofollow">add_weighted_adapter</a> methods require loading the base model and the LoRA adapters separately which incurs some overhead. The <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.fuse_lora">fuse_lora()</a> method allows you to fuse the LoRA weights directly with the original weights of the underlying model. This way, youâ€™re only loading the model once which can increase inference and lower memory-usage.',lt,se,xt='You can use PEFT to easily fuse/unfuse multiple adapters directly into the model weights (both UNet and text encoder) using the <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.fuse_lora">fuse_lora()</a> method, which can lead to a speed-up in inference and lower VRAM usage.',at,le,Et="For example, if you have a base model and adapters loaded and set as active with the following adapter weights:",nt,ae,it,ne,Qt='Fuse these LoRAs into the UNet with the <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.fuse_lora">fuse_lora()</a> method. The <code>lora_scale</code> parameter controls how much to scale the output by with the LoRA weights. It is important to make the <code>lora_scale</code> adjustments in the <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.fuse_lora">fuse_lora()</a> method because it wonâ€™t work if you try to pass <code>scale</code> to the <code>cross_attention_kwargs</code> in the pipeline.',ot,ie,pt,oe,Ht='Then you should use <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.unload_lora_weights">unload_lora_weights()</a> to unload the LoRA weights since theyâ€™ve already been fused with the underlying base model. Finally, call <a href="/docs/diffusers/v0.33.1/en/api/pipelines/overview#diffusers.DiffusionPipeline.save_pretrained">save_pretrained()</a> to save the fused pipeline locally or you could call <a href="/docs/diffusers/v0.33.1/en/api/models/overview#diffusers.utils.PushToHubMixin.push_to_hub">push_to_hub()</a> to push the fused pipeline to the Hub.',rt,pe,dt,re,St="Now you can quickly load the fused pipeline and use it for inference without needing to separately load the LoRA adapters.",ut,de,ht,ue,zt="You can call <code>~~loaders.lora_base.LoraBaseMixin.unfuse_lora</code> to restore the original modelâ€™s weights (for example, if you want to use a different <code>lora_scale</code> value). However, this only works if youâ€™ve only fused one LoRA adapter to the original model. If youâ€™ve fused multiple LoRAs, youâ€™ll need to reload the model.",mt,he,ft,me,ct,fe,At='<a href="../optimization/torch2.0#torchcompile">torch.compile</a> can speed up your pipeline even more, but the LoRA weights must be fused first and then unloaded. Typically, the UNet is compiled because it is such a computationally intensive component of the pipeline.',Mt,ce,yt,Me,Dt='Learn more about torch.compile in the <a href="../tutorials/fast_diffusion#torchcompile">Accelerate inference of text-to-image diffusion models</a> guide.',gt,ye,wt,ge,Pt='For more conceptual details about how each merging method works, take a look at the <a href="https://huggingface.co/blog/peft_merging#concatenation-cat" rel="nofollow">ðŸ¤— PEFT welcomes new merging methods</a> blog post!',Jt,we,bt,Te,Tt;return k=new be({props:{title:"Merge LoRAs",local:"merge-loras",headingTag:"h1"}}),v=new y({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMERpZmZ1c2lvblBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYpLnRvKCUyMmN1ZGElMjIpJTBBcGlwZWxpbmUubG9hZF9sb3JhX3dlaWdodHMoJTIyb3N0cmlzJTJGaWtlYS1pbnN0cnVjdGlvbnMtbG9yYS1zZHhsJTIyJTJDJTIwd2VpZ2h0X25hbWUlM0QlMjJpa2VhX2luc3RydWN0aW9uc194bF92MV81LnNhZmV0ZW5zb3JzJTIyJTJDJTIwYWRhcHRlcl9uYW1lJTNEJTIyaWtlYSUyMiklMEFwaXBlbGluZS5sb2FkX2xvcmFfd2VpZ2h0cyglMjJsb3JkamlhJTJGYnktZmVuZy16aWthaSUyMiUyQyUyMHdlaWdodF9uYW1lJTNEJTIyZmVuZ3ppa2FpX3YxLjBfWEwuc2FmZXRlbnNvcnMlMjIlMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJmZW5nJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline
<span class="hljs-keyword">import</span> torch

pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16).to(<span class="hljs-string">&quot;cuda&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;ostris/ikea-instructions-lora-sdxl&quot;</span>, weight_name=<span class="hljs-string">&quot;ikea_instructions_xl_v1_5.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;ikea&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;lordjia/by-feng-zikai&quot;</span>, weight_name=<span class="hljs-string">&quot;fengzikai_v1.0_XL.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;feng&quot;</span>)`,wrap:!1}}),R=new be({props:{title:"set_adapters",local:"setadapters",headingTag:"h2"}}),B=new y({props:{code:"cGlwZWxpbmUuc2V0X2FkYXB0ZXJzKCU1QiUyMmlrZWElMjIlMkMlMjAlMjJmZW5nJTIyJTVEJTJDJTIwYWRhcHRlcl93ZWlnaHRzJTNEJTVCMC43JTJDJTIwMC44JTVEKSUwQSUwQWdlbmVyYXRvciUyMCUzRCUyMHRvcmNoLm1hbnVhbF9zZWVkKDApJTBBcHJvbXB0JTIwJTNEJTIwJTIyQSUyMGJvd2wlMjBvZiUyMHJhbWVuJTIwc2hhcGVkJTIwbGlrZSUyMGElMjBjdXRlJTIwa2F3YWlpJTIwYmVhciUyQyUyMGJ5JTIwRmVuZyUyMFppa2FpJTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZShwcm9tcHQlMkMlMjBnZW5lcmF0b3IlM0RnZW5lcmF0b3IlMkMlMjBjcm9zc19hdHRlbnRpb25fa3dhcmdzJTNEJTdCJTIyc2NhbGUlMjIlM0ElMjAxLjAlN0QpLmltYWdlcyU1QjAlNUQlMEFpbWFnZQ==",highlighted:`pipeline.set_adapters([<span class="hljs-string">&quot;ikea&quot;</span>, <span class="hljs-string">&quot;feng&quot;</span>], adapter_weights=[<span class="hljs-number">0.7</span>, <span class="hljs-number">0.8</span>])

generator = torch.manual_seed(<span class="hljs-number">0</span>)
prompt = <span class="hljs-string">&quot;A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai&quot;</span>
image = pipeline(prompt, generator=generator, cross_attention_kwargs={<span class="hljs-string">&quot;scale&quot;</span>: <span class="hljs-number">1.0</span>}).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),C=new be({props:{title:"add_weighted_adapter",local:"addweightedadapter",headingTag:"h2"}}),T=new Zt({props:{warning:!0,$$slots:{default:[rs]},$$scope:{ctx:J}}}),q=new y({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1VJTIwZGlmZnVzZXJzJTIwcGVmdA==",highlighted:"pip install -U diffusers peft",wrap:!1}}),x=new y({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMFVOZXQyRENvbmRpdGlvbk1vZGVsJTBBaW1wb3J0JTIwdG9yY2glMEElMEF1bmV0JTIwJTNEJTIwVU5ldDJEQ29uZGl0aW9uTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1iYXNlLTEuMCUyMiUyQyUwQSUyMCUyMCUyMCUyMHRvcmNoX2R0eXBlJTNEdG9yY2guZmxvYXQxNiUyQyUwQSUyMCUyMCUyMCUyMHVzZV9zYWZldGVuc29ycyUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjB2YXJpYW50JTNEJTIyZnAxNiUyMiUyQyUwQSUyMCUyMCUyMCUyMHN1YmZvbGRlciUzRCUyMnVuZXQlMjIlMkMlMEEpLnRvKCUyMmN1ZGElMjIp",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DConditionModel
<span class="hljs-keyword">import</span> torch

unet = UNet2DConditionModel.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>,
    torch_dtype=torch.float16,
    use_safetensors=<span class="hljs-literal">True</span>,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
    subfolder=<span class="hljs-string">&quot;unet&quot;</span>,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),Q=new y({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBJTBBcGlwZWxpbmUlMjAlM0QlMjBEaWZmdXNpb25QaXBlbGluZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyc3RhYmlsaXR5YWklMkZzdGFibGUtZGlmZnVzaW9uLXhsLWJhc2UtMS4wJTIyJTJDJTBBJTIwJTIwJTIwJTIwdmFyaWFudCUzRCUyMmZwMTYlMjIlMkMlMEElMjAlMjAlMjAlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMEElMjAlMjAlMjAlMjB1bmV0JTNEdW5ldCUwQSkudG8oJTIyY3VkYSUyMiklMEFwaXBlbGluZS5sb2FkX2xvcmFfd2VpZ2h0cyglMjJvc3RyaXMlMkZpa2VhLWluc3RydWN0aW9ucy1sb3JhLXNkeGwlMjIlMkMlMjB3ZWlnaHRfbmFtZSUzRCUyMmlrZWFfaW5zdHJ1Y3Rpb25zX3hsX3YxXzUuc2FmZXRlbnNvcnMlMjIlMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJpa2VhJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

pipeline = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
    torch_dtype=torch.float16,
    unet=unet
).to(<span class="hljs-string">&quot;cuda&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;ostris/ikea-instructions-lora-sdxl&quot;</span>, weight_name=<span class="hljs-string">&quot;ikea_instructions_xl_v1_5.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;ikea&quot;</span>)`,wrap:!1}}),S=new y({props:{code:"ZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBnZXRfcGVmdF9tb2RlbCUyQyUyMExvcmFDb25maWclMEFpbXBvcnQlMjBjb3B5JTBBJTBBc2R4bF91bmV0JTIwJTNEJTIwY29weS5kZWVwY29weSh1bmV0KSUwQWlrZWFfcGVmdF9tb2RlbCUyMCUzRCUyMGdldF9wZWZ0X21vZGVsKCUwQSUyMCUyMCUyMCUyMHNkeGxfdW5ldCUyQyUwQSUyMCUyMCUyMCUyMHBpcGVsaW5lLnVuZXQucGVmdF9jb25maWclNUIlMjJpa2VhJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwYWRhcHRlcl9uYW1lJTNEJTIyaWtlYSUyMiUwQSklMEElMEFvcmlnaW5hbF9zdGF0ZV9kaWN0JTIwJTNEJTIwJTdCZiUyMmJhc2VfbW9kZWwubW9kZWwuJTdCayU3RCUyMiUzQSUyMHYlMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwcGlwZWxpbmUudW5ldC5zdGF0ZV9kaWN0KCkuaXRlbXMoKSU3RCUwQWlrZWFfcGVmdF9tb2RlbC5sb2FkX3N0YXRlX2RpY3Qob3JpZ2luYWxfc3RhdGVfZGljdCUyQyUyMHN0cmljdCUzRFRydWUp",highlighted:`<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> get_peft_model, LoraConfig
<span class="hljs-keyword">import</span> copy

sdxl_unet = copy.deepcopy(unet)
ikea_peft_model = get_peft_model(
    sdxl_unet,
    pipeline.unet.peft_config[<span class="hljs-string">&quot;ikea&quot;</span>],
    adapter_name=<span class="hljs-string">&quot;ikea&quot;</span>
)

original_state_dict = {<span class="hljs-string">f&quot;base_model.model.<span class="hljs-subst">{k}</span>&quot;</span>: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> pipeline.unet.state_dict().items()}
ikea_peft_model.load_state_dict(original_state_dict, strict=<span class="hljs-literal">True</span>)`,wrap:!1}}),Z=new Zt({props:{warning:!1,$$slots:{default:[ds]},$$scope:{ctx:J}}}),A=new y({props:{code:"cGlwZWxpbmUuZGVsZXRlX2FkYXB0ZXJzKCUyMmlrZWElMjIpJTBBc2R4bF91bmV0LmRlbGV0ZV9hZGFwdGVycyglMjJpa2VhJTIyKSUwQSUwQXBpcGVsaW5lLmxvYWRfbG9yYV93ZWlnaHRzKCUyMmxvcmRqaWElMkZieS1mZW5nLXppa2FpJTIyJTJDJTIwd2VpZ2h0X25hbWUlM0QlMjJmZW5nemlrYWlfdjEuMF9YTC5zYWZldGVuc29ycyUyMiUyQyUyMGFkYXB0ZXJfbmFtZSUzRCUyMmZlbmclMjIpJTBBcGlwZWxpbmUuc2V0X2FkYXB0ZXJzKGFkYXB0ZXJfbmFtZXMlM0QlMjJmZW5nJTIyKSUwQSUwQWZlbmdfcGVmdF9tb2RlbCUyMCUzRCUyMGdldF9wZWZ0X21vZGVsKCUwQSUyMCUyMCUyMCUyMHNkeGxfdW5ldCUyQyUwQSUyMCUyMCUyMCUyMHBpcGVsaW5lLnVuZXQucGVmdF9jb25maWclNUIlMjJmZW5nJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwYWRhcHRlcl9uYW1lJTNEJTIyZmVuZyUyMiUwQSklMEElMEFvcmlnaW5hbF9zdGF0ZV9kaWN0JTIwJTNEJTIwJTdCZiUyMmJhc2VfbW9kZWwubW9kZWwuJTdCayU3RCUyMiUzQSUyMHYlMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwcGlwZS51bmV0LnN0YXRlX2RpY3QoKS5pdGVtcygpJTdEJTBBZmVuZ19wZWZ0X21vZGVsLmxvYWRfc3RhdGVfZGljdChvcmlnaW5hbF9zdGF0ZV9kaWN0JTJDJTIwc3RyaWN0JTNEVHJ1ZSk=",highlighted:`pipeline.delete_adapters(<span class="hljs-string">&quot;ikea&quot;</span>)
sdxl_unet.delete_adapters(<span class="hljs-string">&quot;ikea&quot;</span>)

pipeline.load_lora_weights(<span class="hljs-string">&quot;lordjia/by-feng-zikai&quot;</span>, weight_name=<span class="hljs-string">&quot;fengzikai_v1.0_XL.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;feng&quot;</span>)
pipeline.set_adapters(adapter_names=<span class="hljs-string">&quot;feng&quot;</span>)

feng_peft_model = get_peft_model(
    sdxl_unet,
    pipeline.unet.peft_config[<span class="hljs-string">&quot;feng&quot;</span>],
    adapter_name=<span class="hljs-string">&quot;feng&quot;</span>
)

original_state_dict = {<span class="hljs-string">f&quot;base_model.model.<span class="hljs-subst">{k}</span>&quot;</span>: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> pipe.unet.state_dict().items()}
feng_peft_model.load_state_dict(original_state_dict, strict=<span class="hljs-literal">True</span>)`,wrap:!1}}),D=new y({props:{code:"ZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBQZWZ0TW9kZWwlMEElMEFiYXNlX3VuZXQlMjAlM0QlMjBVTmV0MkRDb25kaXRpb25Nb2RlbC5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyc3RhYmlsaXR5YWklMkZzdGFibGUtZGlmZnVzaW9uLXhsLWJhc2UtMS4wJTIyJTJDJTBBJTIwJTIwJTIwJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBJTIwJTIwJTIwJTIwdXNlX3NhZmV0ZW5zb3JzJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTBBJTIwJTIwJTIwJTIwc3ViZm9sZGVyJTNEJTIydW5ldCUyMiUyQyUwQSkudG8oJTIyY3VkYSUyMiklMEElMEFtb2RlbCUyMCUzRCUyMFBlZnRNb2RlbC5mcm9tX3ByZXRyYWluZWQoYmFzZV91bmV0JTJDJTIwJTIyc3RldmhsaXUlMkZpa2VhX3BlZnRfbW9kZWwlMjIlMkMlMjB1c2Vfc2FmZXRlbnNvcnMlM0RUcnVlJTJDJTIwc3ViZm9sZGVyJTNEJTIyaWtlYSUyMiUyQyUyMGFkYXB0ZXJfbmFtZSUzRCUyMmlrZWElMjIpJTBBbW9kZWwubG9hZF9hZGFwdGVyKCUyMnN0ZXZobGl1JTJGZmVuZ19wZWZ0X21vZGVsJTIyJTJDJTIwdXNlX3NhZmV0ZW5zb3JzJTNEVHJ1ZSUyQyUyMHN1YmZvbGRlciUzRCUyMmZlbmclMjIlMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJmZW5nJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftModel

base_unet = UNet2DConditionModel.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>,
    torch_dtype=torch.float16,
    use_safetensors=<span class="hljs-literal">True</span>,
    variant=<span class="hljs-string">&quot;fp16&quot;</span>,
    subfolder=<span class="hljs-string">&quot;unet&quot;</span>,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

model = PeftModel.from_pretrained(base_unet, <span class="hljs-string">&quot;stevhliu/ikea_peft_model&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>, subfolder=<span class="hljs-string">&quot;ikea&quot;</span>, adapter_name=<span class="hljs-string">&quot;ikea&quot;</span>)
model.load_adapter(<span class="hljs-string">&quot;stevhliu/feng_peft_model&quot;</span>, use_safetensors=<span class="hljs-literal">True</span>, subfolder=<span class="hljs-string">&quot;feng&quot;</span>, adapter_name=<span class="hljs-string">&quot;feng&quot;</span>)`,wrap:!1}}),_=new Zt({props:{warning:!0,$$slots:{default:[us]},$$scope:{ctx:J}}}),P=new y({props:{code:"bW9kZWwuYWRkX3dlaWdodGVkX2FkYXB0ZXIoJTBBJTIwJTIwJTIwJTIwYWRhcHRlcnMlM0QlNUIlMjJpa2VhJTIyJTJDJTIwJTIyZmVuZyUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodHMlM0QlNUIxLjAlMkMlMjAxLjAlNUQlMkMlMEElMjAlMjAlMjAlMjBjb21iaW5hdGlvbl90eXBlJTNEJTIyZGFyZV9saW5lYXIlMjIlMkMlMEElMjAlMjAlMjAlMjBhZGFwdGVyX25hbWUlM0QlMjJpa2VhLWZlbmclMjIlMEEpJTBBbW9kZWwuc2V0X2FkYXB0ZXJzKCUyMmlrZWEtZmVuZyUyMik=",highlighted:`model.add_weighted_adapter(
    adapters=[<span class="hljs-string">&quot;ikea&quot;</span>, <span class="hljs-string">&quot;feng&quot;</span>],
    weights=[<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],
    combination_type=<span class="hljs-string">&quot;dare_linear&quot;</span>,
    adapter_name=<span class="hljs-string">&quot;ikea-feng&quot;</span>
)
model.set_adapters(<span class="hljs-string">&quot;ikea-feng&quot;</span>)`,wrap:!1}}),O=new y({props:{code:"bW9kZWwlMjAlM0QlMjBtb2RlbC50byhkdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMjBkZXZpY2UlM0QlMjJjdWRhJTIyKSUwQSUwQXBpcGVsaW5lJTIwJTNEJTIwRGlmZnVzaW9uUGlwZWxpbmUuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMnN0YWJpbGl0eWFpJTJGc3RhYmxlLWRpZmZ1c2lvbi14bC1iYXNlLTEuMCUyMiUyQyUyMHVuZXQlM0Rtb2RlbCUyQyUyMHZhcmlhbnQlM0QlMjJmcDE2JTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2JTJDJTBBKS50byglMjJjdWRhJTIyKSUwQSUwQWltYWdlJTIwJTNEJTIwcGlwZWxpbmUoJTIyQSUyMGJvd2wlMjBvZiUyMHJhbWVuJTIwc2hhcGVkJTIwbGlrZSUyMGElMjBjdXRlJTIwa2F3YWlpJTIwYmVhciUyQyUyMGJ5JTIwRmVuZyUyMFppa2FpJTIyJTJDJTIwZ2VuZXJhdG9yJTNEdG9yY2gubWFudWFsX3NlZWQoMCkpLmltYWdlcyU1QjAlNUQlMEFpbWFnZQ==",highlighted:`model = model.to(dtype=torch.float16, device=<span class="hljs-string">&quot;cuda&quot;</span>)

pipeline = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, unet=model, variant=<span class="hljs-string">&quot;fp16&quot;</span>, torch_dtype=torch.float16,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

image = pipeline(<span class="hljs-string">&quot;A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai&quot;</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),ee=new be({props:{title:"fuse_lora",local:"fuselora",headingTag:"h2"}}),ae=new y({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlbGluZSUyMCUzRCUyMERpZmZ1c2lvblBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYpLnRvKCUyMmN1ZGElMjIpJTBBcGlwZWxpbmUubG9hZF9sb3JhX3dlaWdodHMoJTIyb3N0cmlzJTJGaWtlYS1pbnN0cnVjdGlvbnMtbG9yYS1zZHhsJTIyJTJDJTIwd2VpZ2h0X25hbWUlM0QlMjJpa2VhX2luc3RydWN0aW9uc194bF92MV81LnNhZmV0ZW5zb3JzJTIyJTJDJTIwYWRhcHRlcl9uYW1lJTNEJTIyaWtlYSUyMiklMEFwaXBlbGluZS5sb2FkX2xvcmFfd2VpZ2h0cyglMjJsb3JkamlhJTJGYnktZmVuZy16aWthaSUyMiUyQyUyMHdlaWdodF9uYW1lJTNEJTIyZmVuZ3ppa2FpX3YxLjBfWEwuc2FmZXRlbnNvcnMlMjIlMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJmZW5nJTIyKSUwQSUwQXBpcGVsaW5lLnNldF9hZGFwdGVycyglNUIlMjJpa2VhJTIyJTJDJTIwJTIyZmVuZyUyMiU1RCUyQyUyMGFkYXB0ZXJfd2VpZ2h0cyUzRCU1QjAuNyUyQyUyMDAuOCU1RCk=",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline
<span class="hljs-keyword">import</span> torch

pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16).to(<span class="hljs-string">&quot;cuda&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;ostris/ikea-instructions-lora-sdxl&quot;</span>, weight_name=<span class="hljs-string">&quot;ikea_instructions_xl_v1_5.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;ikea&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;lordjia/by-feng-zikai&quot;</span>, weight_name=<span class="hljs-string">&quot;fengzikai_v1.0_XL.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;feng&quot;</span>)

pipeline.set_adapters([<span class="hljs-string">&quot;ikea&quot;</span>, <span class="hljs-string">&quot;feng&quot;</span>], adapter_weights=[<span class="hljs-number">0.7</span>, <span class="hljs-number">0.8</span>])`,wrap:!1}}),ie=new y({props:{code:"cGlwZWxpbmUuZnVzZV9sb3JhKGFkYXB0ZXJfbmFtZXMlM0QlNUIlMjJpa2VhJTIyJTJDJTIwJTIyZmVuZyUyMiU1RCUyQyUyMGxvcmFfc2NhbGUlM0QxLjAp",highlighted:'pipeline.fuse_lora(adapter_names=[<span class="hljs-string">&quot;ikea&quot;</span>, <span class="hljs-string">&quot;feng&quot;</span>], lora_scale=<span class="hljs-number">1.0</span>)',wrap:!1}}),pe=new y({props:{code:"cGlwZWxpbmUudW5sb2FkX2xvcmFfd2VpZ2h0cygpJTBBJTIzJTIwc2F2ZSUyMGxvY2FsbHklMEFwaXBlbGluZS5zYXZlX3ByZXRyYWluZWQoJTIycGF0aCUyRnRvJTJGZnVzZWQtcGlwZWxpbmUlMjIpJTBBJTIzJTIwc2F2ZSUyMHRvJTIwdGhlJTIwSHViJTBBcGlwZWxpbmUucHVzaF90b19odWIoJTIyZnVzZWQtaWtlYS1mZW5nJTIyKQ==",highlighted:`pipeline.unload_lora_weights()
<span class="hljs-comment"># save locally</span>
pipeline.save_pretrained(<span class="hljs-string">&quot;path/to/fused-pipeline&quot;</span>)
<span class="hljs-comment"># save to the Hub</span>
pipeline.push_to_hub(<span class="hljs-string">&quot;fused-ikea-feng&quot;</span>)`,wrap:!1}}),de=new y({props:{code:"cGlwZWxpbmUlMjAlM0QlMjBEaWZmdXNpb25QaXBlbGluZS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIydXNlcm5hbWUlMkZmdXNlZC1pa2VhLWZlbmclMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMkMlMEEpLnRvKCUyMmN1ZGElMjIpJTBBJTBBaW1hZ2UlMjAlM0QlMjBwaXBlbGluZSglMjJBJTIwYm93bCUyMG9mJTIwcmFtZW4lMjBzaGFwZWQlMjBsaWtlJTIwYSUyMGN1dGUlMjBrYXdhaWklMjBiZWFyJTJDJTIwYnklMjBGZW5nJTIwWmlrYWklMjIlMkMlMjBnZW5lcmF0b3IlM0R0b3JjaC5tYW51YWxfc2VlZCgwKSkuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`pipeline = DiffusionPipeline.from_pretrained(
    <span class="hljs-string">&quot;username/fused-ikea-feng&quot;</span>, torch_dtype=torch.float16,
).to(<span class="hljs-string">&quot;cuda&quot;</span>)

image = pipeline(<span class="hljs-string">&quot;A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai&quot;</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),he=new y({props:{code:"cGlwZWxpbmUudW5mdXNlX2xvcmEoKQ==",highlighted:"pipeline.unfuse_lora()",wrap:!1}}),me=new be({props:{title:"torch.compile",local:"torchcompile",headingTag:"h3"}}),ce=new y({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEElMjMlMjBsb2FkJTIwYmFzZSUyMG1vZGVsJTIwYW5kJTIwTG9SQXMlMEFwaXBlbGluZSUyMCUzRCUyMERpZmZ1c2lvblBpcGVsaW5lLmZyb21fcHJldHJhaW5lZCglMjJzdGFiaWxpdHlhaSUyRnN0YWJsZS1kaWZmdXNpb24teGwtYmFzZS0xLjAlMjIlMkMlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmZsb2F0MTYpLnRvKCUyMmN1ZGElMjIpJTBBcGlwZWxpbmUubG9hZF9sb3JhX3dlaWdodHMoJTIyb3N0cmlzJTJGaWtlYS1pbnN0cnVjdGlvbnMtbG9yYS1zZHhsJTIyJTJDJTIwd2VpZ2h0X25hbWUlM0QlMjJpa2VhX2luc3RydWN0aW9uc194bF92MV81LnNhZmV0ZW5zb3JzJTIyJTJDJTIwYWRhcHRlcl9uYW1lJTNEJTIyaWtlYSUyMiklMEFwaXBlbGluZS5sb2FkX2xvcmFfd2VpZ2h0cyglMjJsb3JkamlhJTJGYnktZmVuZy16aWthaSUyMiUyQyUyMHdlaWdodF9uYW1lJTNEJTIyZmVuZ3ppa2FpX3YxLjBfWEwuc2FmZXRlbnNvcnMlMjIlMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJmZW5nJTIyKSUwQSUwQSUyMyUyMGFjdGl2YXRlJTIwYm90aCUyMExvUkFzJTIwYW5kJTIwc2V0JTIwYWRhcHRlciUyMHdlaWdodHMlMEFwaXBlbGluZS5zZXRfYWRhcHRlcnMoJTVCJTIyaWtlYSUyMiUyQyUyMCUyMmZlbmclMjIlNUQlMkMlMjBhZGFwdGVyX3dlaWdodHMlM0QlNUIwLjclMkMlMjAwLjglNUQpJTBBJTBBJTIzJTIwZnVzZSUyMExvUkFzJTIwYW5kJTIwdW5sb2FkJTIwd2VpZ2h0cyUwQXBpcGVsaW5lLmZ1c2VfbG9yYShhZGFwdGVyX25hbWVzJTNEJTVCJTIyaWtlYSUyMiUyQyUyMCUyMmZlbmclMjIlNUQlMkMlMjBsb3JhX3NjYWxlJTNEMS4wKSUwQXBpcGVsaW5lLnVubG9hZF9sb3JhX3dlaWdodHMoKSUwQSUwQSUyMyUyMHRvcmNoLmNvbXBpbGUlMEFwaXBlbGluZS51bmV0LnRvKG1lbW9yeV9mb3JtYXQlM0R0b3JjaC5jaGFubmVsc19sYXN0KSUwQXBpcGVsaW5lLnVuZXQlMjAlM0QlMjB0b3JjaC5jb21waWxlKHBpcGVsaW5lLnVuZXQlMkMlMjBtb2RlJTNEJTIycmVkdWNlLW92ZXJoZWFkJTIyJTJDJTIwZnVsbGdyYXBoJTNEVHJ1ZSklMEElMEFpbWFnZSUyMCUzRCUyMHBpcGVsaW5lKCUyMkElMjBib3dsJTIwb2YlMjByYW1lbiUyMHNoYXBlZCUyMGxpa2UlMjBhJTIwY3V0ZSUyMGthd2FpaSUyMGJlYXIlMkMlMjBieSUyMEZlbmclMjBaaWthaSUyMiUyQyUyMGdlbmVyYXRvciUzRHRvcmNoLm1hbnVhbF9zZWVkKDApKS5pbWFnZXMlNUIwJTVE",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline
<span class="hljs-keyword">import</span> torch

<span class="hljs-comment"># load base model and LoRAs</span>
pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>, torch_dtype=torch.float16).to(<span class="hljs-string">&quot;cuda&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;ostris/ikea-instructions-lora-sdxl&quot;</span>, weight_name=<span class="hljs-string">&quot;ikea_instructions_xl_v1_5.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;ikea&quot;</span>)
pipeline.load_lora_weights(<span class="hljs-string">&quot;lordjia/by-feng-zikai&quot;</span>, weight_name=<span class="hljs-string">&quot;fengzikai_v1.0_XL.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;feng&quot;</span>)

<span class="hljs-comment"># activate both LoRAs and set adapter weights</span>
pipeline.set_adapters([<span class="hljs-string">&quot;ikea&quot;</span>, <span class="hljs-string">&quot;feng&quot;</span>], adapter_weights=[<span class="hljs-number">0.7</span>, <span class="hljs-number">0.8</span>])

<span class="hljs-comment"># fuse LoRAs and unload weights</span>
pipeline.fuse_lora(adapter_names=[<span class="hljs-string">&quot;ikea&quot;</span>, <span class="hljs-string">&quot;feng&quot;</span>], lora_scale=<span class="hljs-number">1.0</span>)
pipeline.unload_lora_weights()

<span class="hljs-comment"># torch.compile</span>
pipeline.unet.to(memory_format=torch.channels_last)
pipeline.unet = torch.<span class="hljs-built_in">compile</span>(pipeline.unet, mode=<span class="hljs-string">&quot;reduce-overhead&quot;</span>, fullgraph=<span class="hljs-literal">True</span>)

image = pipeline(<span class="hljs-string">&quot;A bowl of ramen shaped like a cute kawaii bear, by Feng Zikai&quot;</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]`,wrap:!1}}),ye=new be({props:{title:"Next steps",local:"next-steps",headingTag:"h2"}}),we=new ps({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/using-diffusers/merge_loras.md"}}),{c(){i=o("meta"),g=a(),M=o("p"),w=a(),d(k.$$.fragment),Ze=a(),I=o("p"),I.innerHTML=jt,Ue=a(),$=o("p"),$.innerHTML=_t,je=a(),G=o("p"),G.innerHTML=Wt,_e=a(),d(v.$$.fragment),We=a(),d(R.$$.fragment),ke=a(),V=o("p"),V.innerHTML=kt,Ie=a(),d(B.$$.fragment),$e=a(),b=o("div"),b.innerHTML=It,Ge=a(),d(C.$$.fragment),ve=a(),d(T.$$.fragment),Re=a(),L=o("p"),L.innerHTML=$t,Ve=a(),d(q.$$.fragment),Be=a(),X=o("p"),X.innerHTML=Gt,Ce=a(),F=o("ol"),F.innerHTML=vt,Le=a(),Y=o("p"),Y.textContent=Rt,qe=a(),N=o("ol"),N.innerHTML=Vt,Xe=a(),d(x.$$.fragment),Fe=a(),E=o("p"),E.innerHTML=Bt,Ye=a(),d(Q.$$.fragment),Ne=a(),H=o("p"),H.innerHTML=Ct,xe=a(),d(S.$$.fragment),Ee=a(),d(Z.$$.fragment),Qe=a(),z=o("p"),z.innerHTML=Lt,He=a(),d(A.$$.fragment),Se=a(),U=o("ol"),U.innerHTML=qt,ze=a(),d(D.$$.fragment),Ae=a(),j=o("ol"),j.innerHTML=Xt,De=a(),d(_.$$.fragment),Pe=a(),d(P.$$.fragment),Ke=a(),K=o("p"),K.textContent=Ft,Oe=a(),d(O.$$.fragment),et=a(),W=o("div"),W.innerHTML=Yt,tt=a(),d(ee.$$.fragment),st=a(),te=o("p"),te.innerHTML=Nt,lt=a(),se=o("p"),se.innerHTML=xt,at=a(),le=o("p"),le.textContent=Et,nt=a(),d(ae.$$.fragment),it=a(),ne=o("p"),ne.innerHTML=Qt,ot=a(),d(ie.$$.fragment),pt=a(),oe=o("p"),oe.innerHTML=Ht,rt=a(),d(pe.$$.fragment),dt=a(),re=o("p"),re.textContent=St,ut=a(),d(de.$$.fragment),ht=a(),ue=o("p"),ue.innerHTML=zt,mt=a(),d(he.$$.fragment),ft=a(),d(me.$$.fragment),ct=a(),fe=o("p"),fe.innerHTML=At,Mt=a(),d(ce.$$.fragment),yt=a(),Me=o("p"),Me.innerHTML=Dt,gt=a(),d(ye.$$.fragment),wt=a(),ge=o("p"),ge.innerHTML=Pt,Jt=a(),d(we.$$.fragment),bt=a(),Te=o("p"),this.h()},l(e){const t=is("svelte-u9bgzb",document.head);i=p(t,"META",{name:!0,content:!0}),t.forEach(s),g=n(e),M=p(e,"P",{}),ts(M).forEach(s),w=n(e),u(k.$$.fragment,e),Ze=n(e),I=p(e,"P",{"data-svelte-h":!0}),r(I)!=="svelte-cyt3kz"&&(I.innerHTML=jt),Ue=n(e),$=p(e,"P",{"data-svelte-h":!0}),r($)!=="svelte-1euhkpy"&&($.innerHTML=_t),je=n(e),G=p(e,"P",{"data-svelte-h":!0}),r(G)!=="svelte-2yzbhb"&&(G.innerHTML=Wt),_e=n(e),u(v.$$.fragment,e),We=n(e),u(R.$$.fragment,e),ke=n(e),V=p(e,"P",{"data-svelte-h":!0}),r(V)!=="svelte-348ndd"&&(V.innerHTML=kt),Ie=n(e),u(B.$$.fragment,e),$e=n(e),b=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(b)!=="svelte-rp1f80"&&(b.innerHTML=It),Ge=n(e),u(C.$$.fragment,e),ve=n(e),u(T.$$.fragment,e),Re=n(e),L=p(e,"P",{"data-svelte-h":!0}),r(L)!=="svelte-159dnvr"&&(L.innerHTML=$t),Ve=n(e),u(q.$$.fragment,e),Be=n(e),X=p(e,"P",{"data-svelte-h":!0}),r(X)!=="svelte-1pepmug"&&(X.innerHTML=Gt),Ce=n(e),F=p(e,"OL",{"data-svelte-h":!0}),r(F)!=="svelte-1n5q3v7"&&(F.innerHTML=vt),Le=n(e),Y=p(e,"P",{"data-svelte-h":!0}),r(Y)!=="svelte-qks3mn"&&(Y.textContent=Rt),qe=n(e),N=p(e,"OL",{"data-svelte-h":!0}),r(N)!=="svelte-143mnwl"&&(N.innerHTML=Vt),Xe=n(e),u(x.$$.fragment,e),Fe=n(e),E=p(e,"P",{"data-svelte-h":!0}),r(E)!=="svelte-12jcnpd"&&(E.innerHTML=Bt),Ye=n(e),u(Q.$$.fragment,e),Ne=n(e),H=p(e,"P",{"data-svelte-h":!0}),r(H)!=="svelte-kj4wso"&&(H.innerHTML=Ct),xe=n(e),u(S.$$.fragment,e),Ee=n(e),u(Z.$$.fragment,e),Qe=n(e),z=p(e,"P",{"data-svelte-h":!0}),r(z)!=="svelte-92zrkz"&&(z.innerHTML=Lt),He=n(e),u(A.$$.fragment,e),Se=n(e),U=p(e,"OL",{start:!0,"data-svelte-h":!0}),r(U)!=="svelte-1c06g8d"&&(U.innerHTML=qt),ze=n(e),u(D.$$.fragment,e),Ae=n(e),j=p(e,"OL",{start:!0,"data-svelte-h":!0}),r(j)!=="svelte-4c31b3"&&(j.innerHTML=Xt),De=n(e),u(_.$$.fragment,e),Pe=n(e),u(P.$$.fragment,e),Ke=n(e),K=p(e,"P",{"data-svelte-h":!0}),r(K)!=="svelte-18i0m5d"&&(K.textContent=Ft),Oe=n(e),u(O.$$.fragment,e),et=n(e),W=p(e,"DIV",{class:!0,"data-svelte-h":!0}),r(W)!=="svelte-o7lfk9"&&(W.innerHTML=Yt),tt=n(e),u(ee.$$.fragment,e),st=n(e),te=p(e,"P",{"data-svelte-h":!0}),r(te)!=="svelte-7jvwt1"&&(te.innerHTML=Nt),lt=n(e),se=p(e,"P",{"data-svelte-h":!0}),r(se)!=="svelte-12w5xvg"&&(se.innerHTML=xt),at=n(e),le=p(e,"P",{"data-svelte-h":!0}),r(le)!=="svelte-clyzop"&&(le.textContent=Et),nt=n(e),u(ae.$$.fragment,e),it=n(e),ne=p(e,"P",{"data-svelte-h":!0}),r(ne)!=="svelte-ycn368"&&(ne.innerHTML=Qt),ot=n(e),u(ie.$$.fragment,e),pt=n(e),oe=p(e,"P",{"data-svelte-h":!0}),r(oe)!=="svelte-yf215y"&&(oe.innerHTML=Ht),rt=n(e),u(pe.$$.fragment,e),dt=n(e),re=p(e,"P",{"data-svelte-h":!0}),r(re)!=="svelte-1nux4z4"&&(re.textContent=St),ut=n(e),u(de.$$.fragment,e),ht=n(e),ue=p(e,"P",{"data-svelte-h":!0}),r(ue)!=="svelte-hir9f5"&&(ue.innerHTML=zt),mt=n(e),u(he.$$.fragment,e),ft=n(e),u(me.$$.fragment,e),ct=n(e),fe=p(e,"P",{"data-svelte-h":!0}),r(fe)!=="svelte-h1d3ky"&&(fe.innerHTML=At),Mt=n(e),u(ce.$$.fragment,e),yt=n(e),Me=p(e,"P",{"data-svelte-h":!0}),r(Me)!=="svelte-106h2ac"&&(Me.innerHTML=Dt),gt=n(e),u(ye.$$.fragment,e),wt=n(e),ge=p(e,"P",{"data-svelte-h":!0}),r(ge)!=="svelte-1j7n00j"&&(ge.innerHTML=Pt),Jt=n(e),u(we.$$.fragment,e),bt=n(e),Te=p(e,"P",{}),ts(Te).forEach(s),this.h()},h(){Je(i,"name","hf:doc:metadata"),Je(i,"content",ms),Je(b,"class","flex justify-center"),Je(U,"start","2"),Je(j,"start","3"),Je(W,"class","flex justify-center")},m(e,t){os(document.head,i),l(e,g,t),l(e,M,t),l(e,w,t),h(k,e,t),l(e,Ze,t),l(e,I,t),l(e,Ue,t),l(e,$,t),l(e,je,t),l(e,G,t),l(e,_e,t),h(v,e,t),l(e,We,t),h(R,e,t),l(e,ke,t),l(e,V,t),l(e,Ie,t),h(B,e,t),l(e,$e,t),l(e,b,t),l(e,Ge,t),h(C,e,t),l(e,ve,t),h(T,e,t),l(e,Re,t),l(e,L,t),l(e,Ve,t),h(q,e,t),l(e,Be,t),l(e,X,t),l(e,Ce,t),l(e,F,t),l(e,Le,t),l(e,Y,t),l(e,qe,t),l(e,N,t),l(e,Xe,t),h(x,e,t),l(e,Fe,t),l(e,E,t),l(e,Ye,t),h(Q,e,t),l(e,Ne,t),l(e,H,t),l(e,xe,t),h(S,e,t),l(e,Ee,t),h(Z,e,t),l(e,Qe,t),l(e,z,t),l(e,He,t),h(A,e,t),l(e,Se,t),l(e,U,t),l(e,ze,t),h(D,e,t),l(e,Ae,t),l(e,j,t),l(e,De,t),h(_,e,t),l(e,Pe,t),h(P,e,t),l(e,Ke,t),l(e,K,t),l(e,Oe,t),h(O,e,t),l(e,et,t),l(e,W,t),l(e,tt,t),h(ee,e,t),l(e,st,t),l(e,te,t),l(e,lt,t),l(e,se,t),l(e,at,t),l(e,le,t),l(e,nt,t),h(ae,e,t),l(e,it,t),l(e,ne,t),l(e,ot,t),h(ie,e,t),l(e,pt,t),l(e,oe,t),l(e,rt,t),h(pe,e,t),l(e,dt,t),l(e,re,t),l(e,ut,t),h(de,e,t),l(e,ht,t),l(e,ue,t),l(e,mt,t),h(he,e,t),l(e,ft,t),h(me,e,t),l(e,ct,t),l(e,fe,t),l(e,Mt,t),h(ce,e,t),l(e,yt,t),l(e,Me,t),l(e,gt,t),h(ye,e,t),l(e,wt,t),l(e,ge,t),l(e,Jt,t),h(we,e,t),l(e,bt,t),l(e,Te,t),Tt=!0},p(e,[t]){const Kt={};t&2&&(Kt.$$scope={dirty:t,ctx:e}),T.$set(Kt);const Ot={};t&2&&(Ot.$$scope={dirty:t,ctx:e}),Z.$set(Ot);const es={};t&2&&(es.$$scope={dirty:t,ctx:e}),_.$set(es)},i(e){Tt||(m(k.$$.fragment,e),m(v.$$.fragment,e),m(R.$$.fragment,e),m(B.$$.fragment,e),m(C.$$.fragment,e),m(T.$$.fragment,e),m(q.$$.fragment,e),m(x.$$.fragment,e),m(Q.$$.fragment,e),m(S.$$.fragment,e),m(Z.$$.fragment,e),m(A.$$.fragment,e),m(D.$$.fragment,e),m(_.$$.fragment,e),m(P.$$.fragment,e),m(O.$$.fragment,e),m(ee.$$.fragment,e),m(ae.$$.fragment,e),m(ie.$$.fragment,e),m(pe.$$.fragment,e),m(de.$$.fragment,e),m(he.$$.fragment,e),m(me.$$.fragment,e),m(ce.$$.fragment,e),m(ye.$$.fragment,e),m(we.$$.fragment,e),Tt=!0)},o(e){f(k.$$.fragment,e),f(v.$$.fragment,e),f(R.$$.fragment,e),f(B.$$.fragment,e),f(C.$$.fragment,e),f(T.$$.fragment,e),f(q.$$.fragment,e),f(x.$$.fragment,e),f(Q.$$.fragment,e),f(S.$$.fragment,e),f(Z.$$.fragment,e),f(A.$$.fragment,e),f(D.$$.fragment,e),f(_.$$.fragment,e),f(P.$$.fragment,e),f(O.$$.fragment,e),f(ee.$$.fragment,e),f(ae.$$.fragment,e),f(ie.$$.fragment,e),f(pe.$$.fragment,e),f(de.$$.fragment,e),f(he.$$.fragment,e),f(me.$$.fragment,e),f(ce.$$.fragment,e),f(ye.$$.fragment,e),f(we.$$.fragment,e),Tt=!1},d(e){e&&(s(g),s(M),s(w),s(Ze),s(I),s(Ue),s($),s(je),s(G),s(_e),s(We),s(ke),s(V),s(Ie),s($e),s(b),s(Ge),s(ve),s(Re),s(L),s(Ve),s(Be),s(X),s(Ce),s(F),s(Le),s(Y),s(qe),s(N),s(Xe),s(Fe),s(E),s(Ye),s(Ne),s(H),s(xe),s(Ee),s(Qe),s(z),s(He),s(Se),s(U),s(ze),s(Ae),s(j),s(De),s(Pe),s(Ke),s(K),s(Oe),s(et),s(W),s(tt),s(st),s(te),s(lt),s(se),s(at),s(le),s(nt),s(it),s(ne),s(ot),s(pt),s(oe),s(rt),s(dt),s(re),s(ut),s(ht),s(ue),s(mt),s(ft),s(ct),s(fe),s(Mt),s(yt),s(Me),s(gt),s(wt),s(ge),s(Jt),s(bt),s(Te)),s(i),c(k,e),c(v,e),c(R,e),c(B,e),c(C,e),c(T,e),c(q,e),c(x,e),c(Q,e),c(S,e),c(Z,e),c(A,e),c(D,e),c(_,e),c(P,e),c(O,e),c(ee,e),c(ae,e),c(ie,e),c(pe,e),c(de,e),c(he,e),c(me,e),c(ce,e),c(ye,e),c(we,e)}}}const ms='{"title":"Merge LoRAs","local":"merge-loras","sections":[{"title":"set_adapters","local":"setadapters","sections":[],"depth":2},{"title":"add_weighted_adapter","local":"addweightedadapter","sections":[],"depth":2},{"title":"fuse_lora","local":"fuselora","sections":[{"title":"torch.compile","local":"torchcompile","sections":[],"depth":3}],"depth":2},{"title":"Next steps","local":"next-steps","sections":[],"depth":2}],"depth":1}';function fs(J){return ls(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Js extends as{constructor(i){super(),ns(this,i,fs,hs,ss,{})}}export{Js as component};
