import{s as Zs,o as vs,n as Qt}from"../chunks/scheduler.8c3d61f6.js";import{S as Ws,i as ks,g as i,s as l,r as f,A as xs,h as p,f as s,c as n,j as Lt,u as c,x as o,k as At,y as Ce,a,v as u,d,t as h,w as m}from"../chunks/index.da70eac4.js";import{T as zt}from"../chunks/Tip.1d9b8c37.js";import{D as Bs}from"../chunks/Docstring.567bc132.js";import{C as w}from"../chunks/CodeBlock.a9c4becf.js";import{D as Gs}from"../chunks/DocNotebookDropdown.48852948.js";import{H as xe,E as Xs}from"../chunks/index.5d4ab994.js";function qs(b){let r,g="By default, if the most up-to-date versions of PEFT and Transformers are detected, <code>low_cpu_mem_usage</code> is set to <code>True</code> to speed up the loading time of LoRA checkpoints.";return{c(){r=i("p"),r.innerHTML=g},l(M){r=p(M,"P",{"data-svelte-h":!0}),o(r)!=="svelte-1d53kjc"&&(r.innerHTML=g)},m(M,J){a(M,r,J)},p:Qt,d(M){M&&s(r)}}}function Rs(b){let r,g='LoRA checkpoints in the diffusion community are almost always obtained with <a href="https://huggingface.co/docs/diffusers/main/en/training/dreambooth" rel="nofollow">DreamBooth</a>. DreamBooth training often relies on ‚Äútrigger‚Äù words in the input text prompts in order for the generation results to look as expected. When you combine multiple LoRA checkpoints, it‚Äôs important to ensure the trigger words for the corresponding LoRA checkpoints are present in the input text prompts.';return{c(){r=i("p"),r.innerHTML=g},l(M){r=p(M,"P",{"data-svelte-h":!0}),o(r)!=="svelte-1efkoll"&&(r.innerHTML=g)},m(M,J){a(M,r,J)},p:Qt,d(M){M&&s(r)}}}function Hs(b){let r,g='Through its PEFT integration, Diffusers also offers more efficient merging methods which you can learn about in the <a href="../using-diffusers/merge_loras">Merge LoRAs</a> guide!';return{c(){r=i("p"),r.innerHTML=g},l(M){r=p(M,"P",{"data-svelte-h":!0}),o(r)!=="svelte-11f9n2w"&&(r.innerHTML=g)},m(M,J){a(M,r,J)},p:Qt,d(M){M&&s(r)}}}function Vs(b){let r,g,M,J,$,Be,I,Ge,C,Ft='There are many adapter types (with <a href="https://huggingface.co/docs/peft/conceptual_guides/adapter#low-rank-adaptation-lora" rel="nofollow">LoRAs</a> being the most popular) trained in different styles to achieve different effects. You can even combine multiple adapters to create new and unique images.',Xe,Z,St='In this tutorial, you‚Äôll learn how to easily load and manage adapters for inference with the ü§ó <a href="https://huggingface.co/docs/peft/index" rel="nofollow">PEFT</a> integration in ü§ó Diffusers. You‚Äôll use LoRA as the main adapter technique, so you‚Äôll see the terms LoRA and adapter used interchangeably.',qe,v,Et="Let‚Äôs first install all the required libraries.",Re,W,He,k,Pt='Now, load a pipeline with a <a href="../api/pipelines/stable_diffusion/stable_diffusion_xl">Stable Diffusion XL (SDXL)</a> checkpoint:',Ve,x,Ye,B,Dt='Next, load a <a href="https://huggingface.co/CiroN2022/toy-face" rel="nofollow">CiroN2022/toy-face</a> adapter with the <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.StableDiffusionXLLoraLoaderMixin.load_lora_weights">load_lora_weights()</a> method. With the ü§ó PEFT integration, you can assign a specific <code>adapter_name</code> to the checkpoint, which lets you easily switch between different LoRA checkpoints. Let‚Äôs call this adapter <code>&quot;toy&quot;</code>.',Ne,G,Le,X,Kt="Make sure to include the token <code>toy_face</code> in the prompt and then you can perform inference:",Ae,q,ze,R,Ot='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_8_1.png" alt="toy-face"/>',Qe,H,es='With the <code>adapter_name</code> parameter, it is really easy to use another adapter for inference! Load the <a href="https://huggingface.co/nerijs/pixel-art-xl" rel="nofollow">nerijs/pixel-art-xl</a> adapter that has been fine-tuned to generate pixel art images and call it <code>&quot;pixel&quot;</code>.',Fe,V,ts='The pipeline automatically sets the first loaded adapter (<code>&quot;toy&quot;</code>) as the active adapter, but you can activate the <code>&quot;pixel&quot;</code> adapter with the <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a> method:',Se,Y,Ee,N,ss="Make sure you include the token <code>pixel art</code> in your prompt to generate a pixel art image:",Pe,L,De,A,as='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_12_1.png" alt="pixel-art"/>',Ke,j,Oe,z,et,Q,ls="You can also merge different adapter checkpoints for inference to blend their styles together.",tt,F,ns='Once again, use the <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a> method to activate the <code>pixel</code> and <code>toy</code> adapters and specify the weights for how they should be merged.',st,S,at,_,lt,E,is='Remember to use the trigger words for <a href="https://hf.co/CiroN2022/toy-face" rel="nofollow">CiroN2022/toy-face</a> and <a href="https://hf.co/nerijs/pixel-art-xl" rel="nofollow">nerijs/pixel-art-xl</a> (these are found in their repositories) in the prompt to generate an image.',nt,P,it,D,ps='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_16_1.png" alt="toy-face-pixel-art"/>',pt,K,os="Impressive! As you can see, the model generated an image that mixed the characteristics of both adapters.",ot,U,rt,O,rs='To return to only using one adapter, use the <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a> method to activate the <code>&quot;toy&quot;</code> adapter:',ft,ee,ct,te,fs='Or to disable all adapters entirely, use the <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.disable_lora">disable_lora()</a> method to return the base model.',ut,se,dt,ae,cs='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_20_1.png" alt="no-lora"/>',ht,le,mt,ne,us='For even more customization, you can control how strongly the adapter affects each part of the pipeline. For this, pass a dictionary with the control strengths (called ‚Äúscales‚Äù) to <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.set_adapters">set_adapters()</a>.',Mt,ie,ds="For example, here‚Äôs how you can turn on the adapter for the <code>down</code> parts, but turn it off for the <code>mid</code> and <code>up</code> parts:",wt,pe,gt,oe,hs='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_block_down.png" alt="block-lora-text-and-down"/>',yt,re,ms="Let‚Äôs see how turning off the <code>down</code> part and turning on the <code>mid</code> and <code>up</code> part respectively changes the image.",Tt,fe,Jt,ce,Ms='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_block_mid.png" alt="block-lora-text-and-mid"/>',bt,ue,jt,de,ws='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_block_up.png" alt="block-lora-text-and-up"/>',_t,he,gs="Looks cool!",Ut,me,ys="This is a really powerful feature. You can use it to control the adapter strengths down to per-transformer level. And you can even use it for multiple adapters.",$t,Me,It,we,Ts='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/peft_integration/diffusers_peft_lora_inference_block_mixed.png" alt="block-lora-mixed"/>',Ct,ge,Zt,ye,Js='You have attached multiple adapters in this tutorial, and if you‚Äôre feeling a bit lost on what adapters have been attached to the pipeline‚Äôs components, use the <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.get_active_adapters">get_active_adapters()</a> method to check the list of active adapters:',vt,Te,Wt,Je,bs='You can also get the active adapters of each pipeline component with <a href="/docs/diffusers/v0.33.1/en/api/loaders/lora#diffusers.loaders.lora_base.LoraBaseMixin.get_list_adapters">get_list_adapters()</a>:',kt,be,xt,je,js='The <a href="/docs/diffusers/v0.33.1/en/api/loaders/peft#diffusers.loaders.PeftAdapterMixin.delete_adapters">delete_adapters()</a> function completely removes an adapter and their LoRA layers from a model.',Bt,_e,Gt,Ue,Xt,y,$e,Vt,Ze,_s=`A hook that disables the casting of inputs to the module weight dtype during the forward pass. By default, PEFT
casts the inputs to the weight dtype of the module, which can lead to precision loss.`,Yt,ve,Us="The reasons for needing this are:",Nt,We,$s=`<li>If we don‚Äôt add PEFT layers‚Äô weight names to <code>skip_modules_pattern</code> when applying layerwise casting, the
inputs will be casted to the, possibly lower precision, storage dtype. Reference:
<a href="https://github.com/huggingface/peft/blob/0facdebf6208139cbd8f3586875acb378813dd97/src/peft/tuners/lora/layer.py#L706" rel="nofollow">https://github.com/huggingface/peft/blob/0facdebf6208139cbd8f3586875acb378813dd97/src/peft/tuners/lora/layer.py#L706</a></li> <li>We can, on our end, use something like accelerate‚Äôs <code>send_to_device</code> but for dtypes. This way, we can ensure
that the inputs are casted to the computation dtype correctly always. However, there are two goals we are
hoping to achieve:<ol><li>Making forward implementations independent of device/dtype casting operations as much as possible.</li> <li>Peforming inference without losing information from casting to different precisions. With the current
PEFT implementation (as linked in the reference above), and assuming running layerwise casting inference
with storage_dtype=torch.float8_e4m3fn and compute_dtype=torch.bfloat16, inputs are cast to
torch.float8_e4m3fn in the lora layer. We will then upcast back to torch.bfloat16 when we continue the
forward pass in PEFT linear forward or Diffusers layer forward, with a <code>send_to_dtype</code> operation from
LayerwiseCastingHook. This will be a lossy operation and result in poorer generation quality.</li></ol></li>`,qt,Ie,Rt,ke,Ht;return $=new Gs({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/using_peft_for_inference.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/using_peft_for_inference.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/tensorflow/using_peft_for_inference.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/using_peft_for_inference.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/using_peft_for_inference.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/diffusers_doc/en/tensorflow/using_peft_for_inference.ipynb"}]}}),I=new xe({props:{title:"Load LoRAs for inference",local:"load-loras-for-inference",headingTag:"h1"}}),W=new w({props:{code:"IXBpcCUyMGluc3RhbGwlMjAtcSUyMHRyYW5zZm9ybWVycyUyMGFjY2VsZXJhdGUlMjBwZWZ0JTIwZGlmZnVzZXJz",highlighted:"!pip install -q transformers accelerate peft diffusers",wrap:!1}}),x=new w({props:{code:"ZnJvbSUyMGRpZmZ1c2VycyUyMGltcG9ydCUyMERpZmZ1c2lvblBpcGVsaW5lJTBBaW1wb3J0JTIwdG9yY2glMEElMEFwaXBlX2lkJTIwJTNEJTIwJTIyc3RhYmlsaXR5YWklMkZzdGFibGUtZGlmZnVzaW9uLXhsLWJhc2UtMS4wJTIyJTBBcGlwZSUyMCUzRCUyMERpZmZ1c2lvblBpcGVsaW5lLmZyb21fcHJldHJhaW5lZChwaXBlX2lkJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2KS50byglMjJjdWRhJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline
<span class="hljs-keyword">import</span> torch

pipe_id = <span class="hljs-string">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span>
pipe = DiffusionPipeline.from_pretrained(pipe_id, torch_dtype=torch.float16).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),G=new w({props:{code:"cGlwZS5sb2FkX2xvcmFfd2VpZ2h0cyglMjJDaXJvTjIwMjIlMkZ0b3ktZmFjZSUyMiUyQyUyMHdlaWdodF9uYW1lJTNEJTIydG95X2ZhY2Vfc2R4bC5zYWZldGVuc29ycyUyMiUyQyUyMGFkYXB0ZXJfbmFtZSUzRCUyMnRveSUyMik=",highlighted:'pipe.load_lora_weights(<span class="hljs-string">&quot;CiroN2022/toy-face&quot;</span>, weight_name=<span class="hljs-string">&quot;toy_face_sdxl.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;toy&quot;</span>)',wrap:!1}}),q=new w({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIydG95X2ZhY2UlMjBvZiUyMGElMjBoYWNrZXIlMjB3aXRoJTIwYSUyMGhvb2RpZSUyMiUwQSUwQWxvcmFfc2NhbGUlMjAlM0QlMjAwLjklMEFpbWFnZSUyMCUzRCUyMHBpcGUoJTBBJTIwJTIwJTIwJTIwcHJvbXB0JTJDJTIwbnVtX2luZmVyZW5jZV9zdGVwcyUzRDMwJTJDJTIwY3Jvc3NfYXR0ZW50aW9uX2t3YXJncyUzRCU3QiUyMnNjYWxlJTIyJTNBJTIwbG9yYV9zY2FsZSU3RCUyQyUyMGdlbmVyYXRvciUzRHRvcmNoLm1hbnVhbF9zZWVkKDApJTBBKS5pbWFnZXMlNUIwJTVEJTBBaW1hZ2U=",highlighted:`prompt = <span class="hljs-string">&quot;toy_face of a hacker with a hoodie&quot;</span>

lora_scale = <span class="hljs-number">0.9</span>
image = pipe(
    prompt, num_inference_steps=<span class="hljs-number">30</span>, cross_attention_kwargs={<span class="hljs-string">&quot;scale&quot;</span>: lora_scale}, generator=torch.manual_seed(<span class="hljs-number">0</span>)
).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),Y=new w({props:{code:"cGlwZS5sb2FkX2xvcmFfd2VpZ2h0cyglMjJuZXJpanMlMkZwaXhlbC1hcnQteGwlMjIlMkMlMjB3ZWlnaHRfbmFtZSUzRCUyMnBpeGVsLWFydC14bC5zYWZldGVuc29ycyUyMiUyQyUyMGFkYXB0ZXJfbmFtZSUzRCUyMnBpeGVsJTIyKSUwQXBpcGUuc2V0X2FkYXB0ZXJzKCUyMnBpeGVsJTIyKQ==",highlighted:`pipe.load_lora_weights(<span class="hljs-string">&quot;nerijs/pixel-art-xl&quot;</span>, weight_name=<span class="hljs-string">&quot;pixel-art-xl.safetensors&quot;</span>, adapter_name=<span class="hljs-string">&quot;pixel&quot;</span>)
pipe.set_adapters(<span class="hljs-string">&quot;pixel&quot;</span>)`,wrap:!1}}),L=new w({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyYSUyMGhhY2tlciUyMHdpdGglMjBhJTIwaG9vZGllJTJDJTIwcGl4ZWwlMjBhcnQlMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGUoJTBBJTIwJTIwJTIwJTIwcHJvbXB0JTJDJTIwbnVtX2luZmVyZW5jZV9zdGVwcyUzRDMwJTJDJTIwY3Jvc3NfYXR0ZW50aW9uX2t3YXJncyUzRCU3QiUyMnNjYWxlJTIyJTNBJTIwbG9yYV9zY2FsZSU3RCUyQyUyMGdlbmVyYXRvciUzRHRvcmNoLm1hbnVhbF9zZWVkKDApJTBBKS5pbWFnZXMlNUIwJTVEJTBBaW1hZ2U=",highlighted:`prompt = <span class="hljs-string">&quot;a hacker with a hoodie, pixel art&quot;</span>
image = pipe(
    prompt, num_inference_steps=<span class="hljs-number">30</span>, cross_attention_kwargs={<span class="hljs-string">&quot;scale&quot;</span>: lora_scale}, generator=torch.manual_seed(<span class="hljs-number">0</span>)
).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),j=new zt({props:{$$slots:{default:[qs]},$$scope:{ctx:b}}}),z=new xe({props:{title:"Merge adapters",local:"merge-adapters",headingTag:"h2"}}),S=new w({props:{code:"cGlwZS5zZXRfYWRhcHRlcnMoJTVCJTIycGl4ZWwlMjIlMkMlMjAlMjJ0b3klMjIlNUQlMkMlMjBhZGFwdGVyX3dlaWdodHMlM0QlNUIwLjUlMkMlMjAxLjAlNUQp",highlighted:'pipe.set_adapters([<span class="hljs-string">&quot;pixel&quot;</span>, <span class="hljs-string">&quot;toy&quot;</span>], adapter_weights=[<span class="hljs-number">0.5</span>, <span class="hljs-number">1.0</span>])',wrap:!1}}),_=new zt({props:{$$slots:{default:[Rs]},$$scope:{ctx:b}}}),P=new w({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIydG95X2ZhY2UlMjBvZiUyMGElMjBoYWNrZXIlMjB3aXRoJTIwYSUyMGhvb2RpZSUyQyUyMHBpeGVsJTIwYXJ0JTIyJTBBaW1hZ2UlMjAlM0QlMjBwaXBlKCUwQSUyMCUyMCUyMCUyMHByb21wdCUyQyUyMG51bV9pbmZlcmVuY2Vfc3RlcHMlM0QzMCUyQyUyMGNyb3NzX2F0dGVudGlvbl9rd2FyZ3MlM0QlN0IlMjJzY2FsZSUyMiUzQSUyMDEuMCU3RCUyQyUyMGdlbmVyYXRvciUzRHRvcmNoLm1hbnVhbF9zZWVkKDApJTBBKS5pbWFnZXMlNUIwJTVEJTBBaW1hZ2U=",highlighted:`prompt = <span class="hljs-string">&quot;toy_face of a hacker with a hoodie, pixel art&quot;</span>
image = pipe(
    prompt, num_inference_steps=<span class="hljs-number">30</span>, cross_attention_kwargs={<span class="hljs-string">&quot;scale&quot;</span>: <span class="hljs-number">1.0</span>}, generator=torch.manual_seed(<span class="hljs-number">0</span>)
).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),U=new zt({props:{warning:!1,$$slots:{default:[Hs]},$$scope:{ctx:b}}}),ee=new w({props:{code:"cGlwZS5zZXRfYWRhcHRlcnMoJTIydG95JTIyKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMnRveV9mYWNlJTIwb2YlMjBhJTIwaGFja2VyJTIwd2l0aCUyMGElMjBob29kaWUlMjIlMEFsb3JhX3NjYWxlJTIwJTNEJTIwMC45JTBBaW1hZ2UlMjAlM0QlMjBwaXBlKCUwQSUyMCUyMCUyMCUyMHByb21wdCUyQyUyMG51bV9pbmZlcmVuY2Vfc3RlcHMlM0QzMCUyQyUyMGNyb3NzX2F0dGVudGlvbl9rd2FyZ3MlM0QlN0IlMjJzY2FsZSUyMiUzQSUyMGxvcmFfc2NhbGUlN0QlMkMlMjBnZW5lcmF0b3IlM0R0b3JjaC5tYW51YWxfc2VlZCgwKSUwQSkuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`pipe.set_adapters(<span class="hljs-string">&quot;toy&quot;</span>)

prompt = <span class="hljs-string">&quot;toy_face of a hacker with a hoodie&quot;</span>
lora_scale = <span class="hljs-number">0.9</span>
image = pipe(
    prompt, num_inference_steps=<span class="hljs-number">30</span>, cross_attention_kwargs={<span class="hljs-string">&quot;scale&quot;</span>: lora_scale}, generator=torch.manual_seed(<span class="hljs-number">0</span>)
).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),se=new w({props:{code:"cGlwZS5kaXNhYmxlX2xvcmEoKSUwQSUwQXByb21wdCUyMCUzRCUyMCUyMnRveV9mYWNlJTIwb2YlMjBhJTIwaGFja2VyJTIwd2l0aCUyMGElMjBob29kaWUlMjIlMEFpbWFnZSUyMCUzRCUyMHBpcGUocHJvbXB0JTJDJTIwbnVtX2luZmVyZW5jZV9zdGVwcyUzRDMwJTJDJTIwZ2VuZXJhdG9yJTNEdG9yY2gubWFudWFsX3NlZWQoMCkpLmltYWdlcyU1QjAlNUQlMEFpbWFnZQ==",highlighted:`pipe.disable_lora()

prompt = <span class="hljs-string">&quot;toy_face of a hacker with a hoodie&quot;</span>
image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),le=new xe({props:{title:"Customize adapters strength",local:"customize-adapters-strength",headingTag:"h3"}}),pe=new w({props:{code:"cGlwZS5lbmFibGVfbG9yYSgpJTIwJTIwJTIzJTIwZW5hYmxlJTIwbG9yYSUyMGFnYWluJTJDJTIwYWZ0ZXIlMjB3ZSUyMGRpc2FibGVkJTIwaXQlMjBhYm92ZSUwQXByb21wdCUyMCUzRCUyMCUyMnRveV9mYWNlJTIwb2YlMjBhJTIwaGFja2VyJTIwd2l0aCUyMGElMjBob29kaWUlMkMlMjBwaXhlbCUyMGFydCUyMiUwQWFkYXB0ZXJfd2VpZ2h0X3NjYWxlcyUyMCUzRCUyMCU3QiUyMCUyMnVuZXQlMjIlM0ElMjAlN0IlMjAlMjJkb3duJTIyJTNBJTIwMSUyQyUyMCUyMm1pZCUyMiUzQSUyMDAlMkMlMjAlMjJ1cCUyMiUzQSUyMDAlN0QlMjAlN0QlMEFwaXBlLnNldF9hZGFwdGVycyglMjJwaXhlbCUyMiUyQyUyMGFkYXB0ZXJfd2VpZ2h0X3NjYWxlcyklMEFpbWFnZSUyMCUzRCUyMHBpcGUocHJvbXB0JTJDJTIwbnVtX2luZmVyZW5jZV9zdGVwcyUzRDMwJTJDJTIwZ2VuZXJhdG9yJTNEdG9yY2gubWFudWFsX3NlZWQoMCkpLmltYWdlcyU1QjAlNUQlMEFpbWFnZQ==",highlighted:`pipe.enable_lora()  <span class="hljs-comment"># enable lora again, after we disabled it above</span>
prompt = <span class="hljs-string">&quot;toy_face of a hacker with a hoodie, pixel art&quot;</span>
adapter_weight_scales = { <span class="hljs-string">&quot;unet&quot;</span>: { <span class="hljs-string">&quot;down&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;mid&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;up&quot;</span>: <span class="hljs-number">0</span>} }
pipe.set_adapters(<span class="hljs-string">&quot;pixel&quot;</span>, adapter_weight_scales)
image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),fe=new w({props:{code:"YWRhcHRlcl93ZWlnaHRfc2NhbGVzJTIwJTNEJTIwJTdCJTIwJTIydW5ldCUyMiUzQSUyMCU3QiUyMCUyMmRvd24lMjIlM0ElMjAwJTJDJTIwJTIybWlkJTIyJTNBJTIwMSUyQyUyMCUyMnVwJTIyJTNBJTIwMCU3RCUyMCU3RCUwQXBpcGUuc2V0X2FkYXB0ZXJzKCUyMnBpeGVsJTIyJTJDJTIwYWRhcHRlcl93ZWlnaHRfc2NhbGVzKSUwQWltYWdlJTIwJTNEJTIwcGlwZShwcm9tcHQlMkMlMjBudW1faW5mZXJlbmNlX3N0ZXBzJTNEMzAlMkMlMjBnZW5lcmF0b3IlM0R0b3JjaC5tYW51YWxfc2VlZCgwKSkuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`adapter_weight_scales = { <span class="hljs-string">&quot;unet&quot;</span>: { <span class="hljs-string">&quot;down&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;mid&quot;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&quot;up&quot;</span>: <span class="hljs-number">0</span>} }
pipe.set_adapters(<span class="hljs-string">&quot;pixel&quot;</span>, adapter_weight_scales)
image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),ue=new w({props:{code:"YWRhcHRlcl93ZWlnaHRfc2NhbGVzJTIwJTNEJTIwJTdCJTIwJTIydW5ldCUyMiUzQSUyMCU3QiUyMCUyMmRvd24lMjIlM0ElMjAwJTJDJTIwJTIybWlkJTIyJTNBJTIwMCUyQyUyMCUyMnVwJTIyJTNBJTIwMSU3RCUyMCU3RCUwQXBpcGUuc2V0X2FkYXB0ZXJzKCUyMnBpeGVsJTIyJTJDJTIwYWRhcHRlcl93ZWlnaHRfc2NhbGVzKSUwQWltYWdlJTIwJTNEJTIwcGlwZShwcm9tcHQlMkMlMjBudW1faW5mZXJlbmNlX3N0ZXBzJTNEMzAlMkMlMjBnZW5lcmF0b3IlM0R0b3JjaC5tYW51YWxfc2VlZCgwKSkuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`adapter_weight_scales = { <span class="hljs-string">&quot;unet&quot;</span>: { <span class="hljs-string">&quot;down&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;mid&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;up&quot;</span>: <span class="hljs-number">1</span>} }
pipe.set_adapters(<span class="hljs-string">&quot;pixel&quot;</span>, adapter_weight_scales)
image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),Me=new w({props:{code:"YWRhcHRlcl93ZWlnaHRfc2NhbGVzX3RveSUyMCUzRCUyMDAuNSUwQWFkYXB0ZXJfd2VpZ2h0X3NjYWxlc19waXhlbCUyMCUzRCUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMnVuZXQlMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJkb3duJTIyJTNBJTIwMC45JTJDJTIwJTIwJTIzJTIwYWxsJTIwdHJhbnNmb3JtZXJzJTIwaW4lMjB0aGUlMjBkb3duLXBhcnQlMjB3aWxsJTIwdXNlJTIwc2NhbGUlMjAwLjklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjMlMjAlMjJtaWQlMjIlMjAlMjAlMjMlMjBiZWNhdXNlJTJDJTIwaW4lMjB0aGlzJTIwZXhhbXBsZSUyQyUyMCUyMm1pZCUyMiUyMGlzJTIwbm90JTIwZ2l2ZW4lMkMlMjBhbGwlMjB0cmFuc2Zvcm1lcnMlMjBpbiUyMHRoZSUyMG1pZCUyMHBhcnQlMjB3aWxsJTIwdXNlJTIwdGhlJTIwZGVmYXVsdCUyMHNjYWxlJTIwMS4wJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIydXAlMjIlM0ElMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJibG9ja18wJTIyJTNBJTIwMC42JTJDJTIwJTIwJTIzJTIwYWxsJTIwMyUyMHRyYW5zZm9ybWVycyUyMGluJTIwdGhlJTIwMHRoJTIwYmxvY2slMjBpbiUyMHRoZSUyMHVwLXBhcnQlMjB3aWxsJTIwdXNlJTIwc2NhbGUlMjAwLjYlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJibG9ja18xJTIyJTNBJTIwJTVCMC40JTJDJTIwMC44JTJDJTIwMS4wJTVEJTJDJTIwJTIwJTIzJTIwdGhlJTIwMyUyMHRyYW5zZm9ybWVycyUyMGluJTIwdGhlJTIwMXN0JTIwYmxvY2slMjBpbiUyMHRoZSUyMHVwLXBhcnQlMjB3aWxsJTIwdXNlJTIwc2NhbGVzJTIwMC40JTJDJTIwMC44JTIwYW5kJTIwMS4wJTIwcmVzcGVjdGl2ZWx5JTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTdEJTBBJTIwJTIwJTIwJTIwJTdEJTBBJTdEJTBBcGlwZS5zZXRfYWRhcHRlcnMoJTVCJTIydG95JTIyJTJDJTIwJTIycGl4ZWwlMjIlNUQlMkMlMjAlNUJhZGFwdGVyX3dlaWdodF9zY2FsZXNfdG95JTJDJTIwYWRhcHRlcl93ZWlnaHRfc2NhbGVzX3BpeGVsJTVEKSUwQWltYWdlJTIwJTNEJTIwcGlwZShwcm9tcHQlMkMlMjBudW1faW5mZXJlbmNlX3N0ZXBzJTNEMzAlMkMlMjBnZW5lcmF0b3IlM0R0b3JjaC5tYW51YWxfc2VlZCgwKSkuaW1hZ2VzJTVCMCU1RCUwQWltYWdl",highlighted:`adapter_weight_scales_toy = <span class="hljs-number">0.5</span>
adapter_weight_scales_pixel = {
    <span class="hljs-string">&quot;unet&quot;</span>: {
        <span class="hljs-string">&quot;down&quot;</span>: <span class="hljs-number">0.9</span>,  <span class="hljs-comment"># all transformers in the down-part will use scale 0.9</span>
        <span class="hljs-comment"># &quot;mid&quot;  # because, in this example, &quot;mid&quot; is not given, all transformers in the mid part will use the default scale 1.0</span>
        <span class="hljs-string">&quot;up&quot;</span>: {
            <span class="hljs-string">&quot;block_0&quot;</span>: <span class="hljs-number">0.6</span>,  <span class="hljs-comment"># all 3 transformers in the 0th block in the up-part will use scale 0.6</span>
            <span class="hljs-string">&quot;block_1&quot;</span>: [<span class="hljs-number">0.4</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">1.0</span>],  <span class="hljs-comment"># the 3 transformers in the 1st block in the up-part will use scales 0.4, 0.8 and 1.0 respectively</span>
        }
    }
}
pipe.set_adapters([<span class="hljs-string">&quot;toy&quot;</span>, <span class="hljs-string">&quot;pixel&quot;</span>], [adapter_weight_scales_toy, adapter_weight_scales_pixel])
image = pipe(prompt, num_inference_steps=<span class="hljs-number">30</span>, generator=torch.manual_seed(<span class="hljs-number">0</span>)).images[<span class="hljs-number">0</span>]
image`,wrap:!1}}),ge=new xe({props:{title:"Manage adapters",local:"manage-adapters",headingTag:"h2"}}),Te=new w({props:{code:"YWN0aXZlX2FkYXB0ZXJzJTIwJTNEJTIwcGlwZS5nZXRfYWN0aXZlX2FkYXB0ZXJzKCklMEFhY3RpdmVfYWRhcHRlcnMlMEElNUIlMjJ0b3klMjIlMkMlMjAlMjJwaXhlbCUyMiU1RA==",highlighted:`active_adapters = pipe.get_active_adapters()
active_adapters
[<span class="hljs-string">&quot;toy&quot;</span>, <span class="hljs-string">&quot;pixel&quot;</span>]`,wrap:!1}}),be=new w({props:{code:"bGlzdF9hZGFwdGVyc19jb21wb25lbnRfd2lzZSUyMCUzRCUyMHBpcGUuZ2V0X2xpc3RfYWRhcHRlcnMoKSUwQWxpc3RfYWRhcHRlcnNfY29tcG9uZW50X3dpc2UlMEElN0IlMjJ0ZXh0X2VuY29kZXIlMjIlM0ElMjAlNUIlMjJ0b3klMjIlMkMlMjAlMjJwaXhlbCUyMiU1RCUyQyUyMCUyMnVuZXQlMjIlM0ElMjAlNUIlMjJ0b3klMjIlMkMlMjAlMjJwaXhlbCUyMiU1RCUyQyUyMCUyMnRleHRfZW5jb2Rlcl8yJTIyJTNBJTIwJTVCJTIydG95JTIyJTJDJTIwJTIycGl4ZWwlMjIlNUQlN0Q=",highlighted:`list_adapters_component_wise = pipe.get_list_adapters()
list_adapters_component_wise
{<span class="hljs-string">&quot;text_encoder&quot;</span>: [<span class="hljs-string">&quot;toy&quot;</span>, <span class="hljs-string">&quot;pixel&quot;</span>], <span class="hljs-string">&quot;unet&quot;</span>: [<span class="hljs-string">&quot;toy&quot;</span>, <span class="hljs-string">&quot;pixel&quot;</span>], <span class="hljs-string">&quot;text_encoder_2&quot;</span>: [<span class="hljs-string">&quot;toy&quot;</span>, <span class="hljs-string">&quot;pixel&quot;</span>]}`,wrap:!1}}),_e=new w({props:{code:"cGlwZS5kZWxldGVfYWRhcHRlcnMoJTIydG95JTIyKSUwQXBpcGUuZ2V0X2FjdGl2ZV9hZGFwdGVycygpJTBBJTVCJTIycGl4ZWwlMjIlNUQ=",highlighted:`pipe.delete_adapters(<span class="hljs-string">&quot;toy&quot;</span>)
pipe.get_active_adapters()
[<span class="hljs-string">&quot;pixel&quot;</span>]`,wrap:!1}}),Ue=new xe({props:{title:"PeftInputAutocastDisableHook",local:"diffusers.hooks.layerwise_casting.PeftInputAutocastDisableHook",headingTag:"h2"}}),$e=new Bs({props:{name:"class diffusers.hooks.layerwise_casting.PeftInputAutocastDisableHook",anchor:"diffusers.hooks.layerwise_casting.PeftInputAutocastDisableHook",parameters:[],source:"https://github.com/huggingface/diffusers/blob/v0.33.1/src/diffusers/hooks/layerwise_casting.py#L80"}}),Ie=new Xs({props:{source:"https://github.com/huggingface/diffusers/blob/main/docs/source/en/tutorials/using_peft_for_inference.md"}}),{c(){r=i("meta"),g=l(),M=i("p"),J=l(),f($.$$.fragment),Be=l(),f(I.$$.fragment),Ge=l(),C=i("p"),C.innerHTML=Ft,Xe=l(),Z=i("p"),Z.innerHTML=St,qe=l(),v=i("p"),v.textContent=Et,Re=l(),f(W.$$.fragment),He=l(),k=i("p"),k.innerHTML=Pt,Ve=l(),f(x.$$.fragment),Ye=l(),B=i("p"),B.innerHTML=Dt,Ne=l(),f(G.$$.fragment),Le=l(),X=i("p"),X.innerHTML=Kt,Ae=l(),f(q.$$.fragment),ze=l(),R=i("p"),R.innerHTML=Ot,Qe=l(),H=i("p"),H.innerHTML=es,Fe=l(),V=i("p"),V.innerHTML=ts,Se=l(),f(Y.$$.fragment),Ee=l(),N=i("p"),N.innerHTML=ss,Pe=l(),f(L.$$.fragment),De=l(),A=i("p"),A.innerHTML=as,Ke=l(),f(j.$$.fragment),Oe=l(),f(z.$$.fragment),et=l(),Q=i("p"),Q.textContent=ls,tt=l(),F=i("p"),F.innerHTML=ns,st=l(),f(S.$$.fragment),at=l(),f(_.$$.fragment),lt=l(),E=i("p"),E.innerHTML=is,nt=l(),f(P.$$.fragment),it=l(),D=i("p"),D.innerHTML=ps,pt=l(),K=i("p"),K.textContent=os,ot=l(),f(U.$$.fragment),rt=l(),O=i("p"),O.innerHTML=rs,ft=l(),f(ee.$$.fragment),ct=l(),te=i("p"),te.innerHTML=fs,ut=l(),f(se.$$.fragment),dt=l(),ae=i("p"),ae.innerHTML=cs,ht=l(),f(le.$$.fragment),mt=l(),ne=i("p"),ne.innerHTML=us,Mt=l(),ie=i("p"),ie.innerHTML=ds,wt=l(),f(pe.$$.fragment),gt=l(),oe=i("p"),oe.innerHTML=hs,yt=l(),re=i("p"),re.innerHTML=ms,Tt=l(),f(fe.$$.fragment),Jt=l(),ce=i("p"),ce.innerHTML=Ms,bt=l(),f(ue.$$.fragment),jt=l(),de=i("p"),de.innerHTML=ws,_t=l(),he=i("p"),he.textContent=gs,Ut=l(),me=i("p"),me.textContent=ys,$t=l(),f(Me.$$.fragment),It=l(),we=i("p"),we.innerHTML=Ts,Ct=l(),f(ge.$$.fragment),Zt=l(),ye=i("p"),ye.innerHTML=Js,vt=l(),f(Te.$$.fragment),Wt=l(),Je=i("p"),Je.innerHTML=bs,kt=l(),f(be.$$.fragment),xt=l(),je=i("p"),je.innerHTML=js,Bt=l(),f(_e.$$.fragment),Gt=l(),f(Ue.$$.fragment),Xt=l(),y=i("div"),f($e.$$.fragment),Vt=l(),Ze=i("p"),Ze.textContent=_s,Yt=l(),ve=i("p"),ve.textContent=Us,Nt=l(),We=i("ul"),We.innerHTML=$s,qt=l(),f(Ie.$$.fragment),Rt=l(),ke=i("p"),this.h()},l(e){const t=xs("svelte-u9bgzb",document.head);r=p(t,"META",{name:!0,content:!0}),t.forEach(s),g=n(e),M=p(e,"P",{}),Lt(M).forEach(s),J=n(e),c($.$$.fragment,e),Be=n(e),c(I.$$.fragment,e),Ge=n(e),C=p(e,"P",{"data-svelte-h":!0}),o(C)!=="svelte-16bta26"&&(C.innerHTML=Ft),Xe=n(e),Z=p(e,"P",{"data-svelte-h":!0}),o(Z)!=="svelte-1ieiu2"&&(Z.innerHTML=St),qe=n(e),v=p(e,"P",{"data-svelte-h":!0}),o(v)!=="svelte-k7bd5g"&&(v.textContent=Et),Re=n(e),c(W.$$.fragment,e),He=n(e),k=p(e,"P",{"data-svelte-h":!0}),o(k)!=="svelte-1tmqr11"&&(k.innerHTML=Pt),Ve=n(e),c(x.$$.fragment,e),Ye=n(e),B=p(e,"P",{"data-svelte-h":!0}),o(B)!=="svelte-86ku09"&&(B.innerHTML=Dt),Ne=n(e),c(G.$$.fragment,e),Le=n(e),X=p(e,"P",{"data-svelte-h":!0}),o(X)!=="svelte-edxce6"&&(X.innerHTML=Kt),Ae=n(e),c(q.$$.fragment,e),ze=n(e),R=p(e,"P",{"data-svelte-h":!0}),o(R)!=="svelte-pa1jxn"&&(R.innerHTML=Ot),Qe=n(e),H=p(e,"P",{"data-svelte-h":!0}),o(H)!=="svelte-yg68i8"&&(H.innerHTML=es),Fe=n(e),V=p(e,"P",{"data-svelte-h":!0}),o(V)!=="svelte-1y9t1k7"&&(V.innerHTML=ts),Se=n(e),c(Y.$$.fragment,e),Ee=n(e),N=p(e,"P",{"data-svelte-h":!0}),o(N)!=="svelte-ardgqv"&&(N.innerHTML=ss),Pe=n(e),c(L.$$.fragment,e),De=n(e),A=p(e,"P",{"data-svelte-h":!0}),o(A)!=="svelte-1ixqz7s"&&(A.innerHTML=as),Ke=n(e),c(j.$$.fragment,e),Oe=n(e),c(z.$$.fragment,e),et=n(e),Q=p(e,"P",{"data-svelte-h":!0}),o(Q)!=="svelte-upv9sj"&&(Q.textContent=ls),tt=n(e),F=p(e,"P",{"data-svelte-h":!0}),o(F)!=="svelte-1moeqw2"&&(F.innerHTML=ns),st=n(e),c(S.$$.fragment,e),at=n(e),c(_.$$.fragment,e),lt=n(e),E=p(e,"P",{"data-svelte-h":!0}),o(E)!=="svelte-1rn1ec0"&&(E.innerHTML=is),nt=n(e),c(P.$$.fragment,e),it=n(e),D=p(e,"P",{"data-svelte-h":!0}),o(D)!=="svelte-azw8sd"&&(D.innerHTML=ps),pt=n(e),K=p(e,"P",{"data-svelte-h":!0}),o(K)!=="svelte-1vwq5xu"&&(K.textContent=os),ot=n(e),c(U.$$.fragment,e),rt=n(e),O=p(e,"P",{"data-svelte-h":!0}),o(O)!=="svelte-1ln1igg"&&(O.innerHTML=rs),ft=n(e),c(ee.$$.fragment,e),ct=n(e),te=p(e,"P",{"data-svelte-h":!0}),o(te)!=="svelte-1q2pon3"&&(te.innerHTML=fs),ut=n(e),c(se.$$.fragment,e),dt=n(e),ae=p(e,"P",{"data-svelte-h":!0}),o(ae)!=="svelte-if1nej"&&(ae.innerHTML=cs),ht=n(e),c(le.$$.fragment,e),mt=n(e),ne=p(e,"P",{"data-svelte-h":!0}),o(ne)!=="svelte-13sizak"&&(ne.innerHTML=us),Mt=n(e),ie=p(e,"P",{"data-svelte-h":!0}),o(ie)!=="svelte-1np0ppf"&&(ie.innerHTML=ds),wt=n(e),c(pe.$$.fragment,e),gt=n(e),oe=p(e,"P",{"data-svelte-h":!0}),o(oe)!=="svelte-124uws4"&&(oe.innerHTML=hs),yt=n(e),re=p(e,"P",{"data-svelte-h":!0}),o(re)!=="svelte-er7or2"&&(re.innerHTML=ms),Tt=n(e),c(fe.$$.fragment,e),Jt=n(e),ce=p(e,"P",{"data-svelte-h":!0}),o(ce)!=="svelte-2dcllg"&&(ce.innerHTML=Ms),bt=n(e),c(ue.$$.fragment,e),jt=n(e),de=p(e,"P",{"data-svelte-h":!0}),o(de)!=="svelte-1fp87nu"&&(de.innerHTML=ws),_t=n(e),he=p(e,"P",{"data-svelte-h":!0}),o(he)!=="svelte-1319h4o"&&(he.textContent=gs),Ut=n(e),me=p(e,"P",{"data-svelte-h":!0}),o(me)!=="svelte-1uxos2u"&&(me.textContent=ys),$t=n(e),c(Me.$$.fragment,e),It=n(e),we=p(e,"P",{"data-svelte-h":!0}),o(we)!=="svelte-16fuaxk"&&(we.innerHTML=Ts),Ct=n(e),c(ge.$$.fragment,e),Zt=n(e),ye=p(e,"P",{"data-svelte-h":!0}),o(ye)!=="svelte-fp67w7"&&(ye.innerHTML=Js),vt=n(e),c(Te.$$.fragment,e),Wt=n(e),Je=p(e,"P",{"data-svelte-h":!0}),o(Je)!=="svelte-1luca71"&&(Je.innerHTML=bs),kt=n(e),c(be.$$.fragment,e),xt=n(e),je=p(e,"P",{"data-svelte-h":!0}),o(je)!=="svelte-n5hc4a"&&(je.innerHTML=js),Bt=n(e),c(_e.$$.fragment,e),Gt=n(e),c(Ue.$$.fragment,e),Xt=n(e),y=p(e,"DIV",{class:!0});var T=Lt(y);c($e.$$.fragment,T),Vt=n(T),Ze=p(T,"P",{"data-svelte-h":!0}),o(Ze)!=="svelte-vivun0"&&(Ze.textContent=_s),Yt=n(T),ve=p(T,"P",{"data-svelte-h":!0}),o(ve)!=="svelte-70e5cx"&&(ve.textContent=Us),Nt=n(T),We=p(T,"UL",{"data-svelte-h":!0}),o(We)!=="svelte-lkxm3f"&&(We.innerHTML=$s),T.forEach(s),qt=n(e),c(Ie.$$.fragment,e),Rt=n(e),ke=p(e,"P",{}),Lt(ke).forEach(s),this.h()},h(){At(r,"name","hf:doc:metadata"),At(r,"content",Ys),At(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,t){Ce(document.head,r),a(e,g,t),a(e,M,t),a(e,J,t),u($,e,t),a(e,Be,t),u(I,e,t),a(e,Ge,t),a(e,C,t),a(e,Xe,t),a(e,Z,t),a(e,qe,t),a(e,v,t),a(e,Re,t),u(W,e,t),a(e,He,t),a(e,k,t),a(e,Ve,t),u(x,e,t),a(e,Ye,t),a(e,B,t),a(e,Ne,t),u(G,e,t),a(e,Le,t),a(e,X,t),a(e,Ae,t),u(q,e,t),a(e,ze,t),a(e,R,t),a(e,Qe,t),a(e,H,t),a(e,Fe,t),a(e,V,t),a(e,Se,t),u(Y,e,t),a(e,Ee,t),a(e,N,t),a(e,Pe,t),u(L,e,t),a(e,De,t),a(e,A,t),a(e,Ke,t),u(j,e,t),a(e,Oe,t),u(z,e,t),a(e,et,t),a(e,Q,t),a(e,tt,t),a(e,F,t),a(e,st,t),u(S,e,t),a(e,at,t),u(_,e,t),a(e,lt,t),a(e,E,t),a(e,nt,t),u(P,e,t),a(e,it,t),a(e,D,t),a(e,pt,t),a(e,K,t),a(e,ot,t),u(U,e,t),a(e,rt,t),a(e,O,t),a(e,ft,t),u(ee,e,t),a(e,ct,t),a(e,te,t),a(e,ut,t),u(se,e,t),a(e,dt,t),a(e,ae,t),a(e,ht,t),u(le,e,t),a(e,mt,t),a(e,ne,t),a(e,Mt,t),a(e,ie,t),a(e,wt,t),u(pe,e,t),a(e,gt,t),a(e,oe,t),a(e,yt,t),a(e,re,t),a(e,Tt,t),u(fe,e,t),a(e,Jt,t),a(e,ce,t),a(e,bt,t),u(ue,e,t),a(e,jt,t),a(e,de,t),a(e,_t,t),a(e,he,t),a(e,Ut,t),a(e,me,t),a(e,$t,t),u(Me,e,t),a(e,It,t),a(e,we,t),a(e,Ct,t),u(ge,e,t),a(e,Zt,t),a(e,ye,t),a(e,vt,t),u(Te,e,t),a(e,Wt,t),a(e,Je,t),a(e,kt,t),u(be,e,t),a(e,xt,t),a(e,je,t),a(e,Bt,t),u(_e,e,t),a(e,Gt,t),u(Ue,e,t),a(e,Xt,t),a(e,y,t),u($e,y,null),Ce(y,Vt),Ce(y,Ze),Ce(y,Yt),Ce(y,ve),Ce(y,Nt),Ce(y,We),a(e,qt,t),u(Ie,e,t),a(e,Rt,t),a(e,ke,t),Ht=!0},p(e,[t]){const T={};t&2&&(T.$$scope={dirty:t,ctx:e}),j.$set(T);const Is={};t&2&&(Is.$$scope={dirty:t,ctx:e}),_.$set(Is);const Cs={};t&2&&(Cs.$$scope={dirty:t,ctx:e}),U.$set(Cs)},i(e){Ht||(d($.$$.fragment,e),d(I.$$.fragment,e),d(W.$$.fragment,e),d(x.$$.fragment,e),d(G.$$.fragment,e),d(q.$$.fragment,e),d(Y.$$.fragment,e),d(L.$$.fragment,e),d(j.$$.fragment,e),d(z.$$.fragment,e),d(S.$$.fragment,e),d(_.$$.fragment,e),d(P.$$.fragment,e),d(U.$$.fragment,e),d(ee.$$.fragment,e),d(se.$$.fragment,e),d(le.$$.fragment,e),d(pe.$$.fragment,e),d(fe.$$.fragment,e),d(ue.$$.fragment,e),d(Me.$$.fragment,e),d(ge.$$.fragment,e),d(Te.$$.fragment,e),d(be.$$.fragment,e),d(_e.$$.fragment,e),d(Ue.$$.fragment,e),d($e.$$.fragment,e),d(Ie.$$.fragment,e),Ht=!0)},o(e){h($.$$.fragment,e),h(I.$$.fragment,e),h(W.$$.fragment,e),h(x.$$.fragment,e),h(G.$$.fragment,e),h(q.$$.fragment,e),h(Y.$$.fragment,e),h(L.$$.fragment,e),h(j.$$.fragment,e),h(z.$$.fragment,e),h(S.$$.fragment,e),h(_.$$.fragment,e),h(P.$$.fragment,e),h(U.$$.fragment,e),h(ee.$$.fragment,e),h(se.$$.fragment,e),h(le.$$.fragment,e),h(pe.$$.fragment,e),h(fe.$$.fragment,e),h(ue.$$.fragment,e),h(Me.$$.fragment,e),h(ge.$$.fragment,e),h(Te.$$.fragment,e),h(be.$$.fragment,e),h(_e.$$.fragment,e),h(Ue.$$.fragment,e),h($e.$$.fragment,e),h(Ie.$$.fragment,e),Ht=!1},d(e){e&&(s(g),s(M),s(J),s(Be),s(Ge),s(C),s(Xe),s(Z),s(qe),s(v),s(Re),s(He),s(k),s(Ve),s(Ye),s(B),s(Ne),s(Le),s(X),s(Ae),s(ze),s(R),s(Qe),s(H),s(Fe),s(V),s(Se),s(Ee),s(N),s(Pe),s(De),s(A),s(Ke),s(Oe),s(et),s(Q),s(tt),s(F),s(st),s(at),s(lt),s(E),s(nt),s(it),s(D),s(pt),s(K),s(ot),s(rt),s(O),s(ft),s(ct),s(te),s(ut),s(dt),s(ae),s(ht),s(mt),s(ne),s(Mt),s(ie),s(wt),s(gt),s(oe),s(yt),s(re),s(Tt),s(Jt),s(ce),s(bt),s(jt),s(de),s(_t),s(he),s(Ut),s(me),s($t),s(It),s(we),s(Ct),s(Zt),s(ye),s(vt),s(Wt),s(Je),s(kt),s(xt),s(je),s(Bt),s(Gt),s(Xt),s(y),s(qt),s(Rt),s(ke)),s(r),m($,e),m(I,e),m(W,e),m(x,e),m(G,e),m(q,e),m(Y,e),m(L,e),m(j,e),m(z,e),m(S,e),m(_,e),m(P,e),m(U,e),m(ee,e),m(se,e),m(le,e),m(pe,e),m(fe,e),m(ue,e),m(Me,e),m(ge,e),m(Te,e),m(be,e),m(_e,e),m(Ue,e),m($e),m(Ie,e)}}}const Ys='{"title":"Load LoRAs for inference","local":"load-loras-for-inference","sections":[{"title":"Merge adapters","local":"merge-adapters","sections":[{"title":"Customize adapters strength","local":"customize-adapters-strength","sections":[],"depth":3}],"depth":2},{"title":"Manage adapters","local":"manage-adapters","sections":[],"depth":2},{"title":"PeftInputAutocastDisableHook","local":"diffusers.hooks.layerwise_casting.PeftInputAutocastDisableHook","sections":[],"depth":2}],"depth":1}';function Ns(b){return vs(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ps extends Ws{constructor(r){super(),ks(this,r,Ns,Vs,Zs,{})}}export{Ps as component};
