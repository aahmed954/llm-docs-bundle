import{s as ss,o as as}from"../chunks/scheduler.d6170356.js";import{S as ls,i as ns,g as i,s as l,r as o,A as is,h as d,f as s,c as n,j as es,u as p,x as r,k as yt,y as ds,a,v as u,d as c,t as m,w as g,m as rs,n as os}from"../chunks/index.fcd4cc08.js";import{T as ps}from"../chunks/Tip.b09c67cf.js";import{C as vt}from"../chunks/CodeBlock.db16bf50.js";import{H as f,E as us}from"../chunks/index.9f2da87a.js";function cs(bt){let h;return{c(){h=rs("Longer-term, we would also like to expose non-GPU hardware, like HPU, IPU or TPU. If you have a specific AI hardware you'd like to run on, please let us know (website at huggingface.co).")},l($){h=os($,"Longer-term, we would also like to expose non-GPU hardware, like HPU, IPU or TPU. If you have a specific AI hardware you'd like to run on, please let us know (website at huggingface.co).")},m($,U){a($,h,U)},d($){$&&s(h)}}}function ms(bt){let h,$,U,Tt,x,Ut,C,Ue="You can upgrade your Space to use a GPU accelerator using the <em>Settings</em> button in the top navigation bar of the Space. You can even request a free upgrade if you are building a cool demo for a side project!",xt,y,xe='<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-gpu-settings.png"/> <img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-gpu-settings-dark.png"/>',Ct,v,Mt,M,Ce="As soon as your Space is running on GPU you can see which hardware it‚Äôs running on directly from this badge:",Gt,w,Me='<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-running-badge.png"/> <img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-running-badge-dark.png"/>',Pt,G,kt,P,Ge="In the following tables, you can see the Specs for the different upgrade options.",jt,k,Bt,j,Pe="<thead><tr><th><strong>Hardware</strong></th> <th><strong>CPU</strong></th> <th><strong>Memory</strong></th> <th><strong>GPU Memory</strong></th> <th><strong>Disk</strong></th> <th><strong>Hourly Price</strong></th></tr></thead> <tbody><tr><td>CPU Basic</td> <td>2 vCPU</td> <td>16 GB</td> <td>-</td> <td>50 GB</td> <td>Free!</td></tr> <tr><td>CPU Upgrade</td> <td>8 vCPU</td> <td>32 GB</td> <td>-</td> <td>50 GB</td> <td>$0.03</td></tr></tbody>",St,B,_t,S,ke="<thead><tr><th><strong>Hardware</strong></th> <th><strong>CPU</strong></th> <th><strong>Memory</strong></th> <th><strong>GPU Memory</strong></th> <th><strong>Disk</strong></th> <th><strong>Hourly Price</strong></th></tr></thead> <tbody><tr><td>Nvidia T4 - small</td> <td>4 vCPU</td> <td>15 GB</td> <td>16 GB</td> <td>50 GB</td> <td>$0.40</td></tr> <tr><td>Nvidia T4 - medium</td> <td>8 vCPU</td> <td>30 GB</td> <td>16 GB</td> <td>100 GB</td> <td>$0.60</td></tr> <tr><td>Nvidia A10G - small</td> <td>4 vCPU</td> <td>15 GB</td> <td>24 GB</td> <td>110 GB</td> <td>$1.00</td></tr> <tr><td>Nvidia A10G - large</td> <td>12 vCPU</td> <td>46 GB</td> <td>24 GB</td> <td>200 GB</td> <td>$1.50</td></tr> <tr><td>2x Nvidia A10G - large</td> <td>24 vCPU</td> <td>92 GB</td> <td>48 GB</td> <td>1000 GB</td> <td>$3.00</td></tr> <tr><td>4x Nvidia A10G - large</td> <td>48 vCPU</td> <td>184 GB</td> <td>96 GB</td> <td>2000 GB</td> <td>$5.00</td></tr> <tr><td>Nvidia A100 - large</td> <td>12 vCPU</td> <td>142 GB</td> <td>80 GB</td> <td>1000 GB</td> <td>$4.00</td></tr> <tr><td>1x Nvidia L40S</td> <td>8 vCPU</td> <td>62 GB</td> <td>48 GB</td> <td>380 GB</td> <td>$1.80</td></tr> <tr><td>4x Nvidia L40S</td> <td>48 vCPU</td> <td>48 GB</td> <td>192 GB</td> <td>3200 GB</td> <td>$8.30</td></tr> <tr><td>8x Nvidia L40S</td> <td>192 vCPU</td> <td>1534 GB</td> <td>384 GB</td> <td>6500 GB</td> <td>$23.50</td></tr> <tr><td>Nvidia H100</td> <td>24 vCPU</td> <td>250 GB</td> <td>80 GB</td> <td>3000 GB</td> <td>$10.00</td></tr> <tr><td>8x Nvidia H100</td> <td>192 vCPU</td> <td>2 TB</td> <td>640 GB</td> <td>3000 GB</td> <td>coming soon</td></tr></tbody>",Ht,_,Jt,H,je="<thead><tr><th><strong>Hardware</strong></th> <th><strong>Accelerators</strong></th> <th><strong>Accelerator Memory</strong></th> <th><strong>RAM</strong></th> <th><strong>Hourly Price</strong></th></tr></thead> <tbody><tr><td>Google TPU v5e - 1x1</td> <td>1</td> <td>16 GB</td> <td>44 GB</td> <td>$1.20</td></tr> <tr><td>Google TPU v5e - 2x2</td> <td>4</td> <td>64 GB</td> <td>186 GB</td> <td>$4.75</td></tr> <tr><td>Google TPU v5e - 2x4</td> <td>8</td> <td>128 GB</td> <td>380 GB</td> <td>$9.50</td></tr></tbody>",Lt,J,At,L,Be=`You can programmatically configure your Space hardware using <code>huggingface_hub</code>. This allows for a wide range of use cases where you need to dynamically assign GPUs.
Check out <a href="https://huggingface.co/docs/huggingface_hub/main/en/guides/manage_spaces" rel="nofollow">this guide</a> for more details.`,Yt,A,Zt,Y,Se="Most Spaces should run out of the box after a GPU upgrade, but sometimes you‚Äôll need to install CUDA versions of the machine learning frameworks you use. Please, follow this guide to ensure your Space takes advantage of the improved hardware.",It,Z,Nt,I,_e="You‚Äôll need to install a version of PyTorch compatible with the built-in CUDA drivers. Adding the following two lines to your <code>requirements.txt</code> file should work:",Et,N,Rt,E,He="You can verify whether the installation was successful by running the following code in your <code>app.py</code> and checking the output in your Space logs:",Wt,R,Vt,W,Je="Many frameworks automatically use the GPU if one is available. This is the case for the Pipelines in ü§ó <code>transformers</code>, <code>fastai</code> and many others. In other cases, or if you use PyTorch directly, you may need to move your models and data to the GPU to ensure computation is done on the accelerator and not on the CPU. You can use PyTorch‚Äôs <code>.to()</code> syntax, for example:",Xt,V,Ft,X,qt,F,Le="If you use JAX, you need to specify the URL that contains CUDA compatible packages. Please, add the following lines to your <code>requirements.txt</code> file:",zt,q,Qt,z,Ae="After that, you can verify the installation by printing the output from the following code and checking it in your Space logs.",Dt,Q,Kt,D,Ot,K,Ye="The default <code>tensorflow</code> installation should recognize the CUDA device. Just add <code>tensorflow</code> to your <code>requirements.txt</code> file and use the following code in your <code>app.py</code> to verify in your Space logs.",te,O,ee,tt,se,et,Ze=`Billing on Spaces is based on hardware usage and is computed by the minute: you get charged for every minute the Space runs on the requested hardware,
regardless of whether the Space is used.`,ae,st,Ie="During a Space‚Äôs lifecycle, it is only billed when the Space is actually <code>Running</code>. This means that there is no cost during build or startup.",le,at,Ne="If a running Space starts to fail, it will be automatically suspended and the billing will stop.",ne,lt,Ee='Spaces running on free hardware are suspended automatically if they are not used for an extended period of time (e.g. two days). Upgraded Spaces run indefinitely by default, even if there is no usage. You can change this behavior by <a href="#sleep-time">setting a custom ‚Äúsleep time‚Äù</a> in the Space‚Äôs settings. To interrupt the billing on your Space, you can change the Hardware to CPU basic, or <a href="#pause">pause</a> it.',ie,nt,Re='Additional information about billing can be found in the <a href="./billing">dedicated Hub-wide section</a>.',de,it,re,dt,We="Do you have an awesome Space but need help covering the GPU hardware upgrade costs? We love helping out those with an innovative Space so please feel free to apply for a community GPU grant and see if yours makes the cut! This application can be found in your Space hardware repo settings in the lower left corner under ‚Äúsleep time settings‚Äù:",oe,rt,Ve='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/ask-for-community-grant.png" alt="Community GPU Grant"/>',pe,ot,ue,pt,Xe="If your Space runs on the default <code>cpu-basic</code> hardware, it will go to sleep if inactive for more than a set time (currently, 48 hours). Anyone visiting your Space will restart it automatically.",ce,ut,Fe="If you want your Space never to deactivate or if you want to set a custom sleep time, you need to upgrade to paid hardware.",me,ct,qe="By default, an upgraded Space will never go to sleep. However, you can use this setting for your upgraded Space to become idle (<code>stopped</code> stage) when it‚Äôs unused üò¥. You are not going to be charged for the upgraded hardware while it is asleep. The Space will ‚Äòwake up‚Äô or get restarted once it receives a new visitor.",ge,mt,ze="The following interface will then be available in your Spaces hardware settings:",he,b,Qe='<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-sleep-time.png"/> <img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-sleep-time-dark.png"/>',fe,gt,De="The following options are available:",$e,T,Ke='<img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-sleep-time-options.png"/> <img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-sleep-time-options-dark.png"/>',ye,ht,ve,ft,Oe="You can <code>pause</code> a Space from the repo settings. A ‚Äúpaused‚Äù Space means that the Space is on hold and will not use resources until manually restarted, and only the owner of a paused Space can restart it. Paused time is not billed.",we,$t,be,wt,Te;return x=new f({props:{title:"Using GPU Spaces",local:"using-gpu-spaces",headingTag:"h1"}}),v=new ps({props:{$$slots:{default:[cs]},$$scope:{ctx:bt}}}),G=new f({props:{title:"Hardware Specs",local:"hardware-specs",headingTag:"h2"}}),k=new f({props:{title:"CPU",local:"cpu",headingTag:"h3"}}),B=new f({props:{title:"GPU",local:"gpu",headingTag:"h3"}}),_=new f({props:{title:"TPU",local:"tpu",headingTag:"h3"}}),J=new f({props:{title:"Configure hardware programmatically",local:"configure-hardware-programmatically",headingTag:"h2"}}),A=new f({props:{title:"Framework specific requirements",local:"frameworks",headingTag:"h2"}}),Z=new f({props:{title:"PyTorch",local:"pytorch",headingTag:"h3"}}),N=new vt({props:{code:"LS1leHRyYS1pbmRleC11cmwlMjBodHRwcyUzQSUyRiUyRmRvd25sb2FkLnB5dG9yY2gub3JnJTJGd2hsJTJGY3UxMTMlMEF0b3JjaA==",highlighted:`--extra-index-url https:<span class="hljs-regexp">//</span>download.pytorch.org<span class="hljs-regexp">/whl/</span>cu113
torch`,wrap:!1}}),R=new vt({props:{code:"aW1wb3J0JTIwdG9yY2glMEFwcmludChmJTIySXMlMjBDVURBJTIwYXZhaWxhYmxlJTNBJTIwJTdCdG9yY2guY3VkYS5pc19hdmFpbGFibGUoKSU3RCUyMiklMEElMjMlMjBUcnVlJTBBcHJpbnQoZiUyMkNVREElMjBkZXZpY2UlM0ElMjAlN0J0b3JjaC5jdWRhLmdldF9kZXZpY2VfbmFtZSh0b3JjaC5jdWRhLmN1cnJlbnRfZGV2aWNlKCkpJTdEJTIyKSUwQSUyMyUyMFRlc2xhJTIwVDQ=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Is CUDA available: <span class="hljs-subst">{torch.cuda.is_available()}</span>&quot;</span>)
<span class="hljs-comment"># True</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;CUDA device: <span class="hljs-subst">{torch.cuda.get_device_name(torch.cuda.current_device())}</span>&quot;</span>)
<span class="hljs-comment"># Tesla T4</span>`,wrap:!1}}),V=new vt({props:{code:"bW9kZWwlMjAlM0QlMjBsb2FkX3B5dG9yY2hfbW9kZWwoKSUwQW1vZGVsJTIwJTNEJTIwbW9kZWwudG8oJTIyY3VkYSUyMik=",highlighted:`model = load_pytorch_model()
model = model.to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),X=new f({props:{title:"JAX",local:"jax",headingTag:"h3"}}),q=new vt({props:{code:"LWYlMjBodHRwcyUzQSUyRiUyRnN0b3JhZ2UuZ29vZ2xlYXBpcy5jb20lMkZqYXgtcmVsZWFzZXMlMkZqYXhfY3VkYV9yZWxlYXNlcy5odG1sJTBBamF4JTVCY3VkYTExX3BpcCU1RCUwQWpheGxpYg==",highlighted:`-f https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/jax-releases/</span>jax_cuda_releases.html
jax[cuda11_pip]
jaxlib`,wrap:!1}}),Q=new vt({props:{code:"aW1wb3J0JTIwamF4JTBBJTBBcHJpbnQoZiUyMkpBWCUyMGRldmljZXMlM0ElMjAlN0JqYXguZGV2aWNlcygpJTdEJTIyKSUwQSUyMyUyMEpBWCUyMGRldmljZXMlM0ElMjAlNUJTdHJlYW1FeGVjdXRvckdwdURldmljZShpZCUzRDAlMkMlMjBwcm9jZXNzX2luZGV4JTNEMCklNUQlMEFwcmludChmJTIySkFYJTIwZGV2aWNlJTIwdHlwZSUzQSUyMCU3QmpheC5kZXZpY2VzKCklNUIwJTVELmRldmljZV9raW5kJTdEJTIyKSUwQSUyMyUyMEpBWCUyMGRldmljZSUyMHR5cGUlM0ElMjBUZXNsYSUyMFQ0",highlighted:`<span class="hljs-keyword">import</span> jax

<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;JAX devices: <span class="hljs-subst">{jax.devices()}</span>&quot;</span>)
<span class="hljs-comment"># JAX devices: [StreamExecutorGpuDevice(id=0, process_index=0)]</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;JAX device type: <span class="hljs-subst">{jax.devices()[<span class="hljs-number">0</span>].device_kind}</span>&quot;</span>)
<span class="hljs-comment"># JAX device type: Tesla T4</span>`,wrap:!1}}),D=new f({props:{title:"Tensorflow",local:"tensorflow",headingTag:"h3"}}),O=new vt({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEFwcmludCh0Zi5jb25maWcubGlzdF9waHlzaWNhbF9kZXZpY2VzKCdHUFUnKSklMEElMjMlMjAlNUJQaHlzaWNhbERldmljZShuYW1lJTNEJyUyRnBoeXNpY2FsX2RldmljZSUzQUdQVSUzQTAnJTJDJTIwZGV2aWNlX3R5cGUlM0QnR1BVJyklNUQ=",highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-built_in">print</span>(tf.config.list_physical_devices(<span class="hljs-string">&#x27;GPU&#x27;</span>))
<span class="hljs-comment"># [PhysicalDevice(name=&#x27;/physical_device:GPU:0&#x27;, device_type=&#x27;GPU&#x27;)]</span>`,wrap:!1}}),tt=new f({props:{title:"Billing",local:"billing",headingTag:"h2"}}),it=new f({props:{title:"Community GPU Grants",local:"community-gpu-grants",headingTag:"h3"}}),ot=new f({props:{title:"Set a custom sleep time",local:"sleep-time",headingTag:"h2"}}),ht=new f({props:{title:"Pausing a Space",local:"pause",headingTag:"h2"}}),$t=new us({props:{source:"https://github.com/huggingface/hub-docs/blob/main/docs/hub/spaces-gpus.md"}}),{c(){h=i("meta"),$=l(),U=i("p"),Tt=l(),o(x.$$.fragment),Ut=l(),C=i("p"),C.innerHTML=Ue,xt=l(),y=i("div"),y.innerHTML=xe,Ct=l(),o(v.$$.fragment),Mt=l(),M=i("p"),M.textContent=Ce,Gt=l(),w=i("div"),w.innerHTML=Me,Pt=l(),o(G.$$.fragment),kt=l(),P=i("p"),P.textContent=Ge,jt=l(),o(k.$$.fragment),Bt=l(),j=i("table"),j.innerHTML=Pe,St=l(),o(B.$$.fragment),_t=l(),S=i("table"),S.innerHTML=ke,Ht=l(),o(_.$$.fragment),Jt=l(),H=i("table"),H.innerHTML=je,Lt=l(),o(J.$$.fragment),At=l(),L=i("p"),L.innerHTML=Be,Yt=l(),o(A.$$.fragment),Zt=l(),Y=i("p"),Y.textContent=Se,It=l(),o(Z.$$.fragment),Nt=l(),I=i("p"),I.innerHTML=_e,Et=l(),o(N.$$.fragment),Rt=l(),E=i("p"),E.innerHTML=He,Wt=l(),o(R.$$.fragment),Vt=l(),W=i("p"),W.innerHTML=Je,Xt=l(),o(V.$$.fragment),Ft=l(),o(X.$$.fragment),qt=l(),F=i("p"),F.innerHTML=Le,zt=l(),o(q.$$.fragment),Qt=l(),z=i("p"),z.textContent=Ae,Dt=l(),o(Q.$$.fragment),Kt=l(),o(D.$$.fragment),Ot=l(),K=i("p"),K.innerHTML=Ye,te=l(),o(O.$$.fragment),ee=l(),o(tt.$$.fragment),se=l(),et=i("p"),et.textContent=Ze,ae=l(),st=i("p"),st.innerHTML=Ie,le=l(),at=i("p"),at.textContent=Ne,ne=l(),lt=i("p"),lt.innerHTML=Ee,ie=l(),nt=i("p"),nt.innerHTML=Re,de=l(),o(it.$$.fragment),re=l(),dt=i("p"),dt.textContent=We,oe=l(),rt=i("p"),rt.innerHTML=Ve,pe=l(),o(ot.$$.fragment),ue=l(),pt=i("p"),pt.innerHTML=Xe,ce=l(),ut=i("p"),ut.textContent=Fe,me=l(),ct=i("p"),ct.innerHTML=qe,ge=l(),mt=i("p"),mt.textContent=ze,he=l(),b=i("div"),b.innerHTML=Qe,fe=l(),gt=i("p"),gt.textContent=De,$e=l(),T=i("div"),T.innerHTML=Ke,ye=l(),o(ht.$$.fragment),ve=l(),ft=i("p"),ft.innerHTML=Oe,we=l(),o($t.$$.fragment),be=l(),wt=i("p"),this.h()},l(t){const e=is("svelte-u9bgzb",document.head);h=d(e,"META",{name:!0,content:!0}),e.forEach(s),$=n(t),U=d(t,"P",{}),es(U).forEach(s),Tt=n(t),p(x.$$.fragment,t),Ut=n(t),C=d(t,"P",{"data-svelte-h":!0}),r(C)!=="svelte-1r0b8ra"&&(C.innerHTML=Ue),xt=n(t),y=d(t,"DIV",{class:!0,"data-svelte-h":!0}),r(y)!=="svelte-195xp0n"&&(y.innerHTML=xe),Ct=n(t),p(v.$$.fragment,t),Mt=n(t),M=d(t,"P",{"data-svelte-h":!0}),r(M)!=="svelte-xvc6ld"&&(M.textContent=Ce),Gt=n(t),w=d(t,"DIV",{class:!0,"data-svelte-h":!0}),r(w)!=="svelte-1a8modj"&&(w.innerHTML=Me),Pt=n(t),p(G.$$.fragment,t),kt=n(t),P=d(t,"P",{"data-svelte-h":!0}),r(P)!=="svelte-8bcu8s"&&(P.textContent=Ge),jt=n(t),p(k.$$.fragment,t),Bt=n(t),j=d(t,"TABLE",{"data-svelte-h":!0}),r(j)!=="svelte-1wfpm10"&&(j.innerHTML=Pe),St=n(t),p(B.$$.fragment,t),_t=n(t),S=d(t,"TABLE",{"data-svelte-h":!0}),r(S)!=="svelte-1ukhjju"&&(S.innerHTML=ke),Ht=n(t),p(_.$$.fragment,t),Jt=n(t),H=d(t,"TABLE",{"data-svelte-h":!0}),r(H)!=="svelte-1873kas"&&(H.innerHTML=je),Lt=n(t),p(J.$$.fragment,t),At=n(t),L=d(t,"P",{"data-svelte-h":!0}),r(L)!=="svelte-hd4ipt"&&(L.innerHTML=Be),Yt=n(t),p(A.$$.fragment,t),Zt=n(t),Y=d(t,"P",{"data-svelte-h":!0}),r(Y)!=="svelte-wzbx3d"&&(Y.textContent=Se),It=n(t),p(Z.$$.fragment,t),Nt=n(t),I=d(t,"P",{"data-svelte-h":!0}),r(I)!=="svelte-11wbw9n"&&(I.innerHTML=_e),Et=n(t),p(N.$$.fragment,t),Rt=n(t),E=d(t,"P",{"data-svelte-h":!0}),r(E)!=="svelte-1xa4f2l"&&(E.innerHTML=He),Wt=n(t),p(R.$$.fragment,t),Vt=n(t),W=d(t,"P",{"data-svelte-h":!0}),r(W)!=="svelte-hlysi2"&&(W.innerHTML=Je),Xt=n(t),p(V.$$.fragment,t),Ft=n(t),p(X.$$.fragment,t),qt=n(t),F=d(t,"P",{"data-svelte-h":!0}),r(F)!=="svelte-pcmtzq"&&(F.innerHTML=Le),zt=n(t),p(q.$$.fragment,t),Qt=n(t),z=d(t,"P",{"data-svelte-h":!0}),r(z)!=="svelte-yvyw72"&&(z.textContent=Ae),Dt=n(t),p(Q.$$.fragment,t),Kt=n(t),p(D.$$.fragment,t),Ot=n(t),K=d(t,"P",{"data-svelte-h":!0}),r(K)!=="svelte-ibx2cu"&&(K.innerHTML=Ye),te=n(t),p(O.$$.fragment,t),ee=n(t),p(tt.$$.fragment,t),se=n(t),et=d(t,"P",{"data-svelte-h":!0}),r(et)!=="svelte-1waltjy"&&(et.textContent=Ze),ae=n(t),st=d(t,"P",{"data-svelte-h":!0}),r(st)!=="svelte-be6k8f"&&(st.innerHTML=Ie),le=n(t),at=d(t,"P",{"data-svelte-h":!0}),r(at)!=="svelte-1gpnuli"&&(at.textContent=Ne),ne=n(t),lt=d(t,"P",{"data-svelte-h":!0}),r(lt)!=="svelte-e3ljnh"&&(lt.innerHTML=Ee),ie=n(t),nt=d(t,"P",{"data-svelte-h":!0}),r(nt)!=="svelte-a71shw"&&(nt.innerHTML=Re),de=n(t),p(it.$$.fragment,t),re=n(t),dt=d(t,"P",{"data-svelte-h":!0}),r(dt)!=="svelte-1y4zyk2"&&(dt.textContent=We),oe=n(t),rt=d(t,"P",{"data-svelte-h":!0}),r(rt)!=="svelte-pjbwz8"&&(rt.innerHTML=Ve),pe=n(t),p(ot.$$.fragment,t),ue=n(t),pt=d(t,"P",{"data-svelte-h":!0}),r(pt)!=="svelte-crnlvc"&&(pt.innerHTML=Xe),ce=n(t),ut=d(t,"P",{"data-svelte-h":!0}),r(ut)!=="svelte-v5kvhb"&&(ut.textContent=Fe),me=n(t),ct=d(t,"P",{"data-svelte-h":!0}),r(ct)!=="svelte-1obgmq7"&&(ct.innerHTML=qe),ge=n(t),mt=d(t,"P",{"data-svelte-h":!0}),r(mt)!=="svelte-1p9yxd0"&&(mt.textContent=ze),he=n(t),b=d(t,"DIV",{class:!0,"data-svelte-h":!0}),r(b)!=="svelte-180o3b"&&(b.innerHTML=Qe),fe=n(t),gt=d(t,"P",{"data-svelte-h":!0}),r(gt)!=="svelte-k0x3k1"&&(gt.textContent=De),$e=n(t),T=d(t,"DIV",{class:!0,"data-svelte-h":!0}),r(T)!=="svelte-19ohzoj"&&(T.innerHTML=Ke),ye=n(t),p(ht.$$.fragment,t),ve=n(t),ft=d(t,"P",{"data-svelte-h":!0}),r(ft)!=="svelte-vhdjt1"&&(ft.innerHTML=Oe),we=n(t),p($t.$$.fragment,t),be=n(t),wt=d(t,"P",{}),es(wt).forEach(s),this.h()},h(){yt(h,"name","hf:doc:metadata"),yt(h,"content",gs),yt(y,"class","flex justify-center"),yt(w,"class","flex justify-center"),yt(b,"class","flex justify-center"),yt(T,"class","flex justify-center")},m(t,e){ds(document.head,h),a(t,$,e),a(t,U,e),a(t,Tt,e),u(x,t,e),a(t,Ut,e),a(t,C,e),a(t,xt,e),a(t,y,e),a(t,Ct,e),u(v,t,e),a(t,Mt,e),a(t,M,e),a(t,Gt,e),a(t,w,e),a(t,Pt,e),u(G,t,e),a(t,kt,e),a(t,P,e),a(t,jt,e),u(k,t,e),a(t,Bt,e),a(t,j,e),a(t,St,e),u(B,t,e),a(t,_t,e),a(t,S,e),a(t,Ht,e),u(_,t,e),a(t,Jt,e),a(t,H,e),a(t,Lt,e),u(J,t,e),a(t,At,e),a(t,L,e),a(t,Yt,e),u(A,t,e),a(t,Zt,e),a(t,Y,e),a(t,It,e),u(Z,t,e),a(t,Nt,e),a(t,I,e),a(t,Et,e),u(N,t,e),a(t,Rt,e),a(t,E,e),a(t,Wt,e),u(R,t,e),a(t,Vt,e),a(t,W,e),a(t,Xt,e),u(V,t,e),a(t,Ft,e),u(X,t,e),a(t,qt,e),a(t,F,e),a(t,zt,e),u(q,t,e),a(t,Qt,e),a(t,z,e),a(t,Dt,e),u(Q,t,e),a(t,Kt,e),u(D,t,e),a(t,Ot,e),a(t,K,e),a(t,te,e),u(O,t,e),a(t,ee,e),u(tt,t,e),a(t,se,e),a(t,et,e),a(t,ae,e),a(t,st,e),a(t,le,e),a(t,at,e),a(t,ne,e),a(t,lt,e),a(t,ie,e),a(t,nt,e),a(t,de,e),u(it,t,e),a(t,re,e),a(t,dt,e),a(t,oe,e),a(t,rt,e),a(t,pe,e),u(ot,t,e),a(t,ue,e),a(t,pt,e),a(t,ce,e),a(t,ut,e),a(t,me,e),a(t,ct,e),a(t,ge,e),a(t,mt,e),a(t,he,e),a(t,b,e),a(t,fe,e),a(t,gt,e),a(t,$e,e),a(t,T,e),a(t,ye,e),u(ht,t,e),a(t,ve,e),a(t,ft,e),a(t,we,e),u($t,t,e),a(t,be,e),a(t,wt,e),Te=!0},p(t,[e]){const ts={};e&2&&(ts.$$scope={dirty:e,ctx:t}),v.$set(ts)},i(t){Te||(c(x.$$.fragment,t),c(v.$$.fragment,t),c(G.$$.fragment,t),c(k.$$.fragment,t),c(B.$$.fragment,t),c(_.$$.fragment,t),c(J.$$.fragment,t),c(A.$$.fragment,t),c(Z.$$.fragment,t),c(N.$$.fragment,t),c(R.$$.fragment,t),c(V.$$.fragment,t),c(X.$$.fragment,t),c(q.$$.fragment,t),c(Q.$$.fragment,t),c(D.$$.fragment,t),c(O.$$.fragment,t),c(tt.$$.fragment,t),c(it.$$.fragment,t),c(ot.$$.fragment,t),c(ht.$$.fragment,t),c($t.$$.fragment,t),Te=!0)},o(t){m(x.$$.fragment,t),m(v.$$.fragment,t),m(G.$$.fragment,t),m(k.$$.fragment,t),m(B.$$.fragment,t),m(_.$$.fragment,t),m(J.$$.fragment,t),m(A.$$.fragment,t),m(Z.$$.fragment,t),m(N.$$.fragment,t),m(R.$$.fragment,t),m(V.$$.fragment,t),m(X.$$.fragment,t),m(q.$$.fragment,t),m(Q.$$.fragment,t),m(D.$$.fragment,t),m(O.$$.fragment,t),m(tt.$$.fragment,t),m(it.$$.fragment,t),m(ot.$$.fragment,t),m(ht.$$.fragment,t),m($t.$$.fragment,t),Te=!1},d(t){t&&(s($),s(U),s(Tt),s(Ut),s(C),s(xt),s(y),s(Ct),s(Mt),s(M),s(Gt),s(w),s(Pt),s(kt),s(P),s(jt),s(Bt),s(j),s(St),s(_t),s(S),s(Ht),s(Jt),s(H),s(Lt),s(At),s(L),s(Yt),s(Zt),s(Y),s(It),s(Nt),s(I),s(Et),s(Rt),s(E),s(Wt),s(Vt),s(W),s(Xt),s(Ft),s(qt),s(F),s(zt),s(Qt),s(z),s(Dt),s(Kt),s(Ot),s(K),s(te),s(ee),s(se),s(et),s(ae),s(st),s(le),s(at),s(ne),s(lt),s(ie),s(nt),s(de),s(re),s(dt),s(oe),s(rt),s(pe),s(ue),s(pt),s(ce),s(ut),s(me),s(ct),s(ge),s(mt),s(he),s(b),s(fe),s(gt),s($e),s(T),s(ye),s(ve),s(ft),s(we),s(be),s(wt)),s(h),g(x,t),g(v,t),g(G,t),g(k,t),g(B,t),g(_,t),g(J,t),g(A,t),g(Z,t),g(N,t),g(R,t),g(V,t),g(X,t),g(q,t),g(Q,t),g(D,t),g(O,t),g(tt,t),g(it,t),g(ot,t),g(ht,t),g($t,t)}}}const gs='{"title":"Using GPU Spaces","local":"using-gpu-spaces","sections":[{"title":"Hardware Specs","local":"hardware-specs","sections":[{"title":"CPU","local":"cpu","sections":[],"depth":3},{"title":"GPU","local":"gpu","sections":[],"depth":3},{"title":"TPU","local":"tpu","sections":[],"depth":3}],"depth":2},{"title":"Configure hardware programmatically","local":"configure-hardware-programmatically","sections":[],"depth":2},{"title":"Framework specific requirements","local":"frameworks","sections":[{"title":"PyTorch","local":"pytorch","sections":[],"depth":3},{"title":"JAX","local":"jax","sections":[],"depth":3},{"title":"Tensorflow","local":"tensorflow","sections":[],"depth":3}],"depth":2},{"title":"Billing","local":"billing","sections":[{"title":"Community GPU Grants","local":"community-gpu-grants","sections":[],"depth":3}],"depth":2},{"title":"Set a custom sleep time","local":"sleep-time","sections":[],"depth":2},{"title":"Pausing a Space","local":"pause","sections":[],"depth":2}],"depth":1}';function hs(bt){return as(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class bs extends ls{constructor(h){super(),ns(this,h,hs,ms,ss,{})}}export{bs as component};
